from flask import Flask, request, jsonify
import torch
import numpy as np
import sys
import os
# å¯¼å…¥ç°æœ‰çš„æ¨¡å‹å’Œè°ƒåº¦å™¨
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from cts_model import CTSDualTowerModel
from cags_scheduler import CAGSStrategyLayer

app = Flask(__name__)

# ==========================================
# 1. ç‰¹å¾æ ‡å‡†åŒ–å™¨
# ==========================================
class SimpleScaler:
    def transform(self, val, mean, std):
        return (val - mean) / (std + 1e-6)

# è¿™é‡Œçš„å‡å€¼å’Œæ–¹å·®æ˜¯åŸºäºè®­ç»ƒæ•°æ®ä¼°ç®—çš„
CLIENT_STATS = {
    'bandwidth_mbps': (20.0, 30.0),    # å¹³å‡å¸¦å®½ 20, æ³¢åŠ¨ 30
    'cpu_load': (0.5, 0.3),           # CPU è´Ÿè½½
    'network_rtt': (50.0, 80.0),      # RTT
    'memory_gb': (8.0, 4.0)           # å†…å­˜ (GB)
}
IMAGE_STATS = {
    'total_size_mb': (200.0, 150.0), 
    'avg_layer_entropy': (6.5, 1.0),
    'text_ratio': (0.1, 0.1),
    'layer_count': (10.0, 5.0),
    'zero_ratio': (0.05, 0.05)
}

# ==========================================
# 2. å…¨å±€æ¨¡å‹åŠ è½½
# ==========================================
print("ğŸ”„ æ­£åœ¨åŠ è½½AIæ¨¡å‹...")
device = torch.device("cpu")
model = CTSDualTowerModel(client_feats=4, image_feats=5, num_algos=10).to(device)

try:
    # æ¨¡å‹è·¯å¾„å¯èƒ½éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    model_path = os.path.join(os.path.dirname(__file__), '..', '..', 'ml_training', 'modeling', 'cts_best_model_full.pth')
    # ä½¿ç”¨å®‰å…¨æ–¹å¼åŠ è½½æ¨¡å‹
    state_dict = torch.load(model_path, map_location=device, weights_only=True)
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    print("âœ… AIæ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ AIæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    print("âš ï¸  ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹è¿›è¡Œæ¼”ç¤º")
    # åˆ›å»ºéšæœºæ¨¡å‹ç»§ç»­è¿è¡Œ
    pass

def calculate_uncertainty(beta, v, alpha):
    """
    è®¡ç®—ä¸ç¡®å®šæ€§ U = beta / (v * (alpha - 1))
    """
    return beta / (v * (alpha - 1) + 1e-6)  # é˜²æ­¢é™¤é›¶

@app.route('/negotiate', methods=['POST'])
def negotiate_strategy():
    """
    æ¥æ”¶å®¢æˆ·ç«¯ç¯å¢ƒä¿¡æ¯ï¼Œè¿”å›AIå†³ç­–çš„ä¸‹è½½ç­–ç•¥
    """
    try:
        # è·å–å®¢æˆ·ç«¯ä¸ŠæŠ¥çš„ç¯å¢ƒä¿¡æ¯
        data = request.json
        client_info = data.get('client_info', {})
        image_info = data.get('image_info', {})
        server_info = data.get('server_info', {})
        
        print(f"[Server] æ¥æ”¶åˆ°å®¢æˆ·ç«¯è¯·æ±‚: {client_info}")
        
        # æ„å»ºæ ‡å‡†åŒ–è¾“å…¥ç‰¹å¾
        scaler = SimpleScaler()
        
        # Clientç‰¹å¾: [Bandwidth, CPU_Limit, RTT, Memory_Limit]
        raw_bw = client_info.get('bandwidth_mbps', 10.0)
        raw_cpu = client_info.get('cpu_load', 0.5)
        raw_rtt = client_info.get('rtt_ms', 50.0)
        raw_mem = client_info.get('memory_gb', 4.0)
        
        norm_bw = scaler.transform(raw_bw, CLIENT_STATS['bandwidth_mbps'][0], CLIENT_STATS['bandwidth_mbps'][1])
        norm_cpu = scaler.transform(raw_cpu, CLIENT_STATS['cpu_load'][0], CLIENT_STATS['cpu_load'][1])
        norm_rtt = scaler.transform(raw_rtt, CLIENT_STATS['network_rtt'][0], CLIENT_STATS['network_rtt'][1])
        norm_mem = scaler.transform(raw_mem, CLIENT_STATS['memory_gb'][0], CLIENT_STATS['memory_gb'][1])
        
        client_vec = torch.FloatTensor([[
            norm_bw, 
            norm_cpu, 
            norm_rtt, 
            norm_mem
        ]]).to(device)
        
        # Imageç‰¹å¾: [Total_Size, Entropy, Text, Layer, Zero]
        raw_size = image_info.get('size_mb', 100.0)
        norm_size = scaler.transform(raw_size, IMAGE_STATS['total_size_mb'][0], IMAGE_STATS['total_size_mb'][1])
        
        image_vec = torch.FloatTensor([[
            norm_size, 
            0.0,  # å…¶ä»–ç‰¹å¾ç®€åŒ–å¤„ç†
            0.0, 
            0.0, 
            0.0
        ]]).to(device)
        
        algo_vec = torch.LongTensor([0]).to(device)

        # AIæ¨ç†
        with torch.no_grad():
            preds = model(client_vec, image_vec, algo_vec)
            gamma, v, alpha, beta = preds[0]
            
            # è®¡ç®—ä¸ç¡®å®šæ€§
            uncertainty_val = calculate_uncertainty(beta, v, alpha)
            ai_uncertainty = min(1.0, max(0.0, uncertainty_val.item() / 10.0))
            
            # åæ ‡å‡†åŒ–é¢„æµ‹æ—¶é—´
            predicted_time_s = torch.expm1(gamma).item()
        
        print(f"[Server] AIæ¨ç†ç»“æœ: é¢„æµ‹è€—æ—¶ {predicted_time_s:.2f}s, ä¸ç¡®å®šæ€§ {ai_uncertainty:.4f}")
        
        # æˆ˜ç•¥å±‚å†³ç­–
        strategy = CAGSStrategyLayer()
        predicted_risk_prob = 0.05 if predicted_time_s > 60 else 0.01
        best_config, cost = strategy.optimize(
            raw_bw,  # ä½¿ç”¨åŸå§‹å¸¦å®½å€¼
            predicted_risk_prob, 
            raw_cpu,  # ä½¿ç”¨åŸå§‹CPUè´Ÿè½½
            model_uncertainty=ai_uncertainty
        )
        chunk_size, concurrency = best_config
        
        print(f"[Server] æˆ˜ç•¥å±‚å†³ç­–: å—å¤§å° {chunk_size/(1024*1024):.2f}MB, å¹¶å‘æ•° {concurrency}")
        
        # è¿”å›å†³ç­–ç»“æœ
        response_data = {
            'target_url': server_info.get('download_url', 'http://192.168.1.100:80/download'),  # IPå ä½ç¬¦ï¼Œéœ€æ ¹æ®å®é™…ç¯å¢ƒä¿®æ”¹
            'strategy': {
                'initial_chunk_size': int(chunk_size),
                'concurrency': int(concurrency)
            },
            'meta_info': {
                'predicted_time_s': predicted_time_s,
                'uncertainty': ai_uncertainty,
                'cost': float(cost)
            }
        }
        
        return jsonify(response_data)
    
    except Exception as e:
        print(f"[Server] å†³ç­–è¿‡ç¨‹å‡ºé”™: {e}")
        # è¿”å›é»˜è®¤ç­–ç•¥
        return jsonify({
            'target_url': 'http://192.168.1.100:80/download',  # IPå ä½ç¬¦ï¼Œéœ€æ ¹æ®å®é™…ç¯å¢ƒä¿®æ”¹
            'strategy': {
                'initial_chunk_size': 1024*1024,  # 1MB
                'concurrency': 2
            },
            'meta_info': {
                'predicted_time_s': 0,
                'uncertainty': 0.1,
                'cost': 1.0,
                'error': str(e)
            }
        })

if __name__ == '__main__':
    # æ³¨æ„ï¼šIPåœ°å€éœ€è¦æ ¹æ®å®é™…éƒ¨ç½²ç¯å¢ƒä¿®æ”¹
    # ç¤ºä¾‹ä¸­ä½¿ç”¨ 192.168.1.100 ä½œä¸ºæœåŠ¡ç«¯IPï¼Œè¯·æ ¹æ®å®é™…ç¯å¢ƒä¿®æ”¹
    app.run(host='0.0.0.0', port=5000, debug=False)