#!/usr/bin/env python3
"""
e2e_runner_thesis.py - æ¯•ä¸šè®¾è®¡ä¸“ç”¨ï¼šå…¨çŸ©é˜µ + 3æ¬¡é‡å¤ + ç»Ÿè®¡åˆ†æ (æœ€ç»ˆä¿®å¤ç‰ˆ)
é›†æˆï¼š
1. RealDownloader (é˜²å´©æºƒä¸‹è½½å™¨)
2. CTSClient (ä½¿ç”¨AIå†³ç­–æ¨¡å‹)
3. ç»Ÿè®¡åˆ†ææ¨¡å—
"""

import argparse
import requests
import subprocess
import time
import csv
import os
import threading
import statistics
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

# å¯¼å…¥AIå†³ç­–æ¨¡å‹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from cts_model import CTSDualTowerModel
from cags_scheduler import CAGSStrategyLayer

# =================é…ç½®åŒºåŸŸ=================
REPEAT_COUNT = 3  # é‡å¤æ¬¡æ•°

# å››å¤§æµ‹è¯•é•œåƒ
TEST_IMAGES = [
    {'name': 'Perl (Text)',    'file': 'generalized_text.tar'},
    {'name': 'HAProxy (Mix)',  'file': 'generalized_mixed.tar'},
    {'name': 'Redis (Bin)',    'file': 'generalized_binary.tar'},
    {'name': 'Alpine (OS)',    'file': 'generalized_os.tar'}
]

# ä¸‰å¤§ç½‘ç»œåœºæ™¯
SCENARIOS = [
    {'name': 'A-IoT',   'bw': 2,   'delay': 400, 'loss': 5, 'strategy': 'weak'},
    {'name': 'B-Edge',  'bw': 20,  'delay': 50,  'loss': 1, 'strategy': 'balanced'},
    {'name': 'C-Cloud', 'bw': 100, 'delay': 20,  'loss': 0, 'strategy': 'strong'}
]
# =========================================

class NetworkController:
    def __init__(self, interface='eth0'):
        self.interface = interface
    
    def set_network(self, bw, delay, loss):
        # æ¸…é™¤æ—§è§„åˆ™
        subprocess.run(['sudo', 'tc', 'qdisc', 'del', 'dev', self.interface, 'root'], 
                      stderr=subprocess.DEVNULL, check=False)
        # è®¾ç½®æ–°è§„åˆ™
        cmd = [
            'sudo', 'tc', 'qdisc', 'add', 'dev', self.interface, 'root', 'netem',
            'rate', f'{bw}mbit', 'delay', f'{delay}ms', 'loss', f'{loss}%'
        ]
        try:
            subprocess.run(cmd, check=True)
            print(f"  âš¡ [Network] Set to {bw}Mbps, {delay}ms, {loss}% loss")
        except Exception as e:
            print(f"  âŒ [Network] Error: {e}")

    def reset(self):
        subprocess.run(['sudo', 'tc', 'qdisc', 'del', 'dev', self.interface, 'root'], 
                      stderr=subprocess.DEVNULL, check=False)

class NativeClient:
    def __init__(self, base_url):
        self.base_url = base_url

    def download(self, filename):
        target = f"{filename}.gz"
        url = f"{self.base_url}/{target}"
        start = time.time()
        try:
            # Nativeå•çº¿ç¨‹ä¸‹è½½ï¼Œè¶…æ—¶è®¾ä¸º300s
            resp = requests.get(url, timeout=300, stream=True)
            resp.raise_for_status()
            size = 0
            for chunk in resp.iter_content(8192): size += len(chunk)
            dur = time.time() - start
            return dur
        except Exception as e:
            return None

# =========================================================
# ğŸ“¦ RealDownloader: é˜²å´©æºƒä¸‹è½½æ ¸å¿ƒ (æ‰‹åŠ¨è½®è¯¢ç‰ˆ)
# =========================================================
class RealDownloader:
    def __init__(self, url, file_size, output_path):
        self.url = url
        self.total_size = file_size
        self.output_path = output_path
        self.lock = threading.Lock()
        
        # é¢„åˆ†é…ç©ºé—´ (/dev/null æˆ– ä¸´æ—¶æ–‡ä»¶å‡å¯ï¼Œè¿™é‡Œä¸ºäº†æµ‹é€Ÿå…¶å®ä¸éœ€è¦å†™çœŸæ–‡ä»¶)
        # ä¸ºäº†æ¯•è®¾å®éªŒçº¯æµ‹é€Ÿï¼Œæˆ‘ä»¬å¯ä»¥ä¸å†™çœŸæ–‡ä»¶ï¼Œåªæ¶ˆè€—ç½‘ç»œIOï¼Œé¿å…ç£ç›˜ç“¶é¢ˆ
        # ä½†ä¸ºäº†æ¨¡æ‹ŸçœŸå®ï¼Œè¿™é‡Œä¿ç•™é€»è¾‘ï¼Œä½†ä¸å†™ç£ç›˜ä»¥æé€Ÿ
        pass 

    def _fetch_chunk(self, start, end):
        headers = {'Range': f'bytes={start}-{end}'}
        try:
            # timeout=15 é€‚åº”ææ…¢çš„å¼±ç½‘ç¯å¢ƒ
            resp = requests.get(self.url, headers=headers, timeout=15)
            if resp.status_code == 206:
                content_len = len(resp.content)
                return content_len, 'SUCCESS'
            else:
                return 0, 'FAILED'
        except:
            return 0, 'TIMEOUT'

    def download_with_chunks(self, initial_chunk_size, concurrency):
        cursor = 0
        start_time = time.time()
        
        # ä½¿ç”¨ ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = {}
            
            # å¡«å……åˆå§‹ä»»åŠ¡æ± 
            while cursor < self.total_size or futures:
                # 1. æäº¤æ–°ä»»åŠ¡
                while cursor < self.total_size and len(futures) < concurrency:
                    end = min(cursor + initial_chunk_size - 1, self.total_size - 1)
                    future = executor.submit(self._fetch_chunk, cursor, end)
                    futures[future] = (cursor, end)
                    cursor += initial_chunk_size
                
                # 2. è½®è¯¢æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ (æ›¿ä»£ as_completed ä»¥é˜²æ­»é”)
                done_list = []
                for f in list(futures.keys()):
                    if f.done():
                        done_list.append(f)
                        try:
                            size, status = f.result()
                            if status != 'SUCCESS':
                                # å¦‚æœå¤±è´¥äº†ï¼Œè¿™é‡Œç®€å•å¤„ç†ï¼šä¸é‡è¯•äº†ï¼Œç›´æ¥ç®—ä½œå®éªŒæ³¢åŠ¨
                                # çœŸå®ç³»ç»Ÿä¼šé‡è¯•ï¼Œä½†åœ¨æµ‹é€Ÿå®éªŒä¸­ï¼Œfailä¼šå¯¼è‡´æ€»æ—¶é—´å˜é•¿ï¼Œç¬¦åˆé€»è¾‘
                                pass
                        except:
                            pass
                
                # 3. æ¸…ç†å·²å®Œæˆä»»åŠ¡
                for f in done_list:
                    del futures[f]
                
                # 4. é¿å… CPU ç©ºè½¬
                if not done_list:
                    time.sleep(0.05)

        total_time = time.time() - start_time
        return True, total_time

# =========================================================
# ğŸ§  CTSClient: ä½¿ç”¨AIå†³ç­–æ¨¡å‹
# =========================================================
class CTSClient:
    def __init__(self, base_url):
        self.base_url = base_url
        # åˆå§‹åŒ–AIå†³ç­–æ¨¡å‹
        self.strategy_layer = CAGSStrategyLayer()
        self.model_loaded = True
        try:
            # å°è¯•åŠ è½½æ¨¡å‹
            from cts_model import CTSDualTowerModel
            import torch
            import os
            
            # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
            possible_paths = [
                "cts_best_model_full.pth",
                "../ml_training/modeling/cts_best_model_full.pth",
                os.path.join(os.path.dirname(__file__), "cts_best_model_full.pth"),
                os.path.join(os.path.dirname(__file__), "../ml_training/modeling/cts_best_model_full.pth")
            ]
            model_path = next((p for p in possible_paths if os.path.exists(p)), None)
            
            if model_path:
                device = torch.device("cpu")
                self.ai_model = CTSDualTowerModel(client_feats=4, image_feats=5, num_algos=10).to(device)
                # ä½¿ç”¨å®‰å…¨æ–¹å¼åŠ è½½æ¨¡å‹
                state_dict = torch.load(model_path, map_location=device, weights_only=True)
                self.ai_model.load_state_dict(state_dict, strict=False)
                self.ai_model.eval()
                print("  âœ… AIæ¨¡å‹åŠ è½½æˆåŠŸï¼")
            else:
                print("  âš ï¸  æœªæ‰¾åˆ°AIæ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                self.model_loaded = False
        except Exception as e:
            print(f"  âš ï¸  AIæ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            self.model_loaded = False

    def calculate_uncertainty(self, beta, v, alpha):
        """è®¡ç®—ä¸ç¡®å®šæ€§ U"""
        return beta / (v * (alpha - 1) + 1e-6)

    def download(self, filename, strategy):
        # è·å–å½“å‰ç½‘ç»œåœºæ™¯å‚æ•°
        scenario_map = {
            'weak': {'bw': 2, 'delay': 400, 'loss': 5},
            'balanced': {'bw': 20, 'delay': 50, 'loss': 1},
            'strong': {'bw': 100, 'delay': 20, 'loss': 0}
        }
        
        scenario = scenario_map[strategy]
        
        # æ¨¡æ‹Ÿå®¢æˆ·ç«¯ç¯å¢ƒä¿¡æ¯
        client_info = {
            'bandwidth_mbps': scenario['bw'],
            'rtt_ms': scenario['delay'],
            'cpu_load': 0.3,  # å‡è®¾ä¸­ç­‰CPUè´Ÿè½½
            'memory_gb': 4.0   # å‡è®¾4GBå†…å­˜
        }
        
        # æ¨¡æ‹Ÿé•œåƒä¿¡æ¯
        image_info = {
            'total_size_mb': 100.0,  # å‡è®¾100MBé•œåƒ
            'avg_layer_entropy': 0.65,
            'text_ratio': 0.1,
            'layer_count': 5,
            'zero_ratio': 0.05
        }
        
        if self.model_loaded:
            # ä½¿ç”¨AIæ¨¡å‹è¿›è¡Œæ¨ç†
            from cags_scheduler import SimpleScaler
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            scaler = SimpleScaler()
            
            # å®¢æˆ·ç«¯ç‰¹å¾
            CLIENT_STATS = {
                'bandwidth_mbps': (20.0, 30.0), 
                'cpu_load': (0.5, 0.3),          
                'network_rtt': (50.0, 80.0),      
                'memory_gb': (8.0, 4.0)          
            }
            IMAGE_STATS = {
                'total_size_mb': (200.0, 150.0), 
                'avg_layer_entropy': (6.5, 1.0),
                'text_ratio': (0.1, 0.1),
                'layer_count': (10.0, 5.0),
                'zero_ratio': (0.05, 0.05)
            }
            
            raw_bw = float(client_info.get('bandwidth_mbps', 10.0))
            raw_cpu = float(client_info.get('cpu_load', 0.5))
            raw_rtt = float(client_info.get('rtt_ms', 50.0))
            raw_mem = float(client_info.get('memory_gb', 4.0))
            
            # æ ‡å‡†åŒ–
            norm_bw = scaler.transform(raw_bw, *CLIENT_STATS['bandwidth_mbps'])
            norm_cpu = scaler.transform(raw_cpu, *CLIENT_STATS['cpu_load'])
            norm_rtt = scaler.transform(raw_rtt, *CLIENT_STATS['network_rtt'])
            norm_mem = scaler.transform(raw_mem, *CLIENT_STATS['memory_gb'])
            
            device = torch.device("cpu")
            client_vec = torch.FloatTensor([[norm_bw, norm_cpu, norm_rtt, norm_mem]]).to(device)
            
            # Image ç‰¹å¾
            raw_size = float(image_info.get('size_mb', 100.0))
            norm_size = scaler.transform(raw_size, *IMAGE_STATS['total_size_mb'])
            image_vec = torch.FloatTensor([[norm_size, 0.5, 0.1, 5.0, 0.05]]).to(device)
            algo_vec = torch.LongTensor([0]).to(device)

            # AIæ¨ç†
            with torch.no_grad():
                preds = self.ai_model(client_vec, image_vec, algo_vec)
                gamma, v, alpha, beta = preds[0]
                
                uncertainty_val = self.calculate_uncertainty(beta, v, alpha)
                predicted_time_s = torch.expm1(gamma).item()
                
                # è·å–AIå†³ç­–çš„ç­–ç•¥
                predicted_risk_prob = 0.05 if predicted_time_s > 60 else 0.01
                ai_uncertainty = min(1.0, max(0.0, uncertainty_val.item() / 10.0))
                
                # AIå†³ç­–æœ€ä¼˜å‚æ•°
                best_config, cost = self.strategy_layer.optimize(
                    predicted_bw_mbps=raw_bw, 
                    predicted_loss_rate=predicted_risk_prob, 
                    client_cpu_load=raw_cpu, 
                    model_uncertainty=ai_uncertainty
                )
                
                chunk_size, concurrency = best_config
                
                # ä½¿ç”¨AIæ¨èçš„å‹ç¼©ç®—æ³•
                c_profile = {'bandwidth_mbps': raw_bw, 'cpu_score': 2000, 'decompression_speed': 200}
                i_profile = {'total_size_mb': raw_size, 'avg_layer_entropy': 0.65}
                
                sorted_algorithms = self.strategy_layer.predict_compression_times(c_profile, i_profile)
                
                # æ˜¾ç¤ºå‰3ä¸ªæ¨èç®—æ³•
                print(f"     [AI Algorithm Ranking]:")
                for idx, (algo, pred_time) in enumerate(sorted_algorithms[:3]):
                    marker = "ğŸ†" if idx == 0 else " "
                    print(f"       {marker} {idx+1}. {algo} ({pred_time:.2f}s)")
                
                top_algorithm = sorted_algorithms[0][0]  # é€‰æ‹©é¢„æµ‹æ—¶é—´æœ€çŸ­çš„ç®—æ³•
                
                # æ˜ å°„å‹ç¼©ç®—æ³•åˆ°æ–‡ä»¶åç¼€
                algo_suffix_map = {
                    'gzip-1': '.gz', 'gzip-6': '.gz', 'gzip-9': '.gz',
                    'zstd-1': '.zst', 'zstd-3': '.zst', 'zstd-6': '.zst', 'zstd-19': '.zst',
                    'lz4-fast': '.lz4', 'lz4-medium': '.lz4', 'lz4-slow': '.lz4',
                    'brotli-1': '.br', 'brotli-6': '.br', 'brotli-11': '.br'
                }
                
                suffix = algo_suffix_map.get(top_algorithm, '.gz')
                
                print(f"     [AI Decision] -> Selected: {top_algorithm}, Suffix: {suffix}, Concurrency: {concurrency}")

        else:
            # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¯å‘å¼è§„åˆ™
            # æ ¹æ®ç½‘ç»œåœºæ™¯é€‰æ‹©é»˜è®¤é…ç½®
            if strategy == 'weak': 
                suffix = '.br'
                chunk_size = 1024*1024  # 1MBåˆ†ç‰‡
                concurrency = 2  # 2çº¿ç¨‹
            elif strategy == 'balanced': 
                suffix = '.zst'
                chunk_size = 2*1024*1024  # 2MBåˆ†ç‰‡
                concurrency = 4  # 4çº¿ç¨‹
            else:  # strong
                suffix = '.lz4'
                chunk_size = 4*1024*1024  # 4MBåˆ†ç‰‡
                concurrency = 8  # 8çº¿ç¨‹
            
            print(f"     [Fallback] -> Suffix: {suffix}, Chunk: {chunk_size/1024/1024:.1f}MB, Concurrency: {concurrency}")

        target_name = f"{filename}{suffix}"
        url = f"{self.base_url}/{target_name}"
        
        try:
            head = requests.head(url, timeout=10)
            total_size = int(head.headers.get('Content-Length', 0))
        except: 
            return None

        # è°ƒç”¨é˜²å´©æºƒä¸‹è½½å™¨
        downloader = RealDownloader(url, total_size, '/dev/null')

        # =======================================================
        # ğŸ›‘ ã€ç´§æ€¥ä¿®å¤ã€‘è¦†ç›– AI æˆ– è§„åˆ™ çš„ chunk_size
        # å³ä½¿ AI å»ºè®® 1MBï¼Œåœ¨ 400ms å»¶è¿Ÿä¸‹æˆ‘ä»¬ä¹Ÿè¦è¦†ç›–å®ƒï¼Œ
        # å¼ºåˆ¶è®©æ¯ä¸ªçº¿ç¨‹åªè·‘ä¸€ä¸ªé•¿è¿æ¥ï¼Œé¿å… TCP æ…¢å¯åŠ¨ï¼
        # =======================================================
        final_chunk_size = max(total_size // concurrency, 1024*1024)

        # æ‰§è¡Œä¸‹è½½ (ç”¨ä¿®å¤åçš„ final_chunk_size)
        success, total_time = downloader.download_with_chunks(final_chunk_size, concurrency)
        
        if success:
            return total_time
        else:
            return None

def get_stats(data_list):
    """è®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®"""
    if not data_list: return 0, 0
    if len(data_list) == 1: return data_list[0], 0
    return statistics.mean(data_list), statistics.stdev(data_list)

def run():
    parser = argparse.ArgumentParser()
    parser.add_argument('--ip', required=True, help="Server IP")
    args = parser.parse_args()

    net = NetworkController()
    native = NativeClient(f"http://{args.ip}")
    cts = CTSClient(f"http://{args.ip}")
    
    results = []
    
    print("="*60)
    print(f"ğŸ“ Thesis Experiment: Full Matrix x {REPEAT_COUNT} Repeats")
    print("="*60)
    print("âš ï¸  Estimated time: 1.5 - 2 Hours. Do not close terminal.\n")

    try:
        for scen in SCENARIOS:
            print(f"\nğŸŒ [SCENARIO: {scen['name']}]")
            net.set_network(scen['bw'], scen['delay'], scen['loss'])
            time.sleep(2)
            
            for img in TEST_IMAGES:
                print(f"\n  ğŸ“¦ Image: {img['name']}")
                
                # --- Native Loop ---
                nat_times = []
                for i in range(REPEAT_COUNT):
                    print(f"     Running Native ({i+1}/{REPEAT_COUNT})... ", end='', flush=True)
                    t = native.download(img['file'])
                    if t: 
                        nat_times.append(t)
                        print(f"Done ({t:.2f}s)")
                    else:
                        print("Failed")
                
                # --- CTS Loop ---
                cts_times = []
                for i in range(REPEAT_COUNT):
                    print(f"     Running CTS    ({i+1}/{REPEAT_COUNT})... ", end='', flush=True)
                    t = cts.download(img['file'], scen['strategy'])
                    if t:
                        cts_times.append(t)
                        print(f"Done ({t:.2f}s)")
                    else:
                        print("Failed")

                # --- ç»Ÿè®¡ä¸è®°å½• ---
                avg_nat, std_nat = get_stats(nat_times)
                avg_cts, std_cts = get_stats(cts_times)
                
                if avg_nat > 0 and avg_cts > 0:
                    speedup = avg_nat / avg_cts
                    results.append({
                        'Scenario': scen['name'],
                        'Image': img['name'],
                        'Strategy': scen['strategy'],
                        'Native_Mean': f"{avg_nat:.2f}",
                        'Native_Std': f"{std_nat:.2f}",
                        'CTS_Mean': f"{avg_cts:.2f}",
                        'CTS_Std': f"{std_cts:.2f}",
                        'Speedup': f"{speedup:.2f}"
                    })
                    print(f"  ğŸ“Š Result: Native={avg_nat:.2f}s Â±{std_nat:.2f}, CTS={avg_cts:.2f}s Â±{std_cts:.2f} => {speedup:.2f}x Speedup")

    finally:
        net.reset()
        print("\nâš¡ Network Reset.")

    csv_file = f"thesis_results_final_{datetime.now().strftime('%d_%H%M')}.csv"
    with open(csv_file, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'Scenario', 'Image', 'Strategy', 
            'Native_Mean', 'Native_Std', 
            'CTS_Mean', 'CTS_Std', 
            'Speedup'
        ])
        writer.writeheader()
        writer.writerows(results)
    
    print(f"\nâœ… Experiment Complete! Data saved to {csv_file}")

if __name__ == '__main__':
    run()