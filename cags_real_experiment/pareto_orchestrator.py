#!/usr/bin/env python3
"""
CTS Pareto Optimization Orchestrator - Production Grade with Multi-Scale Sampling
ç‰©ç†æ­£ç¡®æ€§ï¼šnetnsid å®šä½ + Quota-Aware CPU + éš”ç¦» IFB + 10/100/300MB åˆ†å±‚é‡‡æ · + åŠ¨æ€è¶…æ—¶
ä¿®å¤ï¼šTC é™é€ŸéªŒè¯ + Nginx é›¶æ‹·è´ç¦ç”¨
"""
import docker
import subprocess
import time
import os
import re
import json
import pandas as pd
import itertools
from datetime import datetime
import threading
import numpy as np
from contextlib import contextmanager
from typing import List, Dict, Any
import socket
import struct
import glob
import concurrent.futures

# ==============================
# 1. é…ç½®åŒº
# ==============================
NETWORK_NAME = "cts_exp_net"
SERVER_IMAGE = "nginx:alpine"
CLIENT_IMAGE = "python:3.9-slim"
DATA_FILE = "/tmp/cts_test_file_300mb.dat"

NETWORK_SCENARIOS = [
    {"name": "IoT_Weak", "bw": "2mbit", "delay": "400ms", "loss": "5%", "mbps": 2},
    {"name": "Edge_Normal", "bw": "20mbit", "delay": "100ms", "loss": "1%", "mbps": 20},
    {"name": "Cloud_Fast", "bw": "1000mbit", "delay": "5ms", "loss": "0%", "mbps": 1000}
]

# ==============================
# 2. ç³»ç»Ÿçº§å·¥å…·
# ==============================

def sh(cmd, check=False, timeout=10):
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, 
                              text=True, timeout=timeout)
        return result.stdout.strip()
    except:
        return ""

def nuclear_cleanup_safe():
    """å®‰å…¨æ¸…ç†ï¼šåªæ¸…ç†å®éªŒç›¸å…³æ¥å£ï¼Œä¸ç¢°å…¨å±€ conntrack"""
    try:
        for iface in os.listdir('/sys/class/net/'):
            if iface in ['lo', 'eth0', 'ens160', 'ens33']:
                continue
            if 'docker' in iface or 'veth' in iface or iface.startswith('br-'):
                sh(f"tc qdisc del dev {iface} root 2>/dev/null", check=False)
                sh(f"tc qdisc del dev {iface} ingress 2>/dev/null", check=False)
        
        # æ¸…ç†æ‰€æœ‰ ifb
        ifb_list = sh("ip -o link show type ifb 2>/dev/null | awk -F': ' '{print $2}'", check=False)
        for ifb in ifb_list.split('\n'):
            if ifb.strip():
                name = ifb.strip().split('@')[0]
                sh(f"tc qdisc del dev {name} root 2>/dev/null", check=False)
                sh(f"ip link set {name} down 2>/dev/null", check=False)
                sh(f"ip link del {name} 2>/dev/null", check=False)
        time.sleep(0.1)
    except:
        pass

def prepare_test_file(max_size_mb=300):
    """ç”Ÿæˆæœ€å¤§æµ‹è¯•æ–‡ä»¶ï¼ˆæ‰€æœ‰å®éªŒå…±ç”¨ï¼Œé€šè¿‡Rangeè¯»å–ä¸åŒéƒ¨åˆ†ï¼‰"""
    if not os.path.exists(DATA_FILE) or os.path.getsize(DATA_FILE) < max_size_mb * 1024 * 1024:
        print(f"ğŸ“¦ ç”Ÿæˆ {max_size_mb}MB æµ‹è¯•æ–‡ä»¶...")
        sh(f"dd if=/dev/urandom of={DATA_FILE} bs=1M count={max_size_mb} status=none")
    return DATA_FILE

# ==============================
# 3. VETH å®šä½ï¼ˆå†…æ ¸åŸæ•™æ—¨ï¼‰
# ==============================

def get_veth_kernel_native(container_id, timeout=60):
    """
    ç¨³å®šè·å– vethï¼šç­‰å¾… netns å°±ç»ª -> ç­‰å¾… eth0 UP -> è§£æ ifindex -> MAC fallback
    ä¿®å¤ï¼šDocker å¼‚æ­¥ç½‘ç»œåˆ›å»ºå¯¼è‡´çš„ /proc/<pid>/ns/net ä¸å­˜åœ¨é—®é¢˜
    """
    start = time.time()
    client = docker.from_env()
    
    # =================== é˜¶æ®µ 0: è·å– container å¯¹è±¡å’Œ PID ===================
    while time.time() - start < timeout:
        try:
            container = client.containers.get(container_id)
            info = container.attrs
            
            if not info['State']['Running']:
                if info['State']['ExitCode'] != 0:
                    logs = container.logs(tail=50).decode('utf-8', errors='ignore')
                    raise RuntimeError(f"Container exited ({info['State']['ExitCode']}). Logs: {logs}")
                time.sleep(0.2)
                continue
            
            pid = info['State']['Pid']
            if pid and pid != 0:
                break
                
        except docker.errors.NotFound:
            raise RuntimeError(f"Container {container_id} not found")
        except Exception as e:
            if "exited" in str(e):
                raise
            time.sleep(0.2)
    else:
        raise RuntimeError("Timeout: Container did not start")

    print(f"   [DEBUG] Container {container_id[:12]} PID: {pid}")

    # =================== é˜¶æ®µ 1: å…³é”®ä¿®å¤ - ç­‰å¾… netns æ–‡ä»¶å‡ºç° ===================
    netns_path = f"/proc/{pid}/ns/net"
    ns_start = time.time()
    
    while time.time() - ns_start < timeout:
        if os.path.exists(netns_path):
            print(f"   [DEBUG] Netns ready: {netns_path}")
            break
        print(f"   [WAIT] Netns not ready yet: {netns_path}...")
        time.sleep(0.5)
    else:
        # æœ€åæ£€æŸ¥ï¼šå¦‚æœä»ä¸å­˜åœ¨ï¼Œæ£€æŸ¥å®¹å™¨æ˜¯å¦è¿˜åœ¨è¿è¡Œ
        container.reload()
        if not container.attrs['State']['Running']:
            raise RuntimeError(f"Container died while waiting for netns. Exit code: {container.attrs['State']['ExitCode']}")
        raise RuntimeError(f"Timeout: {netns_path} not created after {timeout}s")

    # =================== é˜¶æ®µ 2: ç­‰å¾… eth0 å‡ºç°å¹¶ UP ===================
    eth0_start = time.time()
    peer_ifindex = None
    
    while time.time() - eth0_start < timeout:
        try:
            # åŒé‡æ£€æŸ¥ netns ä»å­˜åœ¨ï¼ˆé˜²æ­¢å®¹å™¨çªç„¶é€€å‡ºï¼‰
            if not os.path.exists(netns_path):
                raise RuntimeError("Netns disappeared during check")
            
            # ä½¿ç”¨ nsenter æ£€æŸ¥ eth0 çŠ¶æ€
            link_output = sh(f"nsenter -t {pid} -n ip link show eth0 2>&1", check=False)
            
            # eth0 è¿˜ä¸å­˜åœ¨
            if "does not exist" in link_output:
                print(f"   [WAIT] eth0 not created yet...")
                time.sleep(0.5)
                continue
            
            # eth0 å­˜åœ¨ä½†æœª UPï¼ˆç½‘ç»œé…ç½®ä¸­ï¼‰
            if "state UP" not in link_output:
                print(f"   [WAIT] eth0 exists but not UP: {link_output[:60].strip()}...")
                time.sleep(0.3)
                continue
            
            # eth0 UP - æå– peer ifindex
            match = re.search(r'eth0@if(\d+)', link_output)
            if match:
                peer_ifindex = match.group(1)
                print(f"   [DEBUG] eth0 UP, peer ifindex: {peer_ifindex}")
                break
            else:
                # è€å†…æ ¸å¯èƒ½æ²¡æœ‰ @if æ ¼å¼ï¼Œå°è¯•å¤‡é€‰è§£æ
                print(f"   [WARN] Could not parse eth0@ifXXXX from: {link_output[:100]}")
                time.sleep(0.5)
                
        except Exception as e:
            print(f"   [WARN] nsenter check failed: {e}")
            time.sleep(0.5)
    
    if not peer_ifindex:
        print("   [WARN] eth0 timeout, attempting MAC fallback...")
        return get_veth_by_mac(container_id, pid, timeout=15)

    # =================== é˜¶æ®µ 3: åœ¨å®¿ä¸»æœºæŸ¥æ‰¾ veth ===================
    try:
        # æ–¹æ³• A: é€šè¿‡ ip link ç›´æ¥æŸ¥æ‰¾ï¼ˆæœ€å¿«ï¼‰
        result = sh(f"ip -o link show | grep '^{peer_ifindex}:' | head -1", check=False)
        if result:
            # æ ¼å¼: "1044: vethXXXXX@if1043: <BROADCAST,MULTICAST,UP,LOWER_UP>..."
            match = re.match(r'\d+:\s+([^\s:@]+)', result)
            # âœ… å…³é”®ä¿®å¤1ï¼šä½¿ç”¨ startswith ç¡®ä¿æ˜¯ vethï¼Œä¸æ˜¯åŒ…å« veth çš„å…¶ä»–å­—ç¬¦ä¸²
            if match and match.group(1).startswith('veth'):
                veth_name = match.group(1)
                print(f"   [OK] Found veth via ip link: {veth_name}")
                return veth_name
        
        # æ–¹æ³• B: æ‰«æ /sys/class/netï¼ˆæ›´å¯é ï¼Œä½†æ…¢ï¼‰
        for iface in os.listdir('/sys/class/net/'):
            if not iface.startswith('veth'):
                continue
            try:
                with open(f'/sys/class/net/{iface}/iflink', 'r') as f:
                    if f.read().strip() == peer_ifindex:
                        print(f"   [OK] Found veth via sysfs: {iface}")
                        return iface
            except:
                continue
        
        # æ–¹æ³• C: é€šè¿‡ bridge fdb + MACï¼ˆæœ€åæ‰‹æ®µï¼‰
        print("   [WARN] ifindex methods failed, trying bridge fdb...")
        mac = sh(f"docker inspect -f '{{{{range .NetworkSettings.Networks}}}}{{{{.MacAddress}}}}{{{{end}}}}' {container_id}").lower().strip()
        if mac:
            for _ in range(10):
                fdb = sh(f"bridge fdb show | grep -i '{mac}' | grep 'veth' | head -1", check=False)
                if fdb:
                    parts = fdb.split()
                    for i, p in enumerate(parts):
                        if p == 'dev' and i+1 < len(parts):
                            veth_name = parts[i+1]
                            # âœ… å…³é”®ä¿®å¤2ï¼šç¡®ä¿æå–çš„æ˜¯ veth æ¥å£ï¼Œä¸æ˜¯å…¶ä»–å†…å®¹
                            if veth_name.startswith('veth'):
                                print(f"   [OK] Found veth via bridge fdb: {veth_name}")
                                return veth_name
                time.sleep(0.2)
                
    except Exception as e:
        print(f"   [ERROR] Find veth failed: {e}")
    
    raise RuntimeError(f"All veth detection methods failed for {container_id[:12]}")


def get_veth_by_mac(container_id, pid, timeout=10):
    """
    å¤‡é€‰æ–¹æ¡ˆï¼šé€šè¿‡ MAC åœ°å€åœ¨ bridge fdb ä¸­æŸ¥æ‰¾
    """
    try:
        # è·å–å®¹å™¨ MAC
        mac = sh(f"docker inspect -f '{{{{range .NetworkSettings.Networks}}}}{{{{.MacAddress}}}}{{{{end}}}}' {container_id}").lower().strip()
        print(f"   [DEBUG] MAC fallback: {mac}")
        
        if not mac:
            raise RuntimeError("Cannot get MAC")
        
        for _ in range(timeout * 2):  # 20 æ¬¡å°è¯•
            try:
                # åœ¨ bridge fdb ä¸­æŸ¥æ‰¾
                fdb = sh(f"bridge fdb show | grep -i '{mac}' | head -1", check=False)
                if fdb and 'veth' in fdb:
                    parts = fdb.split()
                    for i, p in enumerate(parts):
                        if p == 'dev' and i+1 < len(parts):
                            candidate = parts[i+1]
                            # âœ… å…³é”®ä¿®å¤3ï¼šç¡®ä¿è¿”å›çš„æ˜¯ veth æ¥å£
                            if candidate.startswith('veth'):
                                print(f"   [OK] Found veth by MAC: {candidate}")
                                return candidate
            except:
                pass
            time.sleep(0.5)
            
    except Exception as e:
        print(f"   [ERROR] MAC fallback failed: {e}")
    
    raise RuntimeError("All veth detection methods failed")

# ==============================
# 4. TC é…ç½®ï¼ˆå®Œå…¨éš”ç¦» IFBï¼‰- å¸¦éªŒè¯
# ==============================

def setup_isolated_tc(veth, bw, delay, loss, run_id):
    """
    [âœ… ç»ˆæä¿®å¤ç‰ˆ] HTB ç¡¬é™é€Ÿ + Netem æ¨¡æ‹Ÿ + å…³é—­ TSO/GSO
    ç¡®ä¿å¸¦å®½é™åˆ¶çœŸæ­£ç”Ÿæ•ˆï¼Œè€Œä¸æ˜¯ä»…é…ç½®è§„åˆ™
    """


    """
    [èåˆç‰ˆ] 1. å…³é—­ Offload 2. ä½¿ç”¨ HTB+Netem
    """
    ifb_name = f"ifb_{run_id}_{int(time.time()*1000)%1000}"
    
    # 1. æ¸…ç†
    sh(f"tc qdisc del dev {veth} root 2>/dev/null", check=False)
    sh(f"tc qdisc del dev {veth} ingress 2>/dev/null", check=False)
    
    # 2. âœ… å…³é—­ Offloadï¼ˆå…³é”®æ­¥éª¤ï¼‰
    # å…ˆæ£€æŸ¥ ethtool æ˜¯å¦å­˜åœ¨
    if sh("which ethtool"):
        sh(f"ethtool -K {veth} tso off gso off gro off", check=False)
        print(f"   [DEBUG] Offload disabled on {veth}")
    else:
        print(f"   [WARN] ethtool not found! TSO/GSO may bypass TC limits")
        # å¤‡é€‰æ–¹æ¡ˆï¼šå°è¯•ç”¨ ip route é™é€Ÿï¼ˆæœ€åæ‰‹æ®µï¼‰
    
    # 3. å‡†å¤‡ IFB
    sh(f"modprobe ifb numifbs=100", check=False)
    sh(f"ip link add {ifb_name} type ifb", check=False)
    sh(f"ip link set {ifb_name} up", check=False)
    
    if sh("which ethtool"):
        sh(f"ethtool -K {ifb_name} tso off gso off gro off", check=False)

    # ==============================================================
    # æ–¹å‘ A: Server -> Client (ä¸‹è½½æµï¼Œå®éªŒçš„ä¸»è¦æ–¹å‘)
    # è·¯å¾„: Nginx (Server) -> eth0 -> VETH(Ingress) -> IFB -> é™é€Ÿ
    # ==============================================================
    
    # å°† VETH çš„å…¥ç«™æµé‡é•œåƒåˆ° IFB
    sh(f"tc qdisc add dev {veth} handle ffff: ingress 2>/dev/null || tc qdisc add dev {veth} ingress")
    sh(f"tc filter add dev {veth} parent ffff: protocol all u32 match u32 0 0 action mirred egress redirect dev {ifb_name}")
    
    # åœ¨ IFB ä¸Šåº”ç”¨ HTB (ç¡¬é™é€Ÿ) + Netem (å»¶è¿Ÿ/ä¸¢åŒ…)
    # Root HTB
    sh(f"tc qdisc add dev {ifb_name} root handle 1: htb default 1")
    # é™é€Ÿç±»ï¼ˆburst è®¾å¤§ä¸€äº›é¿å…çªå‘ï¼‰
    sh(f"tc class add dev {ifb_name} parent 1: classid 1:1 htb rate {bw} burst 32k")
    # Netem å­ç±»å¤„ç†å»¶è¿Ÿå’Œä¸¢åŒ…
    sh(f"tc qdisc add dev {ifb_name} parent 1:1 handle 10: netem delay {delay} loss {loss} limit 10000")

    # ==============================================================
    # æ–¹å‘ B: Client -> Server (ACK åŒ…ï¼Œå¦‚æœä¸é™é€Ÿ ACK ä¼šé£å›ï¼Œå½±å“ TCP è¡Œä¸º)
    # è·¯å¾„: Client -> VETH(Egress) -> Server (Nginx)
    # ==============================================================
    
    # ç›´æ¥åœ¨ VETH çš„å‡ºç«™æ–¹å‘åº”ç”¨ HTB + Netem
    sh(f"tc qdisc add dev {veth} root handle 1: htb default 1")
    sh(f"tc class add dev {veth} parent 1: classid 1:1 htb rate {bw} burst 32k")
    sh(f"tc qdisc add dev {veth} parent 1:1 handle 10: netem delay {delay} loss {loss} limit 10000")
    
    # éªŒè¯é…ç½®
    print(f"   [DEBUG] TC Setup Complete:")
    print(f"      VETH {veth}: Egress HTB(rate={bw})")
    print(f"      IFB  {ifb_name}: Ingress HTB(rate={bw}) + Netem(delay={delay}, loss={loss})")
    
    return ifb_name

def reset_isolated_tc(veth, ifb_name):
    if veth:
        sh(f"tc qdisc del dev {veth} root 2>/dev/null", check=False)
        sh(f"tc qdisc del dev {veth} ingress 2>/dev/null", check=False)
    if ifb_name:
        sh(f"tc qdisc del dev {ifb_name} root 2>/dev/null", check=False)
        sh(f"ip link set {ifb_name} down 2>/dev/null", check=False)
        sh(f"ip link del {ifb_name} 2>/dev/null", check=False)

def get_tc_stats(veth, ifb_name):
    stats = {}
    try:
        if veth:
            stats['veth'] = sh(f"tc -s qdisc show dev {veth}", check=False)
        if ifb_name:
            stats['ifb'] = sh(f"tc -s qdisc show dev {ifb_name}", check=False)
    except:
        pass
    return stats

# ==============================
# 5. ç‰©ç†æ­£ç¡®çš„ CPU ç›‘æ§
# ==============================

class PhysicalCPUMonitor:
    def __init__(self, container, nano_cpus_quota):
        self.container = container
        self.quota_cores = nano_cpus_quota / 1e9
        self.host_cores = os.cpu_count()
        self.prev = None
        self.data = []
        self.running = False
        self._df_result = None
        self.start_ns = 0
        self.end_ns = 0
        
    def _read_total_ns(self):
        """ç›´æ¥è·å– Cgroup åŸå§‹ç´¯è®¡å€¼ (çº³ç§’)"""
        try:
            stats = self.container.stats(stream=False)
            return stats['cpu_stats']['cpu_usage']['total_usage']
        except:
            return 0

    def sample(self):
        try:
            stats = self.container.stats(stream=False)
            cgroup_stats = stats.get('cpu_stats', {})
            cpu_usage = cgroup_stats.get('cpu_usage', {}).get('total_usage', 0)
            system_usage = cgroup_stats.get('system_cpu_usage', 0)
            throttling = cgroup_stats.get('throttling_data', {})
            
            if self.prev:
                cpu_delta = cpu_usage - self.prev['cpu_usage']
                sys_delta = system_usage - self.prev['system_usage']
                
                if sys_delta > 0:
                    cpu_percent = (cpu_delta / sys_delta) * self.host_cores / self.quota_cores * 100
                    cpu_percent = min(cpu_percent, self.quota_cores * 100)
                else:
                    cpu_percent = 0.0
                
                throttle_ratio = throttling.get('throttled_periods', 0) / max(throttling.get('periods', 0), 1)
                
                self.data.append({
                    'timestamp': time.time(),
                    'cpu_percent': round(cpu_percent, 2),
                    'throttle_ratio': round(throttle_ratio, 4),
                    'throttled_periods': throttling.get('throttled_periods', 0)
                })
            
            self.prev = {'cpu_usage': cpu_usage, 'system_usage': system_usage}
        except:
            pass
    
    def start(self):
        self.start_ns = self._read_total_ns()
        self.running = True
        def loop():
            while self.running:
                self.sample()
                time.sleep(0.1)
        self.thread = threading.Thread(target=loop, daemon=True)
        self.thread.start()
    
    def stop(self):
        if self._df_result is not None: 
            return self._df_result
        self.running = False
        if self.thread:
            self.thread.join(timeout=2)
        self.end_ns = self._read_total_ns()
        self._df_result = pd.DataFrame(self.data)
        return self._df_result

    def get_total_cpu_seconds(self):
        if self.end_ns and self.start_ns and self.end_ns > self.start_ns:
            return (self.end_ns - self.start_ns) / 1e9
        return 0.000001

@contextmanager
def physical_monitor(container, nano_cpus_quota):
    mon = PhysicalCPUMonitor(container, nano_cpus_quota)
    mon.start()
    try:
        yield mon
    finally:
        df = mon.stop()
        if not df.empty:
            ts = int(time.time())
            df.to_csv(f"micro_{container.id[:12]}_{ts}.csv", index=False)

# ==============================
# 6. ç½‘ç»œç¨³æ€æ£€æµ‹ï¼ˆSYN-onlyï¼‰
# ==============================

def wait_for_network_steady_syn_only(server_ip, port=80, timeout=10):
    samples = []
    start = time.time()
    
    while time.time() - start < timeout:
        try:
            t0 = time.perf_counter()
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(1)
            sock.connect((server_ip, port))
            t1 = time.perf_counter()
            
            sock.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER, struct.pack('ii', 1, 0))
            sock.close()
            
            samples.append((t1 - t0) * 1000)
            
            if len(samples) >= 3:
                mean_rtt = np.mean(samples[-3:])
                if mean_rtt > 0 and np.std(samples[-3:]) / mean_rtt < 0.3:
                    return True
        except:
            pass
        time.sleep(0.3)
    return False

# ==============================
# 7. åˆ†å±‚é‡‡æ ·å®éªŒç”Ÿæˆå™¨
# ==============================

from typing import List, Dict, Any

def get_adjusted_file_size(net_name, base_size):
    """
    æ ¹æ®ç½‘ç»œå¸¦å®½è°ƒæ•´æ–‡ä»¶å¤§å°ï¼Œé¿å…æ…¢ç½‘åœºæ™¯è¶…æ—¶ï¼š
    - IoT_Weak (2mbit): æœ€å¤§ 10MB
    - Edge_Normal (20mbit): æœ€å¤§ 50MB
    - Cloud_Fast (1gbit): ä¿æŒ 100MB
    """
    if "IoT" in net_name or "Weak" in net_name:
        return min(base_size, 10)
    elif "Edge" in net_name:
        return min(base_size, 50)
    else:
        return base_size

# def generate_hierarchical_experiments(NETWORK_SCENARIOS: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
#     experiments = []
#     print("ğŸ¯ Generating Hierarchical Experiments...")

#     for net in NETWORK_SCENARIOS:
#         adj_size = get_adjusted_file_size(net['name'], 100)

#         # ==========================
#         # 1ï¸âƒ£ Baseline Anchor
#         # ==========================
#         experiments.append({
#             "network_scenarios": {
#                 "name": f"{net['name']}_BASELINE", 
#                 "bw": "unlimited", 
#                 "delay": "0ms", 
#                 "loss": "0%"
#             },
#             "cpu_quota": 1.0,
#             "threads": 4,
#             "chunk_size": 1024*1024,
#             "file_size_mb": adj_size,
#             "priority": 1,
#             "nano_cpus": int(1e9),
#             "exp_type": "anchor_baseline",
#             "bandwidth_mbps": net.get('mbps', 1000)
#         })

#         # ==========================
#         # 2ï¸âƒ£ Anchor å…¨å› å­å®éªŒ
#         # ==========================
#         thread_list = [1, 2, 4] if "IoT" in net['name'] else [1, 2, 4, 8, 16]

#         for cpu in [0.5, 1.0, 2.0]:
#             for t in thread_list:
#                 for c in [256*1024, 1024*1024, 4*1024*1024]:
#                     experiments.append({
#                         "network_scenarios": net,
#                         "cpu_quota": cpu,
#                         "threads": t,
#                         "chunk_size": c,
#                         "file_size_mb": adj_size,
#                         "exp_type": "anchor",
#                         "nano_cpus": int(cpu * 1e9),
#                         "priority": 1,
#                         "bandwidth_mbps": net.get('mbps', 1000)
#                     })

#         # ==========================
#         # 3ï¸âƒ£ Probe Small æç«¯ç‚¹
#         # IoT å’Œ Cloud / å¼±ç½‘/é«˜é€Ÿç½‘å°æ–‡ä»¶æµ‹è¯•
#         # ==========================
#         for net_probe in [NETWORK_SCENARIOS[0], NETWORK_SCENARIOS[2]]:
#             for cpu in [0.5, 2.0]:
#                 for t in [1, 16]:
#                     for c in [256*1024, 1024*1024]:
#                         experiments.append({
#                             "network_scenarios": net_probe,
#                             "cpu_quota": cpu,
#                             "threads": t,
#                             "chunk_size": c,
#                             "file_size_mb": 10,
#                             "exp_type": "probe_small",
#                             "nano_cpus": int(cpu * 1e9),
#                             "priority": 2,
#                             "bandwidth_mbps": net_probe.get('mbps', 1000)
#                         })

#         # ==========================
#         # 4ï¸âƒ£ Probe Large æç«¯ç‚¹
#         # æ’é™¤ IoT, æµ‹å¤§æ–‡ä»¶+é«˜å¹¶å‘
#         # ==========================
#         for net_probe in [NETWORK_SCENARIOS[1], NETWORK_SCENARIOS[2]]:
#             for cpu in [0.5, 1.0, 2.0]:
#                 for t in [4, 8, 16]:
#                     for c in [1024*1024, 4*1024*1024]:
#                         experiments.append({
#                             "network_scenarios": net_probe,
#                             "cpu_quota": cpu,
#                             "threads": t,
#                             "chunk_size": c,
#                             "file_size_mb": 300,
#                             "exp_type": "probe_large",
#                             "nano_cpus": int(cpu * 1e9),
#                             "priority": 3,
#                             "bandwidth_mbps": net_probe.get('mbps', 1000)
#                         })

#     # ==========================
#     # 5ï¸âƒ£ æ’åºï¼Œä¿è¯ priority å…ˆè¡Œ
#     # ==========================
#     experiments.sort(key=lambda x: x['priority'])
#     print(f"âœ… Total Experiments Generated: {len(experiments)}")
#     return experiments
def generate_hierarchical_experiments(NETWORK_SCENARIOS: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆå±‚æ¬¡åŒ–å®éªŒé…ç½®
    æ ¸å¿ƒåŸåˆ™ï¼š
    1. åŒä¸€åœºæ™¯åŒä¸€å¼ Paretoå›¾å¿…é¡»ä½¿ç”¨ç›¸åŒæ–‡ä»¶å¤§å°
    2. IoTä¸“æ³¨æ‹‰å¼€CPUå·®è·ï¼ˆå› ä¸ºç½‘ç»œæ˜¯ç“¶é¢ˆï¼‰
    3. Edge/CloudæŒ‰æ–‡ä»¶å¤§å°åˆ†å±‚ï¼Œä¸æ··ç”¨
    """
    experiments = []
    print("ğŸ¯ Generating Hierarchical Experiments (Unified File Size per Plot)...")

    for net in NETWORK_SCENARIOS:
        # åŸºç¡€å¤§å°é™åˆ¶ (IoT=10, Edge=50, Cloud=100)
        adj_size = get_adjusted_file_size(net['name'], 100)

        # ==========================
        # 1ï¸âƒ£ Anchor å…¨å› å­æ‰«æï¼ˆæ¯ä¸ªåœºæ™¯çš„åŸºç¡€ï¼‰
        # ==========================
        thread_list = [1, 2, 4] if "IoT" in net['name'] else [1, 2, 4, 8, 16]
        
        for cpu in [0.5, 1.0, 2.0]:
            for t in thread_list:
                for c in [256*1024, 1024*1024, 4*1024*1024]:
                    experiments.append({
                        "network_scenarios": net,
                        "cpu_quota": cpu,
                        "threads": t,
                        "chunk_size": c,
                        "file_size_mb": adj_size,
                        "exp_type": "anchor",
                        "nano_cpus": int(cpu * 1e9),
                        "priority": 1,
                        "bandwidth_mbps": net.get('mbps', 1000)
                    })

        # ==========================
        # 2ï¸âƒ£ IoT ä¸“é¡¹ï¼šä½CPUé…ç½®ï¼ˆè¯•å›¾æ‹‰å¼€æˆæœ¬å·®è·ï¼‰
        # ==========================
        if "IoT" in net['name']:
            print(f"   + Injecting Low-CPU experiments for {net['name']}")
            # ç”¨æä½CPUé…é¢è¯•å›¾äº§ç”Ÿæ›´ä½çš„æˆæœ¬
            for cpu in [0.25, 0.125]:  
                for t in [1, 2]:
                    for c in [64*1024, 256*1024]:  # å°åˆ†ç‰‡æ›´é€‚åˆå¼±ç½‘
                        experiments.append({
                            "network_scenarios": net,
                            "cpu_quota": cpu,
                            "threads": t,
                            "chunk_size": c,
                            "file_size_mb": 10,  # ä¿æŒ10MBé¿å…è¶…æ—¶
                            "exp_type": "iot_low_cpu",
                            "nano_cpus": max(int(cpu * 1e9), 100000000),  # æœ€å°0.1æ ¸
                            "priority": 2,
                            "bandwidth_mbps": net.get('mbps', 2)
                        })

        # ==========================
        # 3ï¸âƒ£ Probe Smallï¼ˆ10MBï¼Œæ‰€æœ‰åœºæ™¯ï¼‰
        # ç›®çš„ï¼šå»ºç«‹"å°æ–‡ä»¶åŸºå‡†"ï¼Œè·¨åœºæ™¯å¯æ¯”
        # ==========================
        for cpu in [0.5, 2.0]:
            for t in [1, 16]:
                for c in [256*1024, 1024*1024]:
                    experiments.append({
                        "network_scenarios": net,
                        "cpu_quota": cpu,
                        "threads": t,
                        "chunk_size": c,
                        "file_size_mb": 10,
                        "exp_type": "probe_small",
                        "nano_cpus": int(cpu * 1e9),
                        "priority": 2,
                        "bandwidth_mbps": net.get('mbps', 1000)
                    })

        # ==========================
        # 4ï¸âƒ£ Edge/Cloud å¤§æ–‡ä»¶å®éªŒï¼ˆåˆ†å±‚è®¾è®¡ï¼‰
        # åŸåˆ™ï¼šåŒä¸€åœºæ™¯çš„Paretoå›¾åªç”¨ä¸€ç§æ–‡ä»¶å¤§å°
        # ==========================
        if "IoT" not in net['name']:
            
            # ç¡®å®šè¯¥åœºæ™¯çš„å¤§æ–‡ä»¶é…ç½®
            if "Edge" in net['name']:
                # Edge: 50MBï¼ˆæ ‡å‡†ï¼‰+ 300MBï¼ˆæç«¯ï¼‰
                large_sizes = [50, 300]
            else:  # Cloud
                # Cloud: 100MBï¼ˆæ ‡å‡†ï¼‰+ 300MBï¼ˆæç«¯ï¼‰
                large_sizes = [100, 300]
            
            for file_size in large_sizes:
                # 4.1 æ ‡å‡†å¤§æ–‡ä»¶é…ç½®ï¼ˆç±»ä¼¼åŸprobe_largeï¼‰
                thread_list_large = [4, 8, 16] if file_size == 300 else [2, 4, 8, 16]
                for cpu in [0.5, 1.0, 2.0]:
                    for t in thread_list_large:
                        for c in [1024*1024, 4*1024*1024]:
                            experiments.append({
                                "network_scenarios": net,
                                "cpu_quota": cpu,
                                "threads": t,
                                "chunk_size": c,
                                "file_size_mb": file_size,
                                "exp_type": "probe_large",
                                "nano_cpus": int(cpu * 1e9),
                                "priority": 3,
                                "bandwidth_mbps": net.get('mbps', 1000)
                            })
                
                # 4.2 Paretoå¹³æ»‘é‡‡æ ·ï¼ˆå¡«è¡¥ç©ºéš™ï¼Œä»…é’ˆå¯¹æ ‡å‡†å¤§å°ï¼‰
                # 300MBçš„ä¸åšå¹³æ»‘ï¼ˆæ—¶é—´æˆæœ¬å¤ªé«˜ï¼‰ï¼Œåªåš50MB/100MB
                if file_size == adj_size:
                    print(f"   + Injecting Pareto Smoothing for {net['name']} ({file_size}MB)")
                    # ä½¿ç”¨æ ‡å‡†åˆ†æ•°æ­¥é•¿ï¼Œé¿å…cgroupè°ƒåº¦é—®é¢˜
                    smooth_cpus = [0.75, 1.25, 1.5]  # 3/4, 5/4, 3/2æ ¸
                    smooth_threads = [3, 5, 6]  # å¡«è¡¥1-2-4-8-16çš„ç©ºéš™
                    
                    for cpu in smooth_cpus:
                        for t in smooth_threads:
                            experiments.append({
                                "network_scenarios": net,
                                "cpu_quota": cpu,
                                "threads": t,
                                "chunk_size": 1024*1024,  # æ ‡å‡†1MBåˆ†ç‰‡
                                "file_size_mb": file_size,
                                "exp_type": "pareto_smooth",
                                "nano_cpus": int(cpu * 1e9),
                                "priority": 4,  # ä½ä¼˜å…ˆçº§
                                "bandwidth_mbps": net.get('mbps', 1000)
                            })

    # ==========================
    # 5ï¸âƒ£ å»é‡ä¸æ’åº
    # ==========================
    unique_experiments = []
    seen = set()
    
    for exp in experiments:
        # ç”Ÿæˆå”¯ä¸€æŒ‡çº¹ï¼š(åœºæ™¯, CPU, çº¿ç¨‹, åˆ†ç‰‡, æ–‡ä»¶å¤§å°)
        sig = (
            exp['network_scenarios']['name'], 
            exp['cpu_quota'], 
            exp['threads'], 
            exp['chunk_size'], 
            exp['file_size_mb']
        )
        if sig not in seen:
            seen.add(sig)
            unique_experiments.append(exp)
        else:
            # è®°å½•å»é‡ä¿¡æ¯
            print(f"   [DEDUP] Skipped duplicate: {sig}")

    # æŒ‰ä¼˜å…ˆçº§æ’åº
    unique_experiments.sort(key=lambda x: x['priority'])
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š Experiment Distribution:")
    for exp_type in ['anchor', 'iot_low_cpu', 'probe_small', 'probe_large', 'pareto_smooth']:
        count = len([e for e in unique_experiments if e['exp_type'] == exp_type])
        if count > 0:
            print(f"   {exp_type:20s}: {count:3d}")
    
    print(f"\nâœ… Total Unique Experiments: {len(unique_experiments)}")
    return unique_experiments
# ==============================
# è¶…æ—¶è®¡ç®—å‡½æ•°
# ==============================
def calculate_timeout(file_size_mb, bandwidth_mbps, threads=1):
    if bandwidth_mbps <= 0: bandwidth_mbps = 1000
    base_time = (file_size_mb * 8) / bandwidth_mbps

    # å¼±ç½‘ 15x, å¼ºç½‘ 5x
    multiplier = 15 if bandwidth_mbps <= 5 else 5

    timeout = max(60, min(base_time * multiplier, 3600))
    print(f"[DEBUG] Timeout Calc: {file_size_mb}MB @ {bandwidth_mbps}Mbps x{multiplier} -> Limit {int(timeout)}s")
    return int(timeout)

# ==============================
# 8. å•æ¬¡å®éªŒæ‰§è¡Œ
# ==============================

def exec_with_timeout(container, command, timeout_sec):
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(container.exec_run, command)
        try:
            result = future.result(timeout=timeout_sec)
            return result.exit_code, result.output
        except concurrent.futures.TimeoutError:
            print(f"   âŒ Client timeout ({timeout_sec}s)")
            try:
                container.kill()
            except:
                pass
            return -1, b"TIMEOUT"
        except Exception as e:
            print(f"   âŒ Client error: {e}")
            return -1, b"ERROR"


def run_single_experiment(client, config, run_id):
    net_cfg = config["network_scenarios"]
    exp_type = config["exp_type"]
    file_size = config["file_size_mb"]
    is_baseline = "baseline" in exp_type or config.get("is_baseline", False)
    bandwidth_mbps = config.get("bandwidth_mbps", 1000)
    
    type_marker = {"anchor_baseline": "ğŸ“", "anchor": "âš“", 
                   "probe_small": "ğŸ§ª", "probe_large": "ğŸ”¬"}.get(exp_type, "â—‹")
    
    print(f"[{run_id:03d}] {type_marker} {net_cfg['name']:15s} | "
          f"F:{file_size}MB | CPU:{config['cpu_quota']:.1f} | T:{config['threads']:2d}")
    
    nuclear_cleanup_safe()
    
    server_c = None
    client_c = None
    veth = None
    ifb_name = None

    try:
        # 1. Server - âœ… å…³é”®ä¿®å¤ï¼šç¦ç”¨ sendfile ç¡®ä¿æµé‡ç»è¿‡ TC
        short_id = f"{run_id}_{int(time.time()*1000)%10000}"
        
        # sendfile off å¼ºåˆ¶ Nginx ä½¿ç”¨å¸¸è§„ read/writeï¼Œç¡®ä¿ç»è¿‡ TC netem
        nginx_conf = """events {
    worker_connections 1024;
}
http {
    sendfile off;
    tcp_nopush off;
    tcp_nodelay on;
    client_max_body_size 500M;
    proxy_read_timeout 600s;
    send_timeout 600s;
    server {
        listen 80;
        root /usr/share/nginx/html;
        location / {
            add_header Accept-Ranges bytes;
            add_header Cache-Control no-cache;
        }
    }
}"""
        
        with open("/tmp/nginx.conf", "w") as f:
            f.write(nginx_conf)
        
        server_c = client.containers.run(
            SERVER_IMAGE, name=f"srv_{short_id}", detach=True, network=NETWORK_NAME,
            volumes={DATA_FILE: {"bind": "/usr/share/nginx/html/data.bin", "mode": "ro"},
                     "/tmp/nginx.conf": {"bind": "/etc/nginx/nginx.conf", "mode": "ro"}},
            command="nginx -g 'daemon off;'"
        )
        
        # 2. VETH
        veth = get_veth_kernel_native(server_c.id)
        print(f"   ğŸŒ {veth}")
        
        # 3. TC
        if not is_baseline:
            try:
                ifb_name = setup_isolated_tc(veth, net_cfg['bw'], net_cfg['delay'], net_cfg['loss'], run_id)
            except RuntimeError as e:
                print(f"   [ERROR] TC setup failed: {e}")
                return None
        else:
            ifb_name = None
        
        # 4. Server IP
        server_inspect = client.api.inspect_container(server_c.id)
        networks = server_inspect["NetworkSettings"]["Networks"]
        if NETWORK_NAME not in networks:
            raise RuntimeError(f"Container not in {NETWORK_NAME}")
        server_ip = networks[NETWORK_NAME]["IPAddress"]
        
        # 5. Client
        script_path = os.path.join(os.path.dirname(__file__), "pareto_client.py")
        client_c = client.containers.run(
            CLIENT_IMAGE, name=f"cli_{short_id}", detach=True, network=NETWORK_NAME,
            nano_cpus=config["nano_cpus"], mem_limit="512m",
            volumes={script_path: {"bind": "/app/client.py", "mode": "ro"}},
            command="sleep 3600"
        )
        
        # 6. Execute
        with physical_monitor(client_c, config["nano_cpus"]) as mon:
            chunk_mb = config["chunk_size"] / (1024*1024)
            cmd = (f"python3 /app/client.py --url http://{server_ip}/data.bin "
                   f"--threads {config['threads']} --size {file_size} --buffer {chunk_mb}")
            
            t0 = time.perf_counter()
            timeout_val = calculate_timeout(file_size, bandwidth_mbps)
            exit_code, output = exec_with_timeout(client_c, cmd, timeout_val)
            duration = time.perf_counter() - t0
            
            output_str = output.decode("utf-8", errors="ignore")
            
            client_res = {}
            for line in reversed(output_str.strip().split("\n")):
                if line.startswith("{") and line.endswith("}"):
                    try: 
                        client_res = json.loads(line)
                        break
                    except: 
                        pass
            
            df_micro = mon.stop()
        
        if exit_code not in [0, 2]:
            print(f"   âŒ Client failed: {exit_code}, output: {output_str[:100]}")
            return None
        
        # 7. Stats
        total_cpu_s = mon.get_total_cpu_seconds()
        thr = client_res.get("throughput_mbps", 0)
        bytes_downloaded = client_res.get("bytes_downloaded", 0)
        
        # âœ… å…³é”®éªŒè¯ï¼šæ£€æŸ¥å®é™…ååé‡æ˜¯å¦ç¬¦åˆ TC é™åˆ¶ï¼ˆå…è®¸ 20% è¯¯å·®ï¼‰
        if not is_baseline and thr > 0:
            expected_max = bandwidth_mbps * 1.2  # å…è®¸ 20% burst
            if thr > expected_max:
                print(f"   [WARN] TC å¯èƒ½æœªç”Ÿæ•ˆ! æœŸæœ› <{expected_max:.1f}Mbps, å®é™… {thr:.1f}Mbps")
        
        efficiency = file_size / total_cpu_s if total_cpu_s > 1e-6 else 0
        
        result = {
            "run_id": run_id,
            "exp_type": exp_type,
            "file_size_mb": file_size,
            "scenario": net_cfg["name"],
            "cpu_quota": config["cpu_quota"],
            "threads": config["threads"],
            "chunk_kb": config["chunk_size"]//1024,
            "duration_s": round(duration, 3),
            "throughput_mbps": round(thr, 2),
            "cost_cpu_seconds": round(total_cpu_s, 6),
            "efficiency_mb_per_cpus": round(efficiency, 2),
            "bytes_downloaded": bytes_downloaded,
            "exit_code": exit_code
        }
        
        status = "ğŸ“ BASELINE" if is_baseline else "âœ…"
        print(f"   {status} Thr:{thr:6.1f}Mbps | Cost:{total_cpu_s:.4f}s | Time:{duration:.1f}s")
        
        return result
        
    except Exception as e:
        print(f"   âŒ {str(e)[:80]}")
        import traceback
        traceback.print_exc()
        return None
        
    finally:
        if veth or ifb_name:
            reset_isolated_tc(veth, ifb_name)
        if client_c:
            client_c.remove(force=True)
        if server_c:
            server_c.remove(force=True)
        nuclear_cleanup_safe()

# ==============================
# 9. ä¸»ç¨‹åº
# ==============================

def main():
    if os.geteuid() != 0:
        print("âŒ Must run as root")
        exit(1)
    
    if not sh("which nsenter"):
        print("âŒ Need util-linux (nsenter)")
        exit(1)
    
    client = docker.from_env()
    
    try:
        client.networks.create(NETWORK_NAME, driver="bridge")
    except:
        pass
    
    prepare_test_file(300)
    # âœ… æ­£ç¡®ä»£ç  (æŠŠå…¨å±€å˜é‡ä¼ è¿›å»)
    experiments = generate_hierarchical_experiments(NETWORK_SCENARIOS)
    
    print(f"\nğŸ“Š å®éªŒè®¾è®¡: {len(experiments)} æ¬¡å®éªŒ")
    print("=" * 70)
    
    output_csv = f"pareto_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    results = []
    
    for i, cfg in enumerate(experiments):
        res = run_single_experiment(client, cfg, i+1)
        if res:
            results.append(res)
            if len(results) % 5 == 0:
                pd.DataFrame(results[-5:]).to_csv(output_csv, mode="a", 
                                                  header=(len(results)<=5), index=False)
        
        if (i+1) % 10 == 0:
            print(f"\nğŸ“ˆ Progress: {i+1}/{len(experiments)}, Success: {len(results)}\n")
    
    if results:
        pd.DataFrame(results).to_csv(output_csv, mode="a", header=False, index=False)
    
    print(f"\nâœ… Completed: {len(results)}/{len(experiments)}")

if __name__ == "__main__":
    main()
    