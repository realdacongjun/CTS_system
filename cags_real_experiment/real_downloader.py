import requests
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import csv


class RealDownloader:
    def __init__(self, url, file_size, output_path):
        self.url = url
        self.total_size = file_size
        self.output_path = output_path
        self.lock = threading.Lock()
        self.progress_lock = threading.Lock()
        self.downloaded_bytes = 0
        
        # åˆå§‹åŒ–ç©ºæ–‡ä»¶
        with open(self.output_path, 'wb') as f:
            f.seek(self.total_size - 1)
            f.write(b'\0')

    def _fetch_chunk(self, start, end, chunk_id, log_file):
        """ä¸‹è½½å•ä¸ªåˆ†ç‰‡çš„å·¥ä½œå‡½æ•°"""
        headers = {'Range': f'bytes={start}-{end}'}
        try:
            t0 = time.time()
            resp = requests.get(self.url, headers=headers, timeout=10)
            
            if resp.status_code == 206:
                data = resp.content
                duration = time.time() - t0
                
                # å†™å…¥æ–‡ä»¶ (åŠ é”é˜²æ­¢å†²çª)
                with self.lock:
                    with open(self.output_path, 'r+b') as f:
                        f.seek(start)
                        f.write(data)
                
                # æ›´æ–°ä¸‹è½½è¿›åº¦
                with self.progress_lock:
                    self.downloaded_bytes += len(data)
                
                # è®°å½•å¾®è§‚æ•°æ®
                with open(log_file, 'a', newline='') as csvfile:
                    writer = csv.writer(csvfile)
                    inst_speed = (len(data)/1024/1024) / duration if duration > 0 else 0
                    writer.writerow([
                        time.time(),  # æ—¶é—´æˆ³
                        len(data)/1024,  # å½“å‰åˆ†ç‰‡å¤§å°KB
                        f"{inst_speed:.2f}",  # ç¬æ—¶é€Ÿåº¦MB/s
                        'SUCCESS'  # çŠ¶æ€
                    ])
                
                return len(data), duration, 'SUCCESS'
            else:
                # è®°å½•å¤±è´¥æƒ…å†µ
                with open(log_file, 'a', newline='') as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow([
                        time.time(),  # æ—¶é—´æˆ³
                        (end-start+1)/1024,  # åˆ†ç‰‡å¤§å°KB
                        0,  # ç¬æ—¶é€Ÿåº¦
                        'FAILED'  # çŠ¶æ€
                    ])
                return 0, 0, 'FAILED'
        except Exception as e:
            # è®°å½•è¶…æ—¶æƒ…å†µ
            with open(log_file, 'a', newline='') as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow([
                    time.time(),  # æ—¶é—´æˆ³
                    (end-start+1)/1024,  # åˆ†ç‰‡å¤§å°KB
                    0,  # ç¬æ—¶é€Ÿåº¦
                    'TIMEOUT'  # çŠ¶æ€
                ])
            return 0, 0, 'TIMEOUT'

    def download_with_chunks(self, initial_chunk_size, concurrency, correction_layer=None, log_file='microscopic_log.csv'):
        """
        æ‰§è¡Œåˆ†ç‰‡ä¸‹è½½
        :param correction_layer: ä¼ å…¥ CAGSCorrectionLayer å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä¸è°ƒæ•´
        :param log_file: å¾®è§‚æ•°æ®è®°å½•æ–‡ä»¶è·¯å¾„
        """
        cursor = 0
        self.downloaded_bytes = 0
        start_time = time.time()
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        with open(log_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Timestamp', 'Chunk_Size_KB', 'Speed_MB_s', 'Status'])  # å†™è¡¨å¤´

        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ | å¤§å°: {self.total_size/(1024*1024):.2f}MB | å¹¶å‘: {concurrency} | åˆå§‹å—: {initial_chunk_size/(1024*1024):.2f}MB")

        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = {}
            active_count = 0
            
            while cursor < self.total_size or futures:
                # 1. æäº¤æ–°ä»»åŠ¡ (å¦‚æœè¿˜æœ‰å‰©ä½™æ•°æ®ä¸”å¹¶å‘æœªæ»¡)
                while cursor < self.total_size and len(futures) < concurrency:
                    # åŠ¨æ€è·å–å½“å‰åˆ‡ç‰‡å¤§å°
                    if correction_layer:
                        current_chunk_size = correction_layer.current_size
                    else:
                        current_chunk_size = initial_chunk_size # é™æ€æ¨¡å¼
                    
                    end = min(cursor + current_chunk_size - 1, self.total_size - 1)
                    
                    # è®°å½•å†³ç­–æ—¥å¿—
                    log_data.append((time.time()-start_time, current_chunk_size))
                    
                    # æäº¤
                    future = executor.submit(self._fetch_chunk, cursor, end, 0, log_file)
                    futures[future] = (cursor, end)
                    cursor += current_chunk_size
                
                # 2. å¤„ç†å·²å®Œæˆçš„ä»»åŠ¡
                completed_futures = []
                for future in as_completed(list(futures.keys()), timeout=0.1):
                    size, duration, status = future.result()
                    start_pos, end_pos = futures[future]
                    completed_futures.append(future)
                    
                    if status == 'SUCCESS':
                        # æ‰“å°è¿›åº¦ (æ¯ 5MB æ‰“å°ä¸€æ¬¡ï¼Œé¿å…åˆ·å±)
                        with self.progress_lock:
                            progress = self.downloaded_bytes / self.total_size * 100
                        speed = (size/1024/1024) / duration if duration > 0 else 0
                        if self.downloaded_bytes % (5*1024*1024) < size:
                            print(f"\rğŸš€ è¿›åº¦: {progress:.1f}% | ç¬æ—¶é€Ÿåº¦: {speed:.2f} MB/s | å—: {size/1024:.0f}KB", end="")

                    # 3. åé¦ˆç»™ AIMD ä¿®æ­£å±‚
                    if correction_layer:
                        correction_layer.feedback(status, rtt_ms=duration*1000)
                
                # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
                for future in completed_futures:
                    del futures[future]
                
                # é¿å… CPU ç©ºè½¬
                time.sleep(0.01)

        total_time = time.time() - start_time
        avg_speed = (self.total_size / (1024*1024)) / total_time
        print(f"\nâœ… ä¸‹è½½å®Œæˆ | è€—æ—¶: {total_time:.2f}s | å¹³å‡é€Ÿåº¦: {avg_speed:.2f} MB/s")
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        actual_size = os.path.getsize(self.output_path)
        if actual_size == self.total_size:
            print("âœ… æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡!")
            return True
        else:
            print(f"âŒ æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥! æœŸæœ›: {self.total_size}, å®é™…: {actual_size}")
            return False