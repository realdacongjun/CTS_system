import requests
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import csv

class RealDownloader:
    def __init__(self, url, file_size, output_path):
        self.url = url
        self.total_size = file_size
        self.output_path = output_path
        self.lock = threading.Lock()
        self.progress_lock = threading.Lock()
        self.downloaded_bytes = 0
        
        # åˆå§‹åŒ–ç©ºæ–‡ä»¶
        with open(self.output_path, 'wb') as f:
            f.seek(self.total_size - 1)
            f.write(b'\0')

    # æ³¨æ„ï¼šç§»é™¤äº† log_file å‚æ•°ï¼Œå› ä¸ºæ—¥å¿—æ˜¯åœ¨ä¸»çº¿ç¨‹å†™çš„ï¼Œä¸éœ€è¦ä¼ è¿›å»
    def _fetch_chunk(self, start, end, chunk_id):
        """ä¸‹è½½å•ä¸ªåˆ†ç‰‡çš„å·¥ä½œå‡½æ•°"""
        headers = {'Range': f'bytes={start}-{end}'}
        try:
            t0 = time.time()
            resp = requests.get(self.url, headers=headers, timeout=10)
            
            if resp.status_code == 206:
                data = resp.content
                duration = time.time() - t0
                
                # å†™å…¥æ–‡ä»¶ (åŠ é”é˜²æ­¢å†²çª)
                with self.lock:
                    with open(self.output_path, 'r+b') as f:
                        f.seek(start)
                        f.write(data)
                
                # æ›´æ–°ä¸‹è½½è¿›åº¦
                with self.progress_lock:
                    self.downloaded_bytes += len(data)
                
                return len(data), duration, 'SUCCESS'
            else:
                return 0, 0, 'FAILED'
        except Exception as e:
            return 0, 0, 'TIMEOUT'

    def download_with_chunks(self, initial_chunk_size, concurrency, correction_layer=None, log_file=None):
        """
        æ‰§è¡Œåˆ†ç‰‡ä¸‹è½½
        :param correction_layer: ä¼ å…¥ CAGSCorrectionLayer å®ä¾‹
        :param log_file: CSVæ—¥å¿—æ–‡ä»¶è·¯å¾„
        """
        cursor = 0
        self.downloaded_bytes = 0
        start_time = time.time()
        
        # åˆå§‹åŒ–CSVæ—¥å¿—æ–‡ä»¶ (å†™è¡¨å¤´)
        if log_file:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            log_dir = os.path.dirname(log_file)
            if log_dir and not os.path.exists(log_dir):
                os.makedirs(log_dir)
                
            file_exists = os.path.isfile(log_file)
            with open(log_file, 'w', newline='') as f: # ä½¿ç”¨ 'w' è¦†ç›–æ—§æ—¥å¿—ï¼Œä¿è¯æ¯æ¬¡å®éªŒå¹²å‡€
                writer = csv.writer(f)
                writer.writerow(["Time_Offset_s", "Chunk_Size_KB", "Instant_Speed_MBs", "Status"])
        
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ | å¤§å°: {self.total_size/(1024*1024):.2f}MB | å¹¶å‘: {concurrency} | åˆå§‹å—: {initial_chunk_size/1024:.0f}KB")

        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = {}
            
            while cursor < self.total_size or futures:
                # 1. æäº¤æ–°ä»»åŠ¡
                while cursor < self.total_size and len(futures) < concurrency:
                    # åŠ¨æ€è·å–å½“å‰åˆ‡ç‰‡å¤§å°
                    if correction_layer:
                        current_chunk_size = correction_layer.current_size
                    else:
                        current_chunk_size = initial_chunk_size # é™æ€æ¨¡å¼
                    
                    end = min(cursor + current_chunk_size - 1, self.total_size - 1)
                    
                    # æäº¤ä»»åŠ¡
                    future = executor.submit(self._fetch_chunk, cursor, end, 0)
                    # å°† chunk_size å­˜å…¥ futures å­—å…¸ï¼Œæ–¹ä¾¿åç»­è®°å½•æ—¥å¿—
                    futures[future] = (cursor, end, current_chunk_size)
                    cursor += current_chunk_size
                
                # 2. å¤„ç†å·²å®Œæˆçš„ä»»åŠ¡
                completed_futures = []
                for future in as_completed(list(futures.keys()), timeout=0.05): # ç¼©çŸ­ timeout æé«˜å“åº”é€Ÿåº¦
                    size, duration, status = future.result()
                    start_pos, end_pos, chunk_size_used = futures[future]
                    completed_futures.append(future)
                    
                    # --- å¾®è§‚æ•°æ®è®°å½•æ ¸å¿ƒåŒºåŸŸ ---
                    speed = (size/1024/1024) / duration if duration > 0 else 0
                    time_offset = time.time() - start_time
                    
                    if log_file:
                        with open(log_file, 'a', newline='') as f:
                            writer = csv.writer(f)
                            writer.writerow([
                                f"{time_offset:.2f}",
                                f"{chunk_size_used/1024:.0f}", # è®°å½• KB
                                f"{speed:.2f}",
                                status
                            ])
                    # ---------------------------

                    if status == 'SUCCESS':
                        # æ‰“å°è¿›åº¦
                        with self.progress_lock:
                            if self.downloaded_bytes % (5*1024*1024) < size:
                                progress = self.downloaded_bytes / self.total_size * 100
                                print(f"\rğŸš€ è¿›åº¦: {progress:.1f}% | é€Ÿåº¦: {speed:.2f} MB/s | å—: {chunk_size_used/1024:.0f}KB", end="")
                    
                    # 3. åé¦ˆç»™ AIMD ä¿®æ­£å±‚ (é—­ç¯æ§åˆ¶)
                    if correction_layer:
                        correction_layer.feedback(status, rtt_ms=duration*1000)
                
                # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
                for future in completed_futures:
                    del futures[future]
                
                # é¿å… CPU ç©ºè½¬
                if not completed_futures:
                    time.sleep(0.01)

        total_time = time.time() - start_time
        avg_speed = (self.total_size / (1024*1024)) / total_time
        print(f"\nâœ… ä¸‹è½½å®Œæˆ | è€—æ—¶: {total_time:.2f}s | å¹³å‡é€Ÿåº¦: {avg_speed:.2f} MB/s")
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        if os.path.exists(self.output_path):
            actual_size = os.path.getsize(self.output_path)
            if actual_size == self.total_size:
                return True
            else:
                print(f"âŒ å¤§å°ä¸åŒ¹é…: {actual_size} != {self.total_size}")
                return False
        return False