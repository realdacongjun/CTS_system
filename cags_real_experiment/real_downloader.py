import requests
import time
import os
from concurrent.futures import ThreadPoolExecutor
import threading
import csv

class RealDownloader:
    """
    çœŸå®ç¯å¢ƒå¹¶å‘ä¸‹è½½å™¨ (é˜²å´©æºƒæœ€ç»ˆç‰ˆ)
    """
    def __init__(self, url, file_size, output_path):
        self.url = url
        self.total_size = file_size
        self.output_path = output_path
        self.lock = threading.Lock()
        self.progress_lock = threading.Lock()
        self.downloaded_bytes = 0
        
        # é¢„åˆ†é…ç£ç›˜ç©ºé—´
        print(f"[Downloader] æ­£åœ¨é¢„åˆ†é…ç£ç›˜ç©ºé—´: {file_size/(1024*1024):.2f} MB")
        try:
            with open(self.output_path, 'wb') as f:
                f.seek(self.total_size - 1)
                f.write(b'\0')
        except Exception as e:
            print(f"[Downloader] âš ï¸ é¢„åˆ†é…ç©ºé—´å¤±è´¥: {e}")

    def _fetch_chunk(self, start, end, chunk_id, log_file):
        headers = {'Range': f'bytes={start}-{end}'}
        try:
            t0 = time.time()
            # timeout=15 é€‚åº”ææ…¢çš„å¼±ç½‘ç¯å¢ƒ (1.5s RTT)
            resp = requests.get(self.url, headers=headers, timeout=15)
            
            if resp.status_code == 206:
                data = resp.content
                duration = time.time() - t0
                with self.lock:
                    with open(self.output_path, 'r+b') as f:
                        f.seek(start)
                        f.write(data)
                with self.progress_lock:
                    self.downloaded_bytes += len(data)
                self._log_micro_data(log_file, time.time(), len(data), duration, 'SUCCESS')
                return len(data), duration, 'SUCCESS'
            else:
                return 0, 0, 'FAILED'
        except:
            # ä»»ä½•é”™è¯¯éƒ½åªè®°å½•ï¼Œä¸æŠ›å‡ºå¼‚å¸¸
            self._log_micro_data(log_file, time.time(), (end-start+1), 0, 'TIMEOUT')
            return 0, 0, 'TIMEOUT'

    def _log_micro_data(self, log_file, ts, size, duration, status):
        try:
            with open(log_file, 'a', newline='') as csvfile:
                inst_speed = (size/1024/1024) / duration if duration > 0 else 0
                csv.writer(csvfile).writerow([ts, size/1024, f"{inst_speed:.2f}", status])
        except:
            pass

    def download_with_chunks(self, initial_chunk_size, concurrency, correction_layer=None, log_file='microscopic_log.csv'):
        cursor = 0
        self.downloaded_bytes = 0
        start_time = time.time()
        
        with open(log_file, 'w', newline='') as f:
            csv.writer(f).writerow(['Timestamp', 'Chunk_Size_KB', 'Speed_MB_s', 'Status'])

        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ | ç›®æ ‡: {self.total_size/(1024*1024):.2f}MB | å¹¶å‘: {concurrency}")

        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = {}
            while cursor < self.total_size or futures:
                # 1. æäº¤ä»»åŠ¡
                while cursor < self.total_size and len(futures) < concurrency:
                    current_chunk_size = correction_layer.current_size if correction_layer else initial_chunk_size
                    end = min(cursor + current_chunk_size - 1, self.total_size - 1)
                    future = executor.submit(self._fetch_chunk, cursor, end, 0, log_file)
                    futures[future] = (cursor, end)
                    cursor += current_chunk_size
                
                # 2. ã€æ ¸å¿ƒä¿®å¤ã€‘è½®è¯¢çŠ¶æ€ (å»æ‰ä¼šå¯¼è‡´å´©æºƒçš„ as_completed)
                done_list = []
                for f in list(futures.keys()):
                    if f.done():
                        done_list.append(f)
                        try:
                            size, duration, status = f.result()
                            if status == 'SUCCESS':
                                progress = self.downloaded_bytes / self.total_size * 100
                                speed = (size/1024/1024) / duration if duration > 0 else 0
                                # å¼ºåˆ¶åˆ·æ–°æ˜¾ç¤º
                                print(f"\rğŸš€ è¿›åº¦: {progress:.1f}% | é€Ÿåº¦: {speed:.2f} MB/s ", end="", flush=True)
                            if correction_layer:
                                correction_layer.feedback(status, duration*1000)
                        except:
                            pass
                
                for f in done_list:
                    del futures[f]
                
                time.sleep(0.05) # ç¨å¾®ç­‰å¾…ï¼Œé˜²æ­¢CPUç©ºè½¬

        total_time = time.time() - start_time
        print(f"\nâœ… ä¸‹è½½æµç¨‹ç»“æŸ | è€—æ—¶: {total_time:.2f}s")
        return os.path.getsize(self.output_path) == self.total_size, total_time