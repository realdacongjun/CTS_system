import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import os
import sys
import random

# === å¼•å…¥è°ƒåº¦å™¨ (ç¡®ä¿ cags_scheduler.py å·²ç»æ˜¯æœ€æ–°ç‰ˆ) ===
from cags_scheduler import CAGSStrategyLayer, CAGSCorrectionLayer

# ==============================================================================
# 1. æ¨¡å‹å®šä¹‰å‡çº§ (é€‚é… EDL è¯æ®æ·±åº¦å­¦ä¹ )
# ==============================================================================
class FeatureTokenizer(nn.Module):
    def __init__(self, num_features, embed_dim):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
        self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
        nn.init.xavier_uniform_(self.weights)
        nn.init.zeros_(self.biases)

    def forward(self, x):
        return x.unsqueeze(-1) * self.weights + self.biases

class TransformerTower(nn.Module):
    def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
        super().__init__()
        self.tokenizer = FeatureTokenizer(num_features, embed_dim)
        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
            batch_first=True, dropout=0.1
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

    def forward(self, x):
        tokens = self.tokenizer(x)
        batch_size = x.shape[0]
        cls_tokens = self.cls_token.expand(batch_size, -1, -1)
        tokens = torch.cat((cls_tokens, tokens), dim=1)
        out = self.transformer(tokens)
        return out[:, 0, :]

class CTSDualTowerModel(nn.Module):
    def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
        super().__init__()
        self.client_tower = TransformerTower(client_feats, embed_dim)
        self.image_tower = TransformerTower(image_feats, embed_dim)
        self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
        fusion_input_dim = embed_dim * 3 
        self.hidden = nn.Sequential(
            nn.Linear(fusion_input_dim, 64),
            nn.LayerNorm(64),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        # [ä¿®æ”¹ç‚¹ 1] è¾“å‡ºå±‚æ”¹ä¸º 4 ä¸ªç¥ç»å…ƒ (Gamma, v, Alpha, Beta)
        self.head = nn.Linear(64, 4) 

    def forward(self, cx, ix, ax):
        c_vec = self.client_tower(cx)
        i_vec = self.image_tower(ix)
        a_vec = self.algo_embed(ax)
        combined = torch.cat([c_vec, i_vec, a_vec], dim=1)
        hidden = self.hidden(combined)
        out = self.head(hidden)
        
        # [ä¿®æ”¹ç‚¹ 2] æ–½åŠ æ•°å­¦çº¦æŸ (Softplus) ä¿è¯å‚æ•° > 0
        gamma = out[:, 0]
        v     = F.softplus(out[:, 1]) + 1e-6
        alpha = F.softplus(out[:, 2]) + 1.0 + 1e-6
        beta  = F.softplus(out[:, 3]) + 1e-6
        
        return torch.stack([gamma, v, alpha, beta], dim=1)

# ==============================================================================
# 2. åŸºäºéšæœºè¿‡ç¨‹çš„ç½‘ç»œç¯å¢ƒå»ºæ¨¡
# ==============================================================================
def generate_real_world_trace(steps=20): # ç¨å¾®å¢åŠ ç‚¹æ­¥æ•°çœ‹æ•ˆæœ
    """ç”Ÿæˆæ¨¡æ‹ŸçœŸå® 4G/5G å¼±ç½‘ç¯å¢ƒçš„å¸¦å®½è½¨è¿¹"""
    trace = []
    state = "HIGH" 
    for i in range(steps):
        if state == "HIGH":
            bw = random.uniform(8.0, 12.0)
            if random.random() < 0.2: state = "DROP"
        elif state == "DROP":
            bw = random.uniform(2.0, 5.0)
            state = "LOW"
        elif state == "LOW":
            bw = random.gammavariate(1, 0.5)
            bw = max(0.2, min(bw, 1.5)) # ç¨å¾®æé«˜ä¸‹é™é˜²æ­¢å®Œå…¨æ­»æ‰
            if random.random() < 0.15: state = "RECOVERY"
        elif state == "RECOVERY":
            bw = random.uniform(3.0, 7.0)
            state = "HIGH"
        trace.append(round(bw, 2))
    return trace

# ==============================================================================
# 3. æ ¸å¿ƒå®éªŒé€»è¾‘ (Uncertainty-Aware)
# ==============================================================================
def run_ai_driven_experiment():
    print("ğŸš€ å¯åŠ¨çœŸÂ·AIé©±åŠ¨ (å«ä¸ç¡®å®šæ€§æ„ŸçŸ¥) çš„å¯¹æ¯”ä»¿çœŸå®éªŒ...")

    # --- A. åŠ è½½æ¨¡å‹ ---
    device = torch.device("cpu")
    possible_paths = ["cts_best_model_full.pth", "../ml_training/modeling/cts_best_model_full.pth", "ml_training/modeling/cts_edl_model_best.pth"]
    model_path = next((p for p in possible_paths if os.path.exists(p)), None)
    
    # åˆå§‹åŒ–ä¸€ä¸ª Mock çš„ä¸ç¡®å®šæ€§ï¼Œä»¥é˜²æ¨¡å‹åŠ è½½å¤±è´¥
    ai_uncertainty = 0.5 
    cags_initial_size = 4 * 1024 * 1024

    if model_path:
        print(f"ğŸ“¥ å°è¯•åŠ è½½ AI æ¨¡å‹: {model_path}")
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å°è¯•å®ä¾‹åŒ–æ–°çš„ EDL æ¨¡å‹
        model = CTSDualTowerModel(client_feats=4, image_feats=5, num_algos=10).to(device)
        try:
            # å°è¯•åŠ è½½æƒé‡
            state_dict = torch.load(model_path, map_location=device)
            # ç®€å•çš„æƒé‡å½¢çŠ¶æ£€æŸ¥ï¼Œé˜²æ­¢æ—§æ¨¡å‹(è¾“å‡º1)åŠ è½½åˆ°æ–°æ¨¡å‹(è¾“å‡º4)æŠ¥é”™
            if state_dict['head.weight'].shape[0] == 4:
                model.load_state_dict(state_dict)
                model.eval()
                print("âœ… EDL æ¨¡å‹åŠ è½½æˆåŠŸï¼å¯ç”¨ä¸ç¡®å®šæ€§æ¨ç†ã€‚")
                
                # --- B. AI æ¨ç† (è®¡ç®— Uncertainty) ---
                print("ğŸ¤– AI æ­£åœ¨åˆ†æå½“å‰ç¯å¢ƒçš„ä¸ç¡®å®šæ€§...")
                # æ„é€ ä¸€ä¸ªã€é«˜é£é™©åœºæ™¯ã€‘
                client_vec = torch.FloatTensor([[2.0, 0.8, 500.0, 1024.0]]) 
                image_vec = torch.FloatTensor([[1500.0, 0.8, 0.1, 5.0, 0.1]])
                algo_vec = torch.LongTensor([0])
                
                with torch.no_grad():
                    preds = model(client_vec, image_vec, algo_vec)
                    gamma, v, alpha, beta = preds[0]
                    
                    # [ä¿®æ”¹ç‚¹ 3] è®¡ç®—ä¸ç¡®å®šæ€§ (Aleatoric + Epistemic)
                    # U = beta / (v * (alpha - 1))
                    uncertainty_val = beta / (v * (alpha - 1))
                    pred_time = torch.expm1(gamma).item()
                    
                    ai_uncertainty = uncertainty_val.item()
                    # å½’ä¸€åŒ–ä¸€ä¸‹ï¼Œé˜²æ­¢æ•°å€¼å¤ªå¤§
                    ai_uncertainty = min(1.0, max(0.0, ai_uncertainty / 10.0)) 
                    
                    print(f"   ğŸ‘‰ é¢„æµ‹è€—æ—¶: {pred_time:.1f}s")
                    print(f"   ğŸ‘‰ æ¨¡å‹ä¸ç¡®å®šæ€§ (U): {ai_uncertainty:.4f}")
            else:
                print("âš ï¸ æ£€æµ‹åˆ°æ—§æ¨¡å‹æƒé‡ (è¾“å‡ºç»´åº¦ä¸åŒ¹é…)ã€‚")
                print("ğŸ”„ åˆ‡æ¢åˆ°ã€æ¨¡æ‹Ÿæ¨¡å¼ã€‘ï¼šæ¨¡æ‹Ÿä¸€ä¸ªé«˜ä¸ç¡®å®šæ€§åœºæ™¯ã€‚")
                ai_uncertainty = 0.8 # æ¨¡æ‹Ÿé«˜ä¸ç¡®å®šæ€§
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹åŠ è½½å‡ºé”™: {e}")
            print("ğŸ”„ åˆ‡æ¢åˆ°ã€æ¨¡æ‹Ÿæ¨¡å¼ã€‘ã€‚")
            ai_uncertainty = 0.8
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ã€‚ä½¿ç”¨æ¨¡æ‹Ÿå€¼ã€‚")
        ai_uncertainty = 0.8

    # --- C. è°ƒç”¨æˆ˜ç•¥å±‚ (ä¼ é€’ Uncertainty) ---
    strategy = CAGSStrategyLayer()
    
    # æ¨¡æ‹Ÿé¢„æµ‹çš„ä¸¢åŒ…ç‡ (å¦‚æœå¸¦å®½ä½ï¼Œä¸¢åŒ…ç‡é«˜)
    pred_loss = 0.05 
    
    # [ä¿®æ”¹ç‚¹ 4] ä¼ å…¥ model_uncertainty
    # å¦‚æœ ai_uncertainty å¾ˆé«˜ (0.8)ï¼ŒStrategyLayer é‡Œçš„ risk_amplifier ä¼šå¾ˆå¤§
    # ä»è€Œå¯¼è‡´ Cost å‰§å¢ï¼Œç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©å°åˆ‡ç‰‡
    best_config, _ = strategy.optimize(2.0, pred_loss, 0.8, model_uncertainty=ai_uncertainty) 
    
    cags_initial_size = best_config[0]
    
    print(f"ğŸ§  æˆ˜ç•¥å±‚å†³ç­–:")
    print(f"   ğŸ‘‰ è¾“å…¥ä¸ç¡®å®šæ€§: {ai_uncertainty:.4f}")
    print(f"   ğŸ‘‰ é£é™©æ”¾å¤§å› å­: {1.0 + 5.0 * ai_uncertainty:.2f}x") # å‡è®¾ weight=5.0
    print(f"   ğŸ‘‰ æœ€ç»ˆå†³å®šåˆå§‹åˆ‡ç‰‡: {cags_initial_size/1024} KB")

    # --- D. å¼€å§‹è·‘åˆ†å¯¹æ¯” (Trace-driven) ---
    bandwidth_trace = generate_real_world_trace(20)
    print(f"ğŸ“Š åŠ¨æ€å¸¦å®½è½¨è¿¹ç”Ÿæˆå®Œæ¯• (é•¿åº¦ {len(bandwidth_trace)})")
    
    docker_tput = []
    cags_tput = []
    
    # åˆå§‹åŒ–ä¿®æ­£å±‚
    correction = CAGSCorrectionLayer(initial_chunk_size=cags_initial_size)
    
    for bw in bandwidth_trace:
        # === 1. Native Docker (å¤§åŒ… + RTO) ===
        # å‡è®¾ 4MB å¤§åŒ…
        time_cost = 4.0 / max(0.01, bw)
        if time_cost > 2.0: 
            docker_tput.append(0.1) # æ‹¥å¡å´©æºƒ
        else:
            docker_tput.append(bw * 0.9)

        # === 2. AI-CAGS (æ™ºèƒ½è°ƒæ•´) ===
        # è·å–å½“å‰åˆ‡ç‰‡å¤§å° (MB)
        curr_mb = correction.current_size / (1024*1024)
        est_time = curr_mb / max(0.01, bw)
        
        status = 'TIMEOUT' if est_time > 1.5 else 'SUCCESS' # ç¨å¾®ä¸¥æ ¼ä¸€ç‚¹çš„è¶…æ—¶åˆ¤å®š
        
        # ä¿®æ­£å±‚ä»‹å…¥
        correction.feedback(status, rtt_ms=100)
        
        if est_time > 2.0:
             # å¦‚æœçœŸçš„éå¸¸éå¸¸æ…¢ï¼Œååä¹Ÿä¼šå—å½±å“ï¼Œä½†ä¸è‡³äºå½’é›¶
             cags_tput.append(bw * 0.6)
        else:
             # æ­£å¸¸æƒ…å†µï¼Œäº«å—å¹¶å‘æ”¶ç›Š (è¿™é‡Œç®€åŒ–æ¨¡æ‹Ÿ)
             cags_tput.append(min(bw * 0.98, bw)) # è´´è¿‘ä¸Šé™

    # --- E. ç”»å›¾ ---
    plt.figure(figsize=(10, 6))
    plt.plot(bandwidth_trace, 'k--', alpha=0.3, label='Physical Bandwidth (Limit)', linewidth=1)
    plt.plot(docker_tput, 'r-o', linewidth=2, label='Native Docker (Static 4MB)')
    plt.plot(cags_tput, 'g-^', linewidth=2, label='CTS (Uncertainty-Aware CAGS)')
    
    plt.title(f'Performance: Uncertainty-Aware Scheduling (U={ai_uncertainty:.2f})', fontsize=14)
    plt.ylabel('Goodput (Mbps)')
    plt.xlabel('Time Step')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    output_file = "exp_uncertainty_result.png"
    plt.savefig(output_file)
    print(f"\nâœ… å®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    print("ğŸ’¡ è§‚å¯Ÿé‡ç‚¹: ç»¿çº¿åº”è¯¥åœ¨å¼±ç½‘åŒºé—´ä¾ç„¶åšæŒºï¼Œå› ä¸ºé«˜ä¸ç¡®å®šæ€§è®©å®ƒé€‰æ‹©äº†å°åˆ‡ç‰‡ã€‚")

if __name__ == "__main__":
    run_ai_driven_experiment()