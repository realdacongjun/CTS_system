import os
import json
import math
import shutil
import tarfile
import docker
import time
import pandas as pd
from collections import Counter
from tqdm import tqdm

# ==============================================================================
# 1. é…ç½®åŒºåŸŸï¼šä½ çš„ç›®æ ‡é•œåƒåˆ—è¡¨
# ==============================================================================
TARGET_IMAGES = [
    'quay.io/centos/centos:stream9', 
    'fedora:latest', 
    'ubuntu:latest',
    'mongo:latest', 
    'mysql:latest', 
    'postgres:latest',
    'rust:latest', 
    'ruby:latest', 
    'python:latest',
    'nginx:latest', 
    'httpd:latest', 
    'rabbitmq:latest', 
    'wordpress:latest', 
    'nextcloud:latest',
    'gradle:latest', 
    'node:latest'
]

# ä¸´æ—¶å·¥ä½œç›®å½• (ç”¨å®Œä¼šåˆ é™¤)
TEMP_DIR = "temp_feature_extraction"
# é‡‡æ ·å¤§å° (è¯»å–æ¯å±‚çš„å‰ 10MB è¿›è¡Œåˆ†æï¼Œè¶³ä»¥ä»£è¡¨æ•´ä½“)
SAMPLE_SIZE_BYTES = 10 * 1024 * 1024 

class FeatureExtractor:
    def __init__(self):
        try:
            self.client = docker.from_env()
            print("âœ… Docker Client è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Docker è¿æ¥å¤±è´¥ï¼Œè¯·ç¡®ä¿ docker æœåŠ¡å·²å¯åŠ¨: {e}")
            exit(1)
        
        # ç¡®ä¿ç¯å¢ƒå¹²å‡€
        if os.path.exists(TEMP_DIR):
            shutil.rmtree(TEMP_DIR)
        os.makedirs(TEMP_DIR)

    def process_all(self, image_list):
        results = []
        print(f"ğŸš€ å¼€å§‹åˆ†æ {len(image_list)} ä¸ªé•œåƒçš„ç‰©ç†ç‰¹å¾...")
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
        for img in tqdm(image_list, desc="Processing Images"):
            try:
                # 1. ç¡®ä¿é•œåƒå­˜åœ¨
                self._ensure_image(img)
                # 2. æå–ç‰¹å¾
                features = self._analyze_image(img)
                if features:
                    results.append(features)
            except Exception as e:
                print(f"\nâŒ å¤„ç† {img} å¤±è´¥: {e}")
        
        # 3. ä¿å­˜ç»“æœ
        self._save_results(results)

    def _ensure_image(self, image_name):
        """å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œå…ˆæ‹‰å–"""
        try:
            self.client.images.get(image_name)
        except docker.errors.ImageNotFound:
            print(f"\nâ¬‡ï¸ æ­£åœ¨æ‹‰å– {image_name} (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
            self.client.images.pull(image_name)

    def _analyze_image(self, image_name):
        """æ ¸å¿ƒåˆ†æé€»è¾‘"""
        clean_name = image_name.replace("/", "_").replace(":", "_")
        extract_path = os.path.join(TEMP_DIR, clean_name)
        os.makedirs(extract_path, exist_ok=True)
        
        try:
            # A. å¯¼å‡ºé•œåƒ (docker save)
            img_obj = self.client.images.get(image_name)
            tar_stream = img_obj.save()
            tar_file = os.path.join(extract_path, "image.tar")
            
            with open(tar_file, 'wb') as f:
                for chunk in tar_stream:
                    f.write(chunk)
            
            # B. è§£å‹
            with tarfile.open(tar_file) as tar:
                tar.extractall(path=extract_path)
            os.remove(tar_file) # çœç©ºé—´

            # C. è§£æ Manifest æ‰¾ Layers
            manifest_path = os.path.join(extract_path, "manifest.json")
            if not os.path.exists(manifest_path):
                return None
            
            with open(manifest_path) as f:
                manifest = json.load(f)[0]
            
            # D. é€å±‚åˆ†æ
            layer_stats = []
            blobs_dir = os.path.join(extract_path, "blobs", "sha256")
            
            for layer_file in manifest.get('Layers', []):
                # å…¼å®¹ä¸åŒçš„å­˜å‚¨è·¯å¾„ç»“æ„
                layer_path = self._find_layer(extract_path, blobs_dir, layer_file)
                if layer_path:
                    stat = self._compute_file_features(layer_path)
                    layer_stats.append(stat)

            # E. èšåˆç‰¹å¾ (Weighted Average)
            return self._aggregate_features(image_name, layer_stats)

        finally:
            # æ¸…ç†ï¼Œé˜²æ­¢ç£ç›˜çˆ†æ»¡ (Rust è§£å‹å‡ºæ¥å¾ˆå¤§)
            if os.path.exists(extract_path):
                shutil.rmtree(extract_path)

    def _find_layer(self, root, blobs, filename):
        p1 = os.path.join(root, filename)
        if os.path.exists(p1): return p1
        p2 = os.path.join(blobs, os.path.basename(filename))
        if os.path.exists(p2): return p2
        return None

    def _compute_file_features(self, filepath):
        """è®¡ç®—å•ä¸ªæ–‡ä»¶çš„ç‰©ç†å±æ€§"""
        size = os.path.getsize(filepath)
        if size == 0:
            return {'size': 0, 'entropy': 0, 'text_ratio': 0, 'zero_ratio': 0}

        # é‡‡æ ·è¯»å–
        read_len = min(size, SAMPLE_SIZE_BYTES)
        with open(filepath, 'rb') as f:
            data = f.read(read_len)
        
        # 1. ç†µ (Entropy)
        entropy = 0
        if data:
            counts = Counter(data)
            total = len(data)
            for count in counts.values():
                p = count / total
                entropy -= p * math.log2(p)
            entropy /= 8.0 # å½’ä¸€åŒ– 0-1

        # 2. æ–‡æœ¬ç‡ (Text Ratio)
        text_chars = sum(1 for b in data if 32 <= b <= 126 or b in (9, 10, 13))
        text_ratio = text_chars / len(data) if data else 0

        # 3. ç¨€ç–ç‡ (Zero Ratio) - å¾ˆå¤šäºŒè¿›åˆ¶æ–‡ä»¶åŒ…å«å¤§é‡ç©ºæ´
        zero_count = data.count(b'\x00')
        zero_ratio = zero_count / len(data) if data else 0

        return {
            'size': size,
            'entropy': entropy,
            'text_ratio': text_ratio,
            'zero_ratio': zero_ratio
        }

    def _aggregate_features(self, image_name, stats):
        """åŠ æƒèšåˆï¼šå¤§å±‚çš„ç‰¹å¾å†³å®šæ•´ä½“ç‰¹å¾"""
        total_size = sum(s['size'] for s in stats)
        if total_size == 0: return None

        # åŠ æƒå¹³å‡
        avg_entropy = sum(s['entropy'] * s['size'] for s in stats) / total_size
        avg_text = sum(s['text_ratio'] * s['size'] for s in stats) / total_size
        avg_zero = sum(s['zero_ratio'] * s['size'] for s in stats) / total_size

        return {
            "image_name": image_name,
            "total_size_mb": round(total_size / (1024**2), 2),
            "layer_count": len(stats),
            "avg_layer_entropy": round(avg_entropy, 4),
            "text_ratio": round(avg_text, 4),
            "zero_ratio": round(avg_zero, 4)  # ç¨€ç–åº¦
        }

    def _save_results(self, results):
        df = pd.DataFrame(results)
        print("\n" + "="*50)
        print("ğŸ“Š ç‰¹å¾åˆ†æç»“æœé¢„è§ˆ:")
        print("="*50)
        print(df.to_string())
        
        # ä¿å­˜ä¸º CSVï¼Œæ–¹ä¾¿åç»­ Dataset ç±»è¯»å–
        csv_path = "image_features_database.csv"
        df.to_csv(csv_path, index=False)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {os.path.abspath(csv_path)}")
        print("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šåœ¨è®­ç»ƒä»£ç ä¸­åŠ è½½æ­¤æ–‡ä»¶ï¼Œä½¿ç”¨ 'pd.merge' å°†å…¶åˆå¹¶åˆ° experiments è®°å½•ä¸­ã€‚")

if __name__ == "__main__":
    extractor = FeatureExtractor()
    extractor.process_all(TARGET_IMAGES)