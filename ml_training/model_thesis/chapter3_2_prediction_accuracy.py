import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import spearmanr, norm
from scipy.stats import mstats
import pickle
import random
import math
import platform
import matplotlib
from collections import Counter
import json
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# ==============================================================================
# 0. åŸºç¡€é…ç½®
# ==============================================================================
system_name = platform.system()
if system_name == 'Windows':
    font_list = ['Microsoft YaHei', 'SimHei']
elif system_name == 'Darwin':
    font_list = ['Heiti TC', 'PingFang HK']
else:
    font_list = ['WenQuanYi Micro Hei', 'Droid Sans Fallback']
    
matplotlib.rcParams['font.sans-serif'] = font_list
matplotlib.rcParams['axes.unicode_minus'] = False 

def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

set_seed(42)

# ==============================================================================
# 1. è¶…å‚æ•°é…ç½®
# ==============================================================================
CONFIG = {
    "lr": 0.0003,
    "weight_decay": 1e-4,
    "epochs": 200,
    "patience": 30,
    "batch_size": 128,
    "embed_dim": 32,
    "reg_coeff": 2.0,
    "warmup_epochs": 5,
    
    "data_path": "cts_data.xlsx",
    "feature_path": "image_features_database.csv",
    "model_save_path": "cts_final_mape.pth",
    
    "mape_weight": 0.5,
    "corr_weight": 0.3,
    "ece_weight": 0.2,
    "ema_alpha": 0.9,
    
    # Winsorizingå‚æ•°ï¼ˆæˆªå°¾è€Œéåˆ é™¤ï¼‰
    "winsorize_limits": 0.05,  # ä¸Šä¸‹å„5%æˆªå°¾
    
    # é¢„æµ‹åŒºé—´ç½®ä¿¡æ°´å¹³
    "confidence_level": 0.8,
}

# ==============================================================================
# 2. æŸå¤±å‡½æ•°ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
# ==============================================================================
def nig_nll_loss(y, gamma, v, alpha, beta):
    two_blambda = 2 * beta * (1 + v)
    nll = 0.5 * torch.log(np.pi / v) \
        - alpha * torch.log(two_blambda) \
        + (alpha + 0.5) * torch.log(v * (y - gamma)**2 + two_blambda) \
        + torch.lgamma(alpha) - torch.lgamma(alpha + 0.5)
    return nll.mean()

def strong_eub_reg_loss(y, gamma, v, alpha, beta):
    error = torch.abs(y - gamma)
    var = beta / (v * (alpha - 1))
    std = torch.sqrt(var + 1e-6)
    raw_ratio = error / (std + 1e-6)
    ratio = torch.clamp(raw_ratio, max=5.0)
    penalty = (ratio - 1.0) ** 2
    evidence = torch.clamp(2 * v + alpha, max=20.0)
    reg = penalty * torch.log1p(evidence)
    return reg.mean()

def evidential_loss(pred, target, epoch):
    gamma, v, alpha, beta = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]
    target = target.view(-1)
    loss_nll = nig_nll_loss(target, gamma, v, alpha, beta)
    loss_reg = strong_eub_reg_loss(target, gamma, v, alpha, beta)
    
    if epoch < CONFIG["warmup_epochs"]:
        reg_weight = 0.0
    else:
        if epoch < 20:
            progress = min(1.0, (epoch - CONFIG["warmup_epochs"]) / 10)
            reg_weight = CONFIG["reg_coeff"] * progress
        else:
            reg_weight = CONFIG["reg_coeff"]
    
    total_loss = loss_nll + reg_weight * loss_reg
    return total_loss, loss_nll.item(), loss_reg.item()

# ==============================================================================
# 3. æ¨¡å‹å®šä¹‰ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
# ==============================================================================
class FeatureTokenizer(nn.Module):
    def __init__(self, num_features, embed_dim):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
        self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
        self.norm = nn.LayerNorm(embed_dim)
    def forward(self, x):
        return self.norm(x.unsqueeze(-1) * self.weights + self.biases)

class TransformerTower(nn.Module):
    def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
        super().__init__()
        self.tokenizer = FeatureTokenizer(num_features, embed_dim)
        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
            batch_first=True, dropout=0.1, activation="gelu"
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
    def forward(self, x):
        tokens = self.tokenizer(x)
        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)
        out = self.transformer(torch.cat((cls_tokens, tokens), dim=1))
        return out[:, 0, :]

class CTSDualTowerModel(nn.Module):
    def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
        super().__init__()
        self.client_tower = TransformerTower(client_feats, embed_dim)
        self.image_tower = TransformerTower(image_feats, embed_dim)
        self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
        self.hidden = nn.Sequential(
            nn.Linear(embed_dim * 3, 64),
            nn.LayerNorm(64),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.GELU()
        )
        self.head = nn.Linear(32, 4)

    def forward(self, cx, ix, ax):
        c_vec = self.client_tower(cx)
        i_vec = self.image_tower(ix)
        a_vec = self.algo_embed(ax)
        fused_vec = torch.cat([c_vec, i_vec], dim=1)
        combined = torch.cat([fused_vec, a_vec], dim=1)
        out = self.head(self.hidden(combined))
        
        gamma = out[:, 0]
        v = F.softplus(out[:, 1]) + 0.1
        alpha = F.softplus(out[:, 2]) + 1.1
        beta = F.softplus(out[:, 3]) + 1e-6
        
        return torch.stack([gamma, v, alpha, beta], dim=1)

# ==============================================================================
# 4. æ•°æ®åŠ è½½ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
# ==============================================================================
class CTSDataset(Dataset):
    def __init__(self, cx, ix, ax, y):
        self.cx = torch.FloatTensor(cx)
        self.ix = torch.FloatTensor(ix)
        self.ax = torch.LongTensor(ax)
        self.y = torch.FloatTensor(y)
    def __len__(self): 
        return len(self.y)
    def __getitem__(self, idx): 
        return self.cx[idx], self.ix[idx], self.ax[idx], self.y[idx]

def load_data():
    print(f"ğŸ”„ è¯»å–æ•°æ®: {CONFIG['data_path']} ...")
    if not os.path.exists(CONFIG['data_path']):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {CONFIG['data_path']}")
        return None

    try:
        df_exp = pd.read_excel(CONFIG["data_path"])
        df_feat = pd.read_csv(CONFIG["feature_path"])
        
        rename_map = {
            "image": "image_name", 
            "method": "algo_name", 
            "network_bw": "bandwidth_mbps", 
            "network_delay": "network_rtt", 
            "mem_limit": "mem_limit_mb"
        }
        df_exp = df_exp.rename(columns=rename_map)
        
        if 'total_time' not in df_exp.columns: 
            cols = [c for c in df_exp.columns if 'total_tim' in c]
            if cols: 
                df_exp = df_exp.rename(columns={cols[0]: 'total_time'})
            
        df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
        df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
        
        # âœ… ç»Ÿè®¡æå°å€¼è€Œéè¿‡æ»¤
        tiny_samples = (df['total_time'] < 0.5).sum()
        tiny_ratio = tiny_samples / len(df) * 100
        print(f"  æå°å€¼æ ·æœ¬ç»Ÿè®¡: {tiny_samples} æ¡ (<0.5s, {tiny_ratio:.2f}%)")
        
        cols_c = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
        target_cols = ['total_size_mb', 'avg_layer_entropy', 'entropy_std', 
                       'layer_count', 'size_std_mb', 'text_ratio', 'zero_ratio']
        cols_i = [c for c in target_cols if c in df.columns]
        
        Xc_raw = df[cols_c].values
        Xi_raw = df[cols_i].values
        y_raw = np.log1p(df['total_time'].values)
        algo_names_raw = df['algo_name'].values
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæ€»æ ·æœ¬æ•°: {len(y_raw)}")
        print(f"   æ—¶é—´èŒƒå›´: [{df['total_time'].min():.2f}s, {df['total_time'].max():.2f}s]")
        print(f"   æ—¶é—´ä¸­ä½æ•°: {df['total_time'].median():.2f}s")
        print(f"   å®¢æˆ·ç«¯ç‰¹å¾: {cols_c}")
        print(f"   é•œåƒç‰¹å¾: {cols_i}")
        
        return Xc_raw, Xi_raw, algo_names_raw, y_raw, cols_c, cols_i
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

# ==============================================================================
# 5. å¢å¼ºç‰ˆè¯„ä¼°æŒ‡æ ‡è®¡ç®—
# ==============================================================================
def calculate_mape(y_true, y_pred, epsilon=1e-8):
    """ä¼ ç»ŸMAPE"""
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100
    return mape

def calculate_smape(y_true, y_pred, epsilon=1e-8):
    """å¯¹ç§°MAPE"""
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    numerator = 2 * np.abs(y_true - y_pred)
    denominator = np.abs(y_true) + np.abs(y_pred) + epsilon
    smape = np.mean(numerator / denominator) * 100
    return smape

def winsorize_array(arr, limits=0.05):
    """Winsorizingï¼šæˆªå°¾æç«¯å€¼è€Œéåˆ é™¤"""
    return mstats.winsorize(arr, limits=[limits, limits]).data

def calculate_ece_quantile(errors, uncertainties, n_bins=10):
    """åˆ†ä½æ•°åˆ†ç®±è®¡ç®—ECE"""
    if len(errors) == 0:
        return 0.0
    
    quantiles = np.linspace(0, 100, n_bins + 1)
    bin_boundaries = np.percentile(uncertainties, quantiles)
    bin_boundaries[-1] += 1e-8
    
    ece = 0.0
    total_samples = len(errors)
    
    for i in range(n_bins):
        if i == n_bins - 1:
            in_bin = (uncertainties >= bin_boundaries[i]) & (uncertainties <= bin_boundaries[i + 1])
        else:
            in_bin = (uncertainties >= bin_boundaries[i]) & (uncertainties < bin_boundaries[i + 1])
        
        prop_in_bin = in_bin.sum() / total_samples
        
        if prop_in_bin > 0:
            avg_uncertainty_in_bin = uncertainties[in_bin].mean()
            avg_error_in_bin = errors[in_bin].mean()
            ece += np.abs(avg_error_in_bin - avg_uncertainty_in_bin) * prop_in_bin
    
    return ece

def calculate_picp_mpiw(y_true, y_pred, uncertainties, confidence=0.8):
    """
    è®¡ç®—é¢„æµ‹åŒºé—´è¦†ç›–æ¦‚ç‡(PICP)å’Œå¹³å‡åŒºé—´å®½åº¦(MPIW)
    confidence: ç½®ä¿¡æ°´å¹³ï¼Œå¦‚0.8è¡¨ç¤º80%åŒºé—´
    """
    z = norm.ppf((1 + confidence) / 2)  # æ­£æ€åˆ†å¸ƒåˆ†ä½æ•°
    lower = y_pred - z * uncertainties
    upper = y_pred + z * uncertainties
    
    picp = np.mean((y_true >= lower) & (y_true <= upper)) * 100
    mpiw = np.mean(upper - lower)
    return picp, mpiw

def calculate_nll_nig(y_true, gamma, v, alpha, beta):
    """
    è®¡ç®—NIGåˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶
    """
    y_true = torch.FloatTensor(y_true)
    gamma = torch.FloatTensor(gamma)
    v = torch.FloatTensor(v)
    alpha = torch.FloatTensor(alpha)
    beta = torch.FloatTensor(beta)
    
    two_blambda = 2 * beta * (1 + v)
    nll = 0.5 * torch.log(np.pi / v) \
        - alpha * torch.log(two_blambda) \
        + (alpha + 0.5) * torch.log(v * (y_true - gamma)**2 + two_blambda) \
        + torch.lgamma(alpha) - torch.lgamma(alpha + 0.5)
    return nll.mean().item()

# ==============================================================================
# 6. å¢å¼ºç‰ˆå…¬å¹³å¯¹æ¯”è¯„ä¼°å™¨
# ==============================================================================
class EnhancedFairComparisonEvaluator:
    def __init__(self, config, device):
        self.config = config
        self.device = device
        self.results = {}
        
    def load_trained_model(self, model_path, client_feats, image_feats, num_algos):
        """åŠ è½½è®­ç»ƒå¥½çš„CFT-Netæ¨¡å‹"""
        checkpoint = torch.load(model_path, map_location=self.device)
        model = CTSDualTowerModel(client_feats, image_feats, num_algos).to(self.device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        return model, checkpoint
    
    def predict_with_cftnet_full(self, model, loader):
        """
        CFT-Netå®Œæ•´é¢„æµ‹ï¼šè¿”å›é¢„æµ‹å€¼ã€ä¸ç¡®å®šæ€§ã€NIGå‚æ•°
        """
        all_preds = []
        all_uncertainties = []
        all_targets = []
        all_gamma = []
        all_v = []
        all_alpha = []
        all_beta = []
        
        with torch.no_grad():
            for cx, ix, ax, target in loader:
                cx, ix, ax = cx.to(self.device), ix.to(self.device), ax.to(self.device)
                preds = model(cx, ix, ax)
                
                gamma, v, alpha, beta = preds[:,0], preds[:,1], preds[:,2], preds[:,3]
                
                # è½¬æ¢å›åŸå§‹æ—¶é—´ç©ºé—´
                pred_time = torch.expm1(gamma)
                true_time = torch.expm1(target.to(self.device))
                
                # è®¡ç®—ä¸ç¡®å®šæ€§ï¼ˆæ–¹å·®ï¼‰
                var = beta / (v * (alpha - 1))
                unc = torch.sqrt(var + 1e-6)
                
                all_preds.extend(pred_time.cpu().numpy())
                all_uncertainties.extend(unc.cpu().numpy())
                all_targets.extend(true_time.cpu().numpy())
                all_gamma.extend(gamma.cpu().numpy())
                all_v.extend(v.cpu().numpy())
                all_alpha.extend(alpha.cpu().numpy())
                all_beta.extend(beta.cpu().numpy())
        
        return {
            'predictions': np.array(all_preds),
            'uncertainties': np.array(all_uncertainties),
            'targets': np.array(all_targets),
            'gamma': np.array(all_gamma),
            'v': np.array(all_v),
            'alpha': np.array(all_alpha),
            'beta': np.array(all_beta)
        }
    
    def predict_baseline(self, model_class, X_train, y_train, X_test, **model_params):
        """
        è®­ç»ƒå¹¶é¢„æµ‹ä¼ ç»ŸåŸºçº¿æ¨¡å‹ï¼ˆæ— ä¸ç¡®å®šæ€§è¾“å‡ºï¼‰
        """
        model = model_class(**model_params)
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        return predictions
    
    def calculate_all_metrics(self, y_true, y_pred, uncertainties=None, 
                             nig_params=None, confidence=0.8):
        """
        è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ä¸ç¡®å®šæ€§ç‰¹æœ‰æŒ‡æ ‡
        """
        metrics = {
            'MAE': mean_absolute_error(y_true, y_pred),
            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
            'R2': r2_score(y_true, y_pred),
            'MAPE': calculate_mape(y_true, y_pred),
            'sMAPE': calculate_smape(y_true, y_pred),
        }
        
        # ä¸ç¡®å®šæ€§ç›¸å…³æŒ‡æ ‡ï¼ˆä»…CFT-Netï¼‰
        if uncertainties is not None:
            errors = np.abs(y_true - y_pred)
            
            # åŸºç¡€ä¸ç¡®å®šæ€§æŒ‡æ ‡
            metrics['Unc_Mean'] = np.mean(uncertainties)
            metrics['Unc_Std'] = np.std(uncertainties)
            metrics['Corr'] = spearmanr(uncertainties, errors)[0]
            
            # ECEï¼ˆä½¿ç”¨Winsorizedè¯¯å·®ï¼‰
            errors_winsorized = winsorize_array(errors, limits=self.config["winsorize_limits"])
            metrics['ECE'] = calculate_ece_quantile(errors_winsorized, uncertainties)
            
            # é¢„æµ‹åŒºé—´æŒ‡æ ‡
            picp, mpiw = calculate_picp_mpiw(y_true, y_pred, uncertainties, confidence)
            metrics[f'PICP_{int(confidence*100)}'] = picp
            metrics[f'MPIW_{int(confidence*100)}'] = mpiw
            
            # NLLï¼ˆå¦‚æœæä¾›äº†NIGå‚æ•°ï¼‰
            if nig_params is not None:
                metrics['NLL'] = calculate_nll_nig(
                    np.log1p(y_true),  # NLLåœ¨logç©ºé—´è®¡ç®—
                    nig_params['gamma'],
                    nig_params['v'],
                    nig_params['alpha'],
                    nig_params['beta']
                )
        
        return metrics
    
    def generate_calibration_curve(self, errors, uncertainties, n_bins=10, ax=None):
        """ç”Ÿæˆæ ¡å‡†æ›²çº¿"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(8, 6))
        
        quantiles = np.linspace(0, 100, n_bins + 1)
        bin_edges = np.percentile(uncertainties, quantiles)
        bin_centers = []
        bin_errors = []
        
        for i in range(n_bins):
            in_bin = (uncertainties >= bin_edges[i]) & (uncertainties < bin_edges[i+1])
            if in_bin.sum() > 0:
                bin_centers.append(uncertainties[in_bin].mean())
                bin_errors.append(errors[in_bin].mean())
        
        ax.plot(bin_centers, bin_errors, 'o-', color='blue', linewidth=2, markersize=8, label='å®é™…è¯¯å·®')
        ax.plot(bin_centers, bin_centers, 'r--', linewidth=2, label='å®Œç¾æ ¡å‡†')
        ax.fill_between(bin_centers, bin_centers, bin_errors, alpha=0.2, color='blue')
        ax.set_xlabel('å¹³å‡ä¸ç¡®å®šæ€§ (æ ‡å‡†å·®)', fontsize=12)
        ax.set_ylabel('å¹³å‡ç»å¯¹è¯¯å·®', fontsize=12)
        ax.set_title('æ ¡å‡†æ›²çº¿ (Calibration Curve)', fontsize=14)
        ax.legend(fontsize=11)
        ax.grid(True, alpha=0.3)
        
        return ax
    
    def generate_prediction_interval_plot(self, y_true, y_pred, uncertainties, 
                                         confidence=0.8, n_samples=100, ax=None):
        """ç”Ÿæˆé¢„æµ‹åŒºé—´è¦†ç›–å¯è§†åŒ–"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 6))
        
        z = norm.ppf((1 + confidence) / 2)
        lower = y_pred - z * uncertainties
        upper = y_pred + z * uncertainties
        
        # é€‰æ‹©å‰n_samplesä¸ªæ ·æœ¬å¯è§†åŒ–
        indices = np.arange(min(n_samples, len(y_true)))
        
        ax.plot(indices, y_true[indices], 'ko', markersize=4, label='çœŸå®å€¼')
        ax.plot(indices, y_pred[indices], 'b-', linewidth=1.5, label='é¢„æµ‹å€¼')
        ax.fill_between(indices, 
                       lower[indices], 
                       upper[indices], 
                       alpha=0.3, color='blue', label=f'{int(confidence*100)}% é¢„æµ‹åŒºé—´')
        
        # æ ‡è®°è¦†ç›–æƒ…å†µ
        covered = (y_true[indices] >= lower[indices]) & (y_true[indices] <= upper[indices])
        ax.scatter(indices[~covered], y_true[indices][~covered], 
                  color='red', s=50, marker='x', label='æœªè¦†ç›–', zorder=5)
        
        ax.set_xlabel('æ ·æœ¬ç´¢å¼•', fontsize=12)
        ax.set_ylabel('æ—¶é—´ (ç§’)', fontsize=12)
        ax.set_title(f'é¢„æµ‹åŒºé—´è¦†ç›–ç¤ºä¾‹ (å‰{len(indices)}ä¸ªæ ·æœ¬)', fontsize=14)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        return ax
    
    def generate_enhanced_uncertainty_analysis(self, cftnet_results, save_path='enhanced_uncertainty_analysis.png'):
        """
        ç”Ÿæˆå¢å¼ºç‰ˆä¸ç¡®å®šæ€§åˆ†æå›¾ (2x2å¸ƒå±€)
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        y_true = cftnet_results['targets']
        y_pred = cftnet_results['predictions']
        uncertainties = cftnetnet_results['uncertainties']
        errors = np.abs(y_true - y_pred)
        
        # 1. ä¸ç¡®å®šæ€§ vs è¯¯å·®æ•£ç‚¹å›¾
        ax1 = axes[0, 0]
        scatter = ax1.scatter(uncertainties, errors, c=errors, cmap='viridis', alpha=0.6, s=20)
        ax1.set_xlabel('é¢„æµ‹ä¸ç¡®å®šæ€§ (æ ‡å‡†å·®)', fontsize=12)
        ax1.set_ylabel('ç»å¯¹è¯¯å·®', fontsize=12)
        ax1.set_title('ä¸ç¡®å®šæ€§ vs è¯¯å·®ç›¸å…³æ€§', fontsize=14)
        corr_val = spearmanr(uncertainties, errors)[0]
        ax1.text(0.05, 0.95, f'Spearman Ï = {corr_val:.3f}', 
                transform=ax1.transAxes, fontsize=12, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        plt.colorbar(scatter, ax=ax1, label='è¯¯å·®å¤§å°')
        ax1.grid(True, alpha=0.3)
        
        # 2. é¢„æµ‹åŒºé—´è¦†ç›–ç¤ºä¾‹
        ax2 = axes[0, 1]
        self.generate_prediction_interval_plot(y_true, y_pred, uncertainties, 
                                              confidence=self.config["confidence_level"], 
                                              n_samples=100, ax=ax2)
        
        # 3. æ ¡å‡†æ›²çº¿
        ax3 = axes[1, 0]
        self.generate_calibration_curve(errors, uncertainties, n_bins=10, ax=ax3)
        
        # 4. è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾ + æ ¸å¯†åº¦ä¼°è®¡
        ax4 = axes[1, 1]
        ax4.hist(errors, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')
        
        # æ·»åŠ æ ¸å¯†åº¦ä¼°è®¡
        from scipy.stats import gaussian_kde
        kde = gaussian_kde(errors)
        x_range = np.linspace(0, np.percentile(errors, 95), 100)
        ax4.plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')
        ax4.axvline(np.mean(errors), color='green', linestyle='--', linewidth=2, label=f'Mean: {np.mean(errors):.2f}')
        ax4.axvline(np.median(errors), color='orange', linestyle='--', linewidth=2, label=f'Median: {np.median(errors):.2f}')
        ax4.set_xlabel('ç»å¯¹è¯¯å·® (ç§’)', fontsize=12)
        ax4.set_ylabel('å¯†åº¦', fontsize=12)
        ax4.set_title('è¯¯å·®åˆ†å¸ƒ (Error Distribution)', fontsize=14)
        ax4.legend(fontsize=10)
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"âœ… å¢å¼ºç‰ˆä¸ç¡®å®šæ€§åˆ†æå›¾å·²ä¿å­˜è‡³: {save_path}")
    
    def generate_error_distribution_comparison(self, all_results, save_path='error_distribution_comparison.png'):
        """
        ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„è¯¯å·®åˆ†å¸ƒå¯¹æ¯”å›¾ï¼ˆKDEï¼‰
        """
        plt.figure(figsize=(12, 7))
        
        colors = plt.cm.tab10(np.linspace(0, 1, len(all_results)))
        
        for idx, (name, result) in enumerate(all_results.items()):
            y_true = result['targets'] if 'targets' in result else result.get('y_true')
            y_pred = result['predictions']
            errors = np.abs(y_true - y_pred)
            
            # é™åˆ¶èŒƒå›´ä»¥é¿å…æç«¯å€¼å½±å“å¯è§†åŒ–
            error_range = np.percentile(errors, 99)
            filtered_errors = errors[errors <= error_range]
            
            sns.kdeplot(filtered_errors, label=name, color=colors[idx], linewidth=2.5, bw_method=0.2)
        
        plt.xlabel('ç»å¯¹è¯¯å·® (ç§’)', fontsize=13)
        plt.ylabel('å¯†åº¦', fontsize=13)
        plt.title('å„æ¨¡å‹è¯¯å·®åˆ†å¸ƒå¯¹æ¯” (Kernel Density Estimation)', fontsize=15)
        plt.legend(fontsize=11, loc='upper right')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"âœ… è¯¯å·®åˆ†å¸ƒå¯¹æ¯”å›¾å·²ä¿å­˜è‡³: {save_path}")
    
    def generate_comparison_table(self, all_metrics, save_path='comparison_results.txt'):
        """
        ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼ï¼Œåˆ†ä¸ºç²¾åº¦æŒ‡æ ‡å’Œä¸ç¡®å®šæ€§æŒ‡æ ‡ä¸¤éƒ¨åˆ†
        """
        lines = []
        lines.append("=" * 100)
        lines.append("æ¨¡å‹æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š (CFT-Net vs åŸºçº¿æ¨¡å‹)")
        lines.append("=" * 100)
        lines.append("")
        
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šé¢„æµ‹ç²¾åº¦æŒ‡æ ‡ï¼ˆæ‰€æœ‰æ¨¡å‹å…±æœ‰ï¼‰
        lines.append("ã€ä¸€ã€é¢„æµ‹ç²¾åº¦æŒ‡æ ‡ã€‘")
        lines.append("-" * 100)
        lines.append(f"{'æ¨¡å‹':<20} {'MAE(s)':<12} {'RMSE(s)':<12} {'RÂ²':<10} {'MAPE(%)':<12} {'sMAPE(%)':<12}")
        lines.append("-" * 100)
        
        for model_name, metrics in all_metrics.items():
            lines.append(f"{model_name:<20} "
                        f"{metrics['MAE']:<12.4f} "
                        f"{metrics['RMSE']:<12.4f} "
                        f"{metrics['R2']:<10.4f} "
                        f"{metrics['MAPE']:<12.2f} "
                        f"{metrics['sMAPE']:<12.2f}")
        
        lines.append("-" * 100)
        lines.append("")
        
        # ç¬¬äºŒéƒ¨åˆ†ï¼šä¸ç¡®å®šæ€§é‡åŒ–æŒ‡æ ‡ï¼ˆä»…CFT-Netï¼‰
        lines.append("ã€äºŒã€ä¸ç¡®å®šæ€§é‡åŒ–æŒ‡æ ‡ (CFT-Net ç‹¬æœ‰)ã€‘")
        lines.append("-" * 100)
        
        cftnet_metrics = all_metrics.get('CFT-Net (Ours)', {})
        
        if 'Corr' in cftnet_metrics:
            lines.append(f"Spearman ç›¸å…³ç³»æ•° (Corr):     {cftnet_metrics['Corr']:.4f}")
            lines.append(f"æœŸæœ›æ ¡å‡†è¯¯å·® (ECE):           {cftnet_metrics['ECE']:.4f}")
            lines.append(f"å¹³å‡ä¸ç¡®å®šæ€§:                 {cftnet_metrics['Unc_Mean']:.4f} Â± {cftnet_metrics['Unc_Std']:.4f}")
            lines.append(f"80% é¢„æµ‹åŒºé—´è¦†ç›–ç‡ (PICP):    {cftnet_metrics.get('PICP_80', 0):.2f}%")
            lines.append(f"80% å¹³å‡åŒºé—´å®½åº¦ (MPIW):      {cftnet_metrics.get('MPIW_80', 0):.4f} ç§’")
            lines.append(f"è´Ÿå¯¹æ•°ä¼¼ç„¶ (NLL):             {cftnet_metrics.get('NLL', 0):.4f}")
        else:
            lines.append("æœªæ‰¾åˆ°CFT-Netçš„ä¸ç¡®å®šæ€§æŒ‡æ ‡")
        
        lines.append("-" * 100)
        lines.append("")
        
        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šå…³é”®å‘ç°
        lines.append("ã€ä¸‰ã€å…³é”®å‘ç°ã€‘")
        lines.append("-" * 100)
        
        # æ‰¾å‡ºæœ€ä½³sMAPE
        best_smape_model = min(all_metrics.items(), key=lambda x: x[1]['sMAPE'])
        lines.append(f"â€¢ æœ€ä½³é¢„æµ‹ç²¾åº¦ (sMAPE): {best_smape_model[0]} ({best_smape_model[1]['sMAPE']:.2f}%)")
        
        if 'Corr' in cftnet_metrics:
            lines.append(f"â€¢ CFT-Net ä¸ç¡®å®šæ€§-è¯¯å·®ç›¸å…³æ€§: {cftnet_metrics['Corr']:.4f} (>0.5 è¡¨ç¤ºæœ‰æ•ˆä¸ç¡®å®šæ€§ä¼°è®¡)")
            lines.append(f"â€¢ CFT-Net é¢„æµ‹åŒºé—´è¦†ç›–ç‡: {cftnet_metrics.get('PICP_80', 0):.1f}% (ç›®æ ‡: 80%)")
        
        lines.append("-" * 100)
        lines.append("")
        lines.append("æ³¨ï¼šåŸºçº¿æ¨¡å‹ (XGBoost, LightGBM, Random Forest) æ— æ³•æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå› æ­¤æ— Corr/ECE/PICP/MPIWæŒ‡æ ‡")
        lines.append("     CFT-Net åœ¨ä¿æŒç«äº‰åŠ›çš„é¢„æµ‹ç²¾åº¦çš„åŒæ—¶ï¼Œé¢å¤–æä¾›äº†å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›ã€‚")
        lines.append("=" * 100)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°
        print('\n'.join(lines))
        print(f"\nâœ… å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜è‡³: {save_path}")
    
    def generate_scatter_plots(self, all_results, save_path='prediction_scatter_comparison.png'):
        """
        ç”Ÿæˆé¢„æµ‹æ•£ç‚¹å›¾å¯¹æ¯”ï¼ˆæ‰€æœ‰æ¨¡å‹ï¼‰
        """
        n_models = len(all_results)
        fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))
        
        if n_models == 1:
            axes = [axes]
        
        for idx, (name, result) in enumerate(all_results.items()):
            ax = axes[idx]
            y_true = result['targets'] if 'targets' in result else result.get('y_true')
            y_pred = result['predictions']
            
            # è®¡ç®—æŒ‡æ ‡
            mae = mean_absolute_error(y_true, y_pred)
            smape = calculate_smape(y_true, y_pred)
            
            # æ•£ç‚¹å›¾
            ax.scatter(y_true, y_pred, alpha=0.5, s=20, c='blue', edgecolors='none')
            
            # å®Œç¾é¢„æµ‹çº¿
            min_val = min(y_true.min(), y_pred.min())
            max_val = max(y_true.max(), y_pred.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='å®Œç¾é¢„æµ‹')
            
            # è¯¯å·®å¸¦ (Â±20%)
            ax.fill_between([min_val, max_val], 
                           [min_val*0.8, max_val*0.8], 
                           [min_val*1.2, max_val*1.2], 
                           alpha=0.1, color='gray', label='Â±20% è¯¯å·®å¸¦')
            
            ax.set_xlabel('çœŸå®å€¼ (ç§’)', fontsize=11)
            ax.set_ylabel('é¢„æµ‹å€¼ (ç§’)', fontsize=11)
            ax.set_title(f'{name}\nMAE={mae:.2f}s, sMAPE={smape:.2f}%', fontsize=12)
            ax.legend(fontsize=9)
            ax.grid(True, alpha=0.3)
            ax.set_aspect('equal')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"âœ… é¢„æµ‹æ•£ç‚¹å›¾å¯¹æ¯”å·²ä¿å­˜è‡³: {save_path}")

# ==============================================================================
# 7. ä¸»è¯„ä¼°æµç¨‹
# ==============================================================================
def main_evaluation():
    print("=" * 80)
    print("ğŸš€ CFT-Net å¢å¼ºç‰ˆå…¬å¹³å¯¹æ¯”è¯„ä¼°")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    data = load_data()
    if data is None:
        exit(1)
        
    Xc_raw, Xi_raw, algo_names_raw, y_raw, cols_c, cols_i = data
    N = len(y_raw)
    
    # åˆ’åˆ†ç´¢å¼•ï¼ˆä¸è®­ç»ƒæ—¶ç›¸åŒï¼‰
    idx = np.random.permutation(N)
    n_tr = int(N * 0.7)
    n_val = int(N * 0.15)
    
    tr_idx = idx[:n_tr]
    val_idx = idx[n_tr:n_tr+n_val]
    te_idx = idx[n_tr+n_val:]
    
    print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†: è®­ç»ƒ {len(tr_idx)} æ¡, éªŒè¯ {len(val_idx)} æ¡, æµ‹è¯• {len(te_idx)} æ¡")
    
    # åŠ è½½é¢„å¤„ç†å¯¹è±¡
    try:
        with open('preprocessing_objects.pkl', 'rb') as f:
            prep = pickle.load(f)
        scaler_c = prep['scaler_c']
        scaler_i = prep['scaler_i']
        enc = prep['enc']
        default_idx = prep['default_algo_idx']
        most_common_class = prep['most_common_algo']
        print("âœ… å·²åŠ è½½é¢„å¤„ç†å¯¹è±¡")
    except FileNotFoundError:
        print("âš ï¸ æœªæ‰¾åˆ°é¢„å¤„ç†å¯¹è±¡ï¼Œé‡æ–°æ‹Ÿåˆ...")
        scaler_c = StandardScaler().fit(Xc_raw[tr_idx])
        scaler_i = StandardScaler().fit(Xi_raw[tr_idx])
        enc = LabelEncoder()
        enc.fit(algo_names_raw[tr_idx])
        class_counts = Counter(algo_names_raw[tr_idx])
        most_common_class = class_counts.most_common(1)[0][0]
        default_idx = enc.transform([most_common_class])[0]
    
    # æ•°æ®æ ‡å‡†åŒ–
    Xc_test = scaler_c.transform(Xc_raw[te_idx])
    Xi_test = scaler_i.transform(Xi_raw[te_idx])
    
    # å¤„ç†æµ‹è¯•é›†ç®—æ³•åç§°
    def safe_transform(encoder, labels, default):
        known_classes = set(encoder.classes_)
        transformed = []
        for label in labels:
            if label in known_classes:
                transformed.append(encoder.transform([label])[0])
            else:
                transformed.append(default)
        return np.array(transformed)
    
    Xa_test = safe_transform(enc, algo_names_raw[te_idx], default_idx)
    y_test = y_raw[te_idx]
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    te_d = CTSDataset(Xc_test, Xi_test, Xa_test, y_test)
    te_loader = DataLoader(te_d, batch_size=CONFIG["batch_size"], shuffle=False)
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = EnhancedFairComparisonEvaluator(CONFIG, device)
    
    # åŠ è½½CFT-Netæ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½CFT-Netæ¨¡å‹: {CONFIG['model_save_path']}")
    try:
        model, checkpoint = evaluator.load_trained_model(
            CONFIG['model_save_path'], 
            len(cols_c), 
            len(cols_i), 
            len(enc.classes_)
        )
        print(f"   æœ€ä½³è®­ç»ƒè½®æ¬¡: {checkpoint.get('epoch', 'unknown')}")
        print(f"   æœ€ä½³éªŒè¯å¾—åˆ†: {checkpoint.get('best_score', 'unknown')}")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {CONFIG['model_save_path']}")
        print("   è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬æˆ–æ£€æŸ¥è·¯å¾„é…ç½®")
        return
    
    # CFT-Neté¢„æµ‹
    print("\nğŸ” è¿è¡ŒCFT-Neté¢„æµ‹...")
    cftnet_results = evaluator.predict_with_cftnet_full(model, te_loader)
    cftnet_results['y_true'] = cftnet_results['targets']  # å…¼å®¹æ€§
    
    # è®¡ç®—CFT-NetæŒ‡æ ‡
    nig_params = {
        'gamma': cftnet_results['gamma'],
        'v': cftnet_results['v'],
        'alpha': cftnet_results['alpha'],
        'beta': cftnet_results['beta']
    }
    
    cftnet_metrics = evaluator.calculate_all_metrics(
        cftnet_results['targets'],
        cftnet_results['predictions'],
        cftnet_results['uncertainties'],
        nig_params,
        confidence=CONFIG["confidence_level"]
    )
    
    print(f"âœ… CFT-Net sMAPE: {cftnet_metrics['sMAPE']:.2f}%, Corr: {cftnet_metrics['Corr']:.4f}")
    
    # å‡†å¤‡åŸºçº¿æ¨¡å‹å¯¹æ¯”ï¼ˆç¤ºä¾‹ï¼šè¿™é‡Œå¯ä»¥é›†æˆXGBoostç­‰ï¼‰
    # æ³¨æ„ï¼šä¸ºäº†å…¬å¹³å¯¹æ¯”ï¼ŒåŸºçº¿æ¨¡å‹åº”ä½¿ç”¨ç›¸åŒçš„ç‰¹å¾å·¥ç¨‹
    all_results = {'CFT-Net (Ours)': cftnet_results}
    all_metrics = {'CFT-Net (Ours)': cftnet_metrics}
    
    # ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š...")
    
    # 1. å¢å¼ºç‰ˆä¸ç¡®å®šæ€§åˆ†æï¼ˆCFT-Netç‹¬æœ‰ï¼‰
    evaluator.generate_enhanced_uncertainty_analysis(
        cftnet_results, 
        save_path='enhanced_uncertainty_analysis.png'
    )
    
    # 2. é¢„æµ‹æ•£ç‚¹å›¾
    evaluator.generate_scatter_plots(
        all_results,
        save_path='prediction_scatter_comparison.png'
    )
    
    # 3. å¯¹æ¯”è¡¨æ ¼
    evaluator.generate_comparison_table(
        all_metrics,
        save_path='comparison_results.txt'
    )
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSON
    results_json = {
        'cftnet_full_results': {
            'predictions': cftnet_results['predictions'].tolist(),
            'uncertainties': cftnet_results['uncertainties'].tolist(),
            'targets': cftnet_results['targets'].tolist(),
            'metrics': {k: float(v) for k, v in cftnet_metrics.items()}
        },
        'config': CONFIG
    }
    
    with open('detailed_evaluation_results.json', 'w') as f:
        json.dump(results_json, f, indent=2)
    
    print(f"\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: detailed_evaluation_results.json")
    print("\n" + "=" * 80)
    print("ğŸ‰ è¯„ä¼°å®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°å½“å‰ç›®å½•ã€‚")
    print("=" * 80)

if __name__ == "__main__":
    main_evaluation()


# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.linear_model import LinearRegression
# from sklearn.ensemble import GradientBoostingRegressor
# from scipy.stats import spearmanr
# from scipy.stats import mstats
# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import json
# import warnings
# import sys
# import os
# import pickle

# warnings.filterwarnings('ignore')
# import matplotlib
# import platform

# # --- å­—ä½“é…ç½® ---
# system_name = platform.system()
# if system_name == 'Windows':
#     font_list = ['Microsoft YaHei', 'SimHei', 'SimSun']
# elif system_name == 'Darwin':
#     font_list = ['Heiti TC', 'PingFang HK', 'Arial Unicode MS']
# else:
#     font_list = ['WenQuanYi Micro Hei', 'Droid Sans Fallback', 'SimHei']

# matplotlib.rcParams['font.sans-serif'] = font_list
# matplotlib.rcParams['axes.unicode_minus'] = False

# # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
# sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

# # ç›´æ¥å®šä¹‰æ¨¡å‹ç±»ï¼Œé¿å…å¯¼å…¥é—®é¢˜
# class FeatureTokenizer(nn.Module):
#     def __init__(self, num_features, embed_dim):
#         super().__init__()
#         self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
#         self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
#         self.norm = nn.LayerNorm(embed_dim)
#     def forward(self, x):
#         return self.norm(x.unsqueeze(-1) * self.weights + self.biases)

# class TransformerTower(nn.Module):
#     def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
#         super().__init__()
#         self.tokenizer = FeatureTokenizer(num_features, embed_dim)
#         self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
#         encoder_layer = nn.TransformerEncoderLayer(
#             d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
#             batch_first=True, dropout=0.1, activation="gelu"
#         )
#         self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
#     def forward(self, x):
#         tokens = self.tokenizer(x)
#         cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)
#         out = self.transformer(torch.cat((cls_tokens, tokens), dim=1))
#         return out[:, 0, :]

# class CTSDualTowerModel(nn.Module):
#     def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
#         super().__init__()
#         self.client_tower = TransformerTower(client_feats, embed_dim)
#         self.image_tower = TransformerTower(image_feats, embed_dim)
#         self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
#         self.hidden = nn.Sequential(
#             nn.Linear(embed_dim * 3, 64),
#             nn.LayerNorm(64),
#             nn.GELU(),
#             nn.Dropout(0.2),
#             nn.Linear(64, 32),
#             nn.GELU()
#         )
#         self.head = nn.Linear(32, 4)

#     def forward(self, cx, ix, ax):
#         c_vec = self.client_tower(cx)
#         i_vec = self.image_tower(ix)
#         a_vec = self.algo_embed(ax)
#         fused_vec = torch.cat([c_vec, i_vec], dim=1)
#         combined = torch.cat([fused_vec, a_vec], dim=1)
#         out = self.head(self.hidden(combined))
        
#         gamma = out[:, 0]
#         v = F.softplus(out[:, 1]) + 0.1
#         alpha = F.softplus(out[:, 2]) + 1.1
#         beta = F.softplus(out[:, 3]) + 1e-6
        
#         return torch.stack([gamma, v, alpha, beta], dim=1)


# # ==============================================================================
# # è¯„ä¼°æŒ‡æ ‡å‡½æ•°ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
# # ==============================================================================
# def calculate_mape(y_true, y_pred, epsilon=1e-8):
#     """ä¼ ç»ŸMAPE"""
#     y_true = np.array(y_true)
#     y_pred = np.array(y_pred)
#     mape = np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100
#     return mape

# def calculate_smape(y_true, y_pred, epsilon=1e-8):
#     """å¯¹ç§°MAPE"""
#     y_true = np.array(y_true)
#     y_pred = np.array(y_pred)
#     numerator = 2 * np.abs(y_true - y_pred)
#     denominator = np.abs(y_true) + np.abs(y_pred) + epsilon
#     smape = np.mean(numerator / denominator) * 100
#     return smape

# def calculate_ece_quantile(errors, uncertainties, n_bins=10):
#     """åˆ†ä½æ•°åˆ†ç®±è®¡ç®—ECE"""
#     if len(errors) == 0:
#         return 0.0
    
#     quantiles = np.linspace(0, 100, n_bins + 1)
#     bin_boundaries = np.percentile(uncertainties, quantiles)
#     bin_boundaries[-1] += 1e-8
    
#     ece = 0.0
#     total_samples = len(errors)
    
#     for i in range(n_bins):
#         if i == n_bins - 1:
#             in_bin = (uncertainties >= bin_boundaries[i]) & (uncertainties <= bin_boundaries[i + 1])
#         else:
#             in_bin = (uncertainties >= bin_boundaries[i]) & (uncertainties < bin_boundaries[i + 1])
        
#         prop_in_bin = in_bin.sum() / total_samples
        
#         if prop_in_bin > 0:
#             avg_uncertainty_in_bin = uncertainties[in_bin].mean()
#             avg_error_in_bin = errors[in_bin].mean()
#             ece += np.abs(avg_error_in_bin - avg_uncertainty_in_bin) * prop_in_bin
    
#     return ece


# class FairComparisonEvaluator:
#     """å…¬å¹³å¯¹æ¯”è¯„ä¼°å™¨ - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ•°æ®åˆ’åˆ†å’Œé¢„å¤„ç†"""
    
#     def __init__(self):
#         self.model = None
#         self.scaler_c = None
#         self.scaler_i = None
#         self.enc_algo = None
#         self.random_seed = 42
#         np.random.seed(self.random_seed)

#     def load_preprocessing_objects(self):
#         """åŠ è½½è®­ç»ƒæ—¶ä¿å­˜çš„é¢„å¤„ç†å¯¹è±¡"""
#         print("åŠ è½½è®­ç»ƒæ—¶çš„é¢„å¤„ç†å¯¹è±¡...")
#         prep_path = os.path.join('..', 'modeling', 'preprocessing_objects.pkl')
        
#         if not os.path.exists(prep_path):
#             alternative_paths = [
#                 'preprocessing_objects.pkl',
#                 os.path.join('..', '..', 'ml_training', 'modeling', 'preprocessing_objects.pkl'),
#             ]
#             for alt_path in alternative_paths:
#                 if os.path.exists(alt_path):
#                     prep_path = alt_path
#                     break
#             else:
#                 raise FileNotFoundError(f"æ‰¾ä¸åˆ°é¢„å¤„ç†å¯¹è±¡æ–‡ä»¶: {prep_path}")
        
#         with open(prep_path, 'rb') as f:
#             prep_objects = pickle.load(f)
        
#         self.scaler_c = prep_objects['scaler_c']
#         self.scaler_i = prep_objects['scaler_i']
#         self.enc_algo = prep_objects['enc']
        
#         # ä»é¢„å¤„ç†å¯¹è±¡åŠ è½½ç‰¹å¾åˆ—åï¼ˆå¦‚æœå­˜åœ¨ï¼‰
#         if 'cols_c' in prep_objects:
#             self.col_client = prep_objects['cols_c']
#         else:
#             self.col_client = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
            
#         if 'cols_i' in prep_objects:
#             self.col_image = prep_objects['cols_i']
#         else:
#             self.col_image = ['total_size_mb', 'avg_layer_entropy', 'text_ratio', 
#                             'layer_count', 'zero_ratio']
        
#         print(f"âœ… æˆåŠŸåŠ è½½é¢„å¤„ç†å¯¹è±¡")
#         print(f"   å®¢æˆ·ç«¯ç‰¹å¾: {self.col_client}")
#         print(f"   é•œåƒç‰¹å¾: {self.col_image}")
#         print(f"   ç®—æ³•ç±»åˆ«æ•°: {len(self.enc_algo.classes_)}")

#     def load_existing_model(self):
#         """åŠ è½½å·²è®­ç»ƒçš„CFT-Netæ¨¡å‹"""
#         print("åŠ è½½ç°æœ‰çš„CFT-Netæ¨¡å‹...")
        
#         if self.scaler_c is None:
#             self.load_preprocessing_objects()
        
#         model_path = os.path.join('..', 'modeling', 'cts_final_mape.pth')  # æ›´æ–°æ¨¡å‹å
        
#         if not os.path.exists(model_path):
#             alternative_paths = [
#                 'cts_final_mape.pth',
#                 os.path.join('..', '..', 'ml_training', 'modeling', 'cts_final_mape.pth'),
#                 'cts_final_strong.pth',  # å…¼å®¹æ—§åç§°
#                 os.path.join('..', '..', 'ml_training', 'modeling', 'cts_final_strong.pth'),
#             ]
#             for alt_path in alternative_paths:
#                 if os.path.exists(alt_path):
#                     model_path = alt_path
#                     print(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
#                     break
#             else:
#                 raise FileNotFoundError(f"æ‰¾ä¸åˆ°é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶")
        
#         self.model = CTSDualTowerModel(
#             client_feats=self.scaler_c.n_features_in_,
#             image_feats=self.scaler_i.n_features_in_,
#             num_algos=len(self.enc_algo.classes_),
#             embed_dim=32
#         )
        
#         print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
#         checkpoint = torch.load(model_path, map_location='cpu')
        
#         if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
#             state_dict = checkpoint['model_state_dict']
#         else:
#             state_dict = checkpoint
        
#         self.model.load_state_dict(state_dict, strict=False)
#         self.model.eval()
#         print(f"âœ… æˆåŠŸåŠ è½½CFT-Netæ¨¡å‹")
    
#     def load_real_training_data(self):
#         """åŠ è½½çœŸå®çš„è®­ç»ƒæ•°æ®"""
#         print("åŠ è½½çœŸå®çš„è®­ç»ƒæ•°æ®...")
        
#         data_path = os.path.join('..', 'modeling', 'cts_data.xlsx')
#         feature_path = os.path.join('..', 'modeling', 'image_features_database.csv')
        
#         df_exp = pd.read_excel(data_path)
#         df_feat = pd.read_csv(feature_path)
        
#         rename_map = {
#             "image": "image_name", 
#             "method": "algo_name", 
#             "network_bw": "bandwidth_mbps", 
#             "network_delay": "network_rtt", 
#             "mem_limit": "mem_limit_mb"
#         }
#         df_exp = df_exp.rename(columns=rename_map)
        
#         if 'total_time' not in df_exp.columns:
#             possible_cols = [c for c in df_exp.columns if 'total_tim' in c]
#             if possible_cols: 
#                 df_exp = df_exp.rename(columns={possible_cols[0]: 'total_time'})
        
#         df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
#         df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
        
#         # ç»Ÿè®¡æå°å€¼ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
#         tiny_samples = (df['total_time'] < 0.5).sum()
#         tiny_ratio = tiny_samples / len(df) * 100
#         print(f"  æå°å€¼æ ·æœ¬: {tiny_samples} æ¡ (<0.5s, {tiny_ratio:.2f}%)")
        
#         print(f"âœ… åŠ è½½æ•°æ®å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: {len(df)}")
#         print(f"   æ—¶é—´èŒƒå›´: [{df['total_time'].min():.2f}s, {df['total_time'].max():.2f}s]")
        
#         return df
    
#     def prepare_features(self, df):
#         """å‡†å¤‡ç‰¹å¾æ•°æ®"""
#         print("å‡†å¤‡ç‰¹å¾æ•°æ®...")
        
#         X_client = self.scaler_c.transform(df[self.col_client].values)
        
#         available_image_cols = [c for c in self.col_image if c in df.columns]
#         if len(available_image_cols) != len(self.col_image):
#             print(f"è­¦å‘Š: é•œåƒç‰¹å¾åˆ—ä¸å®Œå…¨åŒ¹é…ï¼Œä½¿ç”¨å¯ç”¨åˆ—: {available_image_cols}")
#         X_image = self.scaler_i.transform(df[available_image_cols].values)
        
#         # å¤„ç†æœªçŸ¥ç®—æ³•
#         algo_names = df['algo_name'].values
#         known_algos = set(self.enc_algo.classes_)
#         unknown_algos = set(algo_names) - known_algos
        
#         if unknown_algos:
#             print(f"è­¦å‘Š: å‘ç°æœªè§è¿‡çš„ç®—æ³•: {unknown_algos}")
#             # ä½¿ç”¨è®­ç»ƒæ—¶æœ€å¸¸è§çš„ç±»åˆ«ï¼ˆå¦‚æœä¿å­˜äº†ï¼‰
#             if hasattr(self, 'most_common_algo'):
#                 default_algo = self.most_common_algo
#             else:
#                 default_algo = self.enc_algo.classes_[0]
#             for unknown in unknown_algos:
#                 algo_names[algo_names == unknown] = default_algo
        
#         X_algo = self.enc_algo.transform(algo_names)
        
#         y_original = df['total_time'].values
#         y_log_transformed = np.log1p(y_original)
        
#         print(f"ç›®æ ‡å€¼ç»Ÿè®¡: å‡å€¼={y_original.mean():.2f}s, æ ‡å‡†å·®={y_original.std():.2f}s")
        
#         return X_client, X_image, X_algo, y_log_transformed, y_original
    
#     def train_all_models_on_same_data(self, df):
#         """åœ¨ç›¸åŒæ•°æ®ä¸Šè®­ç»ƒæ‰€æœ‰æ¨¡å‹è¿›è¡Œå…¬å¹³å¯¹æ¯”"""
#         print("=== åœ¨ç›¸åŒçœŸå®æ•°æ®ä¸Šè®­ç»ƒæ‰€æœ‰æ¨¡å‹ ===")
        
#         X_client, X_image, X_algo, y_log, y_orig = self.prepare_features(df)
        
#         # ä¸è®­ç»ƒä»£ç ç›¸åŒçš„æ•°æ®åˆ’åˆ†
#         N = len(df)
#         idx = np.random.permutation(N)
        
#         n_tr = int(N * 0.7)
#         n_val = int(N * 0.15)
        
#         tr_idx = idx[:n_tr]
#         val_idx = idx[n_tr:n_tr+n_val]
#         te_idx = idx[n_tr+n_val:]
        
#         print(f"æ•°æ®åˆ’åˆ†: è®­ç»ƒ {len(tr_idx)} | éªŒè¯ {len(val_idx)} | æµ‹è¯• {len(te_idx)}")
        
#         # è®­ç»ƒé›†
#         X_train_combined = np.hstack([
#             X_client[tr_idx],
#             X_image[tr_idx],
#             X_algo[tr_idx].reshape(-1, 1)
#         ])
#         y_train_log = y_log[tr_idx]
        
#         # æµ‹è¯•é›†
#         X_test_combined = np.hstack([
#             X_client[te_idx],
#             X_image[te_idx],
#             X_algo[te_idx].reshape(-1, 1)
#         ])
#         X_test_client = X_client[te_idx]
#         X_test_image = X_image[te_idx]
#         X_test_algo = X_algo[te_idx]
#         y_test_orig = y_orig[te_idx]
        
#         # å¤„ç†æ— æ•ˆå€¼
#         X_train_combined = np.nan_to_num(X_train_combined, nan=0.0)
#         X_test_combined = np.nan_to_num(X_test_combined, nan=0.0)
#         y_train_log = np.nan_to_num(y_train_log, nan=np.median(y_train_log))
        
#         results = {}
        
#         # 1. çº¿æ€§å›å½’
#         print("è®­ç»ƒ Linear Regression...")
#         lr_model = LinearRegression()
#         lr_model.fit(X_train_combined, y_train_log)
#         lr_pred_log = lr_model.predict(X_test_combined)
#         lr_pred_log = np.clip(lr_pred_log, 0.1, np.log1p(1200.0))
#         lr_pred_orig = np.expm1(lr_pred_log)
        
#         # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
#         lr_metrics = self.calculate_all_metrics(y_test_orig, lr_pred_orig)
#         results['Linear Regression'] = {'predictions': lr_pred_orig, **lr_metrics}
        
#         # 2. éšæœºæ£®æ—
#         print("è®­ç»ƒ Random Forest...")
#         rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
#         rf_model.fit(X_train_combined, y_train_log)
#         rf_pred_log = rf_model.predict(X_test_combined)
#         rf_pred_log = np.clip(rf_pred_log, 0.1, np.log1p(1200.0))
#         rf_pred_orig = np.expm1(rf_pred_log)
        
#         rf_metrics = self.calculate_all_metrics(y_test_orig, rf_pred_orig)
#         results['Random Forest'] = {'predictions': rf_pred_orig, **rf_metrics}
        
#         # 3. æ¢¯åº¦æå‡
#         print("è®­ç»ƒ Gradient Boosting...")
#         gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
#         gb_model.fit(X_train_combined, y_train_log)
#         gb_pred_log = gb_model.predict(X_test_combined)
#         gb_pred_log = np.clip(gb_pred_log, 0.1, np.log1p(1200.0))
#         gb_pred_orig = np.expm1(gb_pred_log)
        
#         gb_metrics = self.calculate_all_metrics(y_test_orig, gb_pred_orig)
#         results['Gradient Boosting'] = {'predictions': gb_pred_orig, **gb_metrics}
        
#         # 4. CFT-Netï¼ˆå¸¦ä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
#         print("è¯„ä¼° CFT-Net...")
#         cftnet_pred, cftnet_uncs = self.predict_with_cftnet_full(X_test_client, X_test_image, X_test_algo)
        
#         # CFT-Netæœ‰ä¸ç¡®å®šæ€§ï¼Œè®¡ç®—å®Œæ•´æŒ‡æ ‡
#         cftnet_metrics = self.calculate_all_metrics(y_test_orig, cftnet_pred, cftnet_uncs)
#         results['CFT-Net'] = {'predictions': cftnet_pred, **cftnet_metrics}
        
#         return results, y_test_orig
    
#     def calculate_all_metrics(self, y_true, y_pred, uncertainties=None):
#         """è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰"""
#         y_true = np.array(y_true)
#         y_pred = np.array(y_pred)
        
#         # åŸºæœ¬æŒ‡æ ‡
#         mae = mean_absolute_error(y_true, y_pred)
#         rmse = np.sqrt(mean_squared_error(y_true, y_pred))
#         r2 = r2_score(y_true, y_pred)
#         mape = calculate_mape(y_true, y_pred)
#         smape = calculate_smape(y_true, y_pred)
        
#         metrics = {
#             'mae': mae,
#             'rmse': rmse,
#             'r2': r2,
#             'mape': mape,
#             'smape': smape,
#         }
        
#         # å¦‚æœæœ‰ä¸ç¡®å®šæ€§ï¼Œè®¡ç®—Corrå’ŒECE
#         if uncertainties is not None:
#             uncertainties = np.array(uncertainties)
#             errors = np.abs(y_true - y_pred)
            
#             # Spearman Corr
#             corr, _ = spearmanr(uncertainties, errors)
#             corr = corr if not np.isnan(corr) else 0.0
            
#             # ECE
#             ece = calculate_ece_quantile(errors, uncertainties)
            
#             metrics['corr'] = corr
#             metrics['ece'] = ece
#         else:
#             # ä¼ ç»Ÿæ¨¡å‹æ²¡æœ‰ä¸ç¡®å®šæ€§ä¼°è®¡
#             metrics['corr'] = None
#             metrics['ece'] = None
        
#         return metrics
    
#     def predict_with_cftnet_full(self, X_client, X_image, X_algo):
#         """ä½¿ç”¨CFT-Netè¿›è¡Œé¢„æµ‹ï¼Œè¿”å›é¢„æµ‹å€¼å’Œä¸ç¡®å®šæ€§"""
#         device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#         self.model = self.model.to(device)
        
#         cx = torch.FloatTensor(X_client).to(device)
#         ix = torch.FloatTensor(X_image).to(device)
#         ax = torch.LongTensor(X_algo).to(device)
        
#         with torch.no_grad():
#             preds = self.model(cx, ix, ax)
#             gamma = preds[:, 0]
#             v = preds[:, 1]
#             alpha = preds[:, 2]
#             beta = preds[:, 3]
            
#             # é¢„æµ‹å€¼
#             predictions = np.expm1(gamma.cpu().numpy())
            
#             # ä¸ç¡®å®šæ€§ï¼ˆæ ‡å‡†å·®ï¼‰
#             var = beta / (v * (alpha - 1))
#             uncertainties = torch.sqrt(var + 1e-6).cpu().numpy()
        
#         predictions = np.nan_to_num(predictions, nan=np.median(predictions))
#         predictions = np.clip(predictions, 0.1, 20000.0)
#         uncertainties = np.nan_to_num(uncertainties, nan=0.0)
        
#         return predictions, uncertainties
    
#     def generate_comparison_table(self, results):
#         """ç”Ÿæˆæ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨æ ¼ï¼ˆçªå‡ºsMAPEå’ŒCorrï¼‰"""
#         print("\n" + "=" * 100)
#         print("æ¨¡å‹é¢„æµ‹æ€§èƒ½å¯¹æ¯”ï¼ˆåŸºäºç›¸åŒæµ‹è¯•é›†ï¼‰")
#         print("=" * 100)
#         print(f"{'æ¨¡å‹':<20} {'sMAPE(%)':<10} {'MAPE(%)':<10} {'MAE(s)':<10} {'RMSE(s)':<10} {'RÂ²':<8} {'Corr':<8} {'ECE':<8}")
#         print("-" * 100)
        
#         # æ‰¾åˆ°æœ€ä½³sMAPEåŸºçº¿
#         baseline_models = {k: v for k, v in results.items() if 'CFT-Net' not in k}
#         best_baseline_smape = min(baseline_models.items(), key=lambda x: x[1]['smape'])
        
#         for name, result in results.items():
#             corr_str = f"{result['corr']:.3f}" if result['corr'] is not None else "N/A"
#             ece_str = f"{result['ece']:.2f}" if result['ece'] is not None else "N/A"
            
#             print(f"{name:<20} {result['smape']:<10.2f} {result['mape']:<10.2f} "
#                   f"{result['mae']:<10.2f} {result['rmse']:<10.2f} "
#                   f"{result['r2']:<8.3f} {corr_str:<8} {ece_str:<8}")
        
#         print("=" * 100)
        
#         # è®¡ç®—æ”¹è¿›å¹…åº¦
#         cftnet = results['CFT-Net']
#         best_baseline = best_baseline_smape[1]
        
#         smape_improvement = (best_baseline['smape'] - cftnet['smape']) / best_baseline['smape'] * 100
        
#         print(f"\nğŸ“Š å…³é”®å¯¹æ¯”ï¼ˆCFT-Net vs æœ€ä½³åŸºçº¿ {best_baseline_smape[0]}ï¼‰:")
#         print(f"   sMAPE: {cftnet['smape']:.2f}% vs {best_baseline['smape']:.2f}% "
#               f"(â†“{smape_improvement:.1f}%)")
#         print(f"   MAE:   {cftnet['mae']:.2f}s vs {best_baseline['mae']:.2f}s")
#         print(f"   Corr:  {cftnet['corr']:.3f} (CFT-Netç‰¹æœ‰)")
        
#         # ä¿å­˜CSV
#         comparison_data = []
#         for name, result in results.items():
#             comparison_data.append({
#                 'Model': name,
#                 'sMAPE': result['smape'],
#                 'MAPE': result['mape'],
#                 'MAE': result['mae'],
#                 'RMSE': result['rmse'],
#                 'R2': result['r2'],
#                 'Corr': result['corr'],
#                 'ECE': result['ece']
#             })
#         pd.DataFrame(comparison_data).to_csv('model_comparison_mape.csv', index=False)
#         print("\nâœ… ç»“æœå·²ä¿å­˜åˆ° model_comparison_mape.csv")
    
#     def generate_prediction_scatter_plots(self, results, y_true):
#         """ç”Ÿæˆé¢„æµ‹å€¼vsçœŸå®å€¼æ•£ç‚¹å›¾ï¼ˆçªå‡ºsMAPEï¼‰"""
#         fig, axes = plt.subplots(2, 2, figsize=(16, 14))
#         fig.suptitle('æ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§å¯¹æ¯”ï¼ˆåŸºäºsMAPEï¼‰', fontsize=16, fontweight='bold')
        
#         models = list(results.keys())
#         positions = [(0,0), (0,1), (1,0), (1,1)]
        
#         for i, model in enumerate(models[:4]):
#             row, col = positions[i]
#             ax = axes[row, col]
#             y_pred = results[model]['predictions']
            
#             # æ•£ç‚¹å›¾
#             ax.scatter(y_true, y_pred, alpha=0.4, s=15, edgecolors='none')
            
#             # å®Œç¾é¢„æµ‹çº¿
#             min_val = min(y_true.min(), y_pred.min())
#             max_val = max(y_true.max(), y_pred.max())
#             ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='å®Œç¾é¢„æµ‹')
            
#             # æŒ‡æ ‡
#             smape = results[model]['smape']
#             mae = results[model]['mae']
#             corr_str = f", Corr={results[model]['corr']:.3f}" if results[model]['corr'] else ""
            
#             ax.set_xlabel('çœŸå®ä¼ è¾“æ—¶é—´ (ç§’)', fontsize=12)
#             ax.set_ylabel('é¢„æµ‹ä¼ è¾“æ—¶é—´ (ç§’)', fontsize=12)
#             ax.set_title(f'{model}\nsMAPE={smape:.2f}%, MAE={mae:.2f}s{corr_str}', fontsize=12)
#             ax.legend()
#             ax.grid(True, alpha=0.3)
        
#         plt.tight_layout()
#         plt.savefig('prediction_accuracy_mape.png', dpi=300, bbox_inches='tight')
#         print("âœ… æ•£ç‚¹å›¾å·²ä¿å­˜åˆ° prediction_accuracy_mape.png")
#         plt.close()

#     def generate_uncertainty_analysis(self, results, y_true):
#         """ç”ŸæˆCFT-Netçš„ä¸ç¡®å®šæ€§åˆ†æå›¾"""
#         if 'CFT-Net' not in results:
#             return
        
#         cftnet = results['CFT-Net']
#         y_pred = cftnet['predictions']
#         uncertainties = cftnet.get('uncertainties', None)
        
#         if uncertainties is None:
#             return
        
#         fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        
#         # 1. ä¸ç¡®å®šæ€§vsè¯¯å·®æ•£ç‚¹å›¾
#         errors = np.abs(y_true - y_pred)
#         axes[0].scatter(uncertainties, errors, alpha=0.4, s=15)
#         axes[0].set_xlabel('é¢„æµ‹ä¸ç¡®å®šæ€§ (ç§’)', fontsize=12)
#         axes[0].set_ylabel('ç»å¯¹è¯¯å·® (ç§’)', fontsize=12)
#         axes[0].set_title(f'ä¸ç¡®å®šæ€§æ ¡å‡†\nCorr={cftnet["corr"]:.3f}, ECE={cftnet["ece"]:.2f}', fontsize=12)
#         axes[0].set_xscale('log')
#         axes[0].set_yscale('log')
#         axes[0].grid(True, alpha=0.3)
        
#         # æ·»åŠ å‚è€ƒçº¿ y=x
#         min_val = min(uncertainties.min(), errors.min()) + 1e-6
#         max_val = max(uncertainties.max(), errors.max())
#         axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, label='å®Œç¾æ ¡å‡†')
#         axes[0].legend()
        
#         # 2. é¢„æµ‹åŒºé—´è¦†ç›–
#         # è®¡ç®—80%é¢„æµ‹åŒºé—´
#         lower = y_pred - 1.28 * uncertainties  # 80%åŒºé—´
#         upper = y_pred + 1.28 * uncertainties
        
#         coverage = np.mean((y_true >= lower) & (y_true <= upper)) * 100
        
#         # ç»˜åˆ¶å‰100ä¸ªæ ·æœ¬çš„é¢„æµ‹åŒºé—´
#         n_plot = min(100, len(y_true))
#         x_idx = np.arange(n_plot)
        
#         axes[1].fill_between(x_idx, lower[:n_plot], upper[:n_plot], alpha=0.3, label='80%é¢„æµ‹åŒºé—´')
#         axes[1].plot(x_idx, y_true[:n_plot], 'o', markersize=3, label='çœŸå®å€¼', color='green')
#         axes[1].plot(x_idx, y_pred[:n_plot], 'x', markersize=3, label='é¢„æµ‹å€¼', color='red')
#         axes[1].set_xlabel('æ ·æœ¬ç´¢å¼•', fontsize=12)
#         axes[1].set_ylabel('ä¼ è¾“æ—¶é—´ (ç§’)', fontsize=12)
#         axes[1].set_title(f'é¢„æµ‹åŒºé—´è¦†ç›–\nå®é™…è¦†ç›–ç‡: {coverage:.1f}% (æœŸæœ›80%)', fontsize=12)
#         axes[1].legend()
#         axes[1].grid(True, alpha=0.3)
        
#         # 3. è¯¯å·®åˆ†å¸ƒ
#         axes[2].hist(errors, bins=50, alpha=0.7, edgecolor='black')
#         axes[2].axvline(x=cftnet['mae'], color='r', linestyle='--', label=f'MAE={cftnet["mae"]:.2f}s')
#         axes[2].set_xlabel('ç»å¯¹è¯¯å·® (ç§’)', fontsize=12)
#         axes[2].set_ylabel('é¢‘æ•°', fontsize=12)
#         axes[2].set_title('è¯¯å·®åˆ†å¸ƒ', fontsize=12)
#         axes[2].legend()
#         axes[2].grid(True, alpha=0.3)
        
#         plt.tight_layout()
#         plt.savefig('uncertainty_analysis.png', dpi=300, bbox_inches='tight')
#         print("âœ… ä¸ç¡®å®šæ€§åˆ†æå›¾å·²ä¿å­˜åˆ° uncertainty_analysis.png")
#         plt.close()

#     def generate_performance_stats(self, results):
#         """ç”Ÿæˆæ€§èƒ½ç»Ÿè®¡æ‘˜è¦"""
#         cftnet = results['CFT-Net']
#         baseline_models = {k: v for k, v in results.items() if 'CFT-Net' not in k}
        
#         # æ‰¾åˆ°æœ€ä½³åŸºçº¿ï¼ˆæŒ‰sMAPEï¼‰
#         best_baseline = min(baseline_models.items(), key=lambda x: x[1]['smape'])
#         best_baseline_name = best_baseline[0]
#         best_baseline_result = best_baseline[1]
        
#         smape_improvement = (best_baseline_result['smape'] - cftnet['smape']) / best_baseline_result['smape'] * 100
        
#         print(f"\n{'='*60}")
#         print(f"ğŸ“Š å…³é”®ç»Ÿè®¡æ‘˜è¦")
#         print(f"{'='*60}")
#         print(f"CFT-Net sMAPE: {cftnet['smape']:.2f}%")
#         print(f"æœ€ä½³åŸºçº¿ ({best_baseline_name}) sMAPE: {best_baseline_result['smape']:.2f}%")
#         print(f"sMAPE ç›¸å¯¹æ”¹å–„: {smape_improvement:.1f}%")
#         print(f"\nCFT-Net ç‰¹æœ‰ä¼˜åŠ¿:")
#         print(f"  - ä¸ç¡®å®šæ€§-è¯¯å·®ç›¸å…³æ€§: {cftnet['corr']:.3f}")
#         print(f"  - æœŸæœ›æ ¡å‡†è¯¯å·® (ECE): {cftnet['ece']:.2f}")
#         print(f"  - æä¾›é¢„æµ‹åŒºé—´ï¼Œæ”¯æŒé£é™©æ„ŸçŸ¥å†³ç­–")
#         print(f"{'='*60}")
        
#         stats = {
#             'cftnet_smape': float(cftnet['smape']),
#             'cftnet_mape': float(cftnet['mape']),
#             'cftnet_mae': float(cftnet['mae']),
#             'cftnet_corr': float(cftnet['corr']),
#             'cftnet_ece': float(cftnet['ece']),
#             'best_baseline_smape': float(best_baseline_result['smape']),
#             'best_baseline_name': best_baseline_name,
#             'smape_improvement_percent': float(smape_improvement)
#         }
        
#         with open('performance_stats_mape.json', 'w') as f:
#             json.dump(stats, f, indent=2)
        
#         return stats


# def main():
#     """ä¸»å‡½æ•°"""
#     print("="*80)
#     print("å…¬å¹³æ¨¡å‹å¯¹æ¯”è¯„ä¼°ï¼ˆåŸºäºsMAPEå’Œä¸ç¡®å®šæ€§æŒ‡æ ‡ï¼‰")
#     print("="*80)
    
#     evaluator = FairComparisonEvaluator()
#     evaluator.load_existing_model()
#     df = evaluator.load_real_training_data()
#     results, y_test = evaluator.train_all_models_on_same_data(df)
    
#     # ç”ŸæˆæŠ¥å‘Š
#     evaluator.generate_comparison_table(results)
#     evaluator.generate_prediction_scatter_plots(results, y_test)
#     evaluator.generate_uncertainty_analysis(results, y_test)
#     stats = evaluator.generate_performance_stats(results)
    
#     print(f"\n{'='*80}")
#     print("å®éªŒå®Œæˆï¼ç”Ÿæˆçš„æ–‡ä»¶:")
#     print("  - model_comparison_mape.csv: è¯¦ç»†å¯¹æ¯”è¡¨æ ¼")
#     print("  - prediction_accuracy_mape.png: é¢„æµ‹å‡†ç¡®æ€§æ•£ç‚¹å›¾")
#     print("  - uncertainty_analysis.png: CFT-Netä¸ç¡®å®šæ€§åˆ†æ")
#     print("  - performance_stats_mape.json: ç»Ÿè®¡æ‘˜è¦")
#     print(f"{'='*80}")


# if __name__ == "__main__":
#     main()
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.linear_model import LinearRegression
# from sklearn.ensemble import GradientBoostingRegressor
# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import json
# import warnings
# import sys
# import os
# import pickle  # æ·»åŠ pickleç”¨äºåŠ è½½é¢„å¤„ç†å¯¹è±¡

# warnings.filterwarnings('ignore')
# import matplotlib
# import platform

# # --- å­—ä½“é…ç½® ---
# system_name = platform.system()
# if system_name == 'Windows':
#     font_list = ['Microsoft YaHei', 'SimHei', 'SimSun']
# elif system_name == 'Darwin':
#     font_list = ['Heiti TC', 'PingFang HK', 'Arial Unicode MS']
# else:
#     font_list = ['WenQuanYi Micro Hei', 'Droid Sans Fallback', 'SimHei']

# matplotlib.rcParams['font.sans-serif'] = font_list
# matplotlib.rcParams['axes.unicode_minus'] = False

# # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
# sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

# from ml_training.modeling.real_train import CTSDualTowerModel, TransformerTower, FeatureTokenizer
# from sklearn.preprocessing import StandardScaler, LabelEncoder


# class FairComparisonEvaluator:
#     """å…¬å¹³å¯¹æ¯”è¯„ä¼°å™¨ - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ•°æ®åˆ’åˆ†å’Œé¢„å¤„ç†"""
    
#     def __init__(self):
#         self.model = None
#         # ä»è®­ç»ƒæ—¶ä¿å­˜çš„é¢„å¤„ç†å¯¹è±¡åŠ è½½ï¼Œè€Œä¸æ˜¯æ–°å»º
#         self.scaler_c = None
#         self.scaler_i = None
#         self.enc_algo = None
#         self.col_client = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
#         self.col_image = ['total_size_mb', 'avg_layer_entropy', 'text_ratio', 'layer_count', 'zero_ratio']
        
#         # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿æ•°æ®åˆ’åˆ†ä¸è®­ç»ƒæ—¶ä¸€è‡´
#         self.random_seed = 42
#         np.random.seed(self.random_seed)

#     def load_preprocessing_objects(self):
#         """åŠ è½½è®­ç»ƒæ—¶ä¿å­˜çš„é¢„å¤„ç†å¯¹è±¡ï¼ˆscalerå’Œencoderï¼‰"""
#         print("åŠ è½½è®­ç»ƒæ—¶çš„é¢„å¤„ç†å¯¹è±¡...")
#         prep_path = os.path.join('..', 'modeling', 'preprocessing_objects.pkl')
        
#         if not os.path.exists(prep_path):
#             # å°è¯•å…¶ä»–è·¯å¾„
#             alternative_paths = [
#                 'preprocessing_objects.pkl',
#                 os.path.join('..', '..', 'ml_training', 'modeling', 'preprocessing_objects.pkl'),
#             ]
#             for alt_path in alternative_paths:
#                 if os.path.exists(alt_path):
#                     prep_path = alt_path
#                     break
#             else:
#                 raise FileNotFoundError(f"æ‰¾ä¸åˆ°é¢„å¤„ç†å¯¹è±¡æ–‡ä»¶: {prep_path}ï¼Œè¯·ç¡®ä¿è®­ç»ƒä»£ç å·²è¿è¡Œå¹¶ä¿å­˜äº†è¯¥æ–‡ä»¶")
        
#         with open(prep_path, 'rb') as f:
#             prep_objects = pickle.load(f)
        
#         self.scaler_c = prep_objects['scaler_c']
#         self.scaler_i = prep_objects['scaler_i']
#         self.enc_algo = prep_objects['enc']
        
#         print(f"âœ… æˆåŠŸåŠ è½½é¢„å¤„ç†å¯¹è±¡")
#         print(f"   å®¢æˆ·ç«¯ç‰¹å¾ç»´åº¦: {self.scaler_c.n_features_in_}")
#         print(f"   é•œåƒç‰¹å¾ç»´åº¦: {self.scaler_i.n_features_in_}")
#         print(f"   ç®—æ³•ç±»åˆ«æ•°: {len(self.enc_algo.classes_)}")

#     def load_existing_model(self):
#         """åŠ è½½å·²è®­ç»ƒçš„CFT-Netæ¨¡å‹"""
#         print("åŠ è½½ç°æœ‰çš„CFT-Netæ¨¡å‹...")
        
#         # å¿…é¡»å…ˆåŠ è½½é¢„å¤„ç†å¯¹è±¡ï¼Œæ‰èƒ½ç¡®å®šç‰¹å¾ç»´åº¦
#         if self.scaler_c is None:
#             self.load_preprocessing_objects()
        
#         # æ¨¡å‹è·¯å¾„
#         model_path = os.path.join('..', 'modeling', 'cts_final_strong.pth')
        
#         if not os.path.exists(model_path):
#             alternative_paths = [
#                 'cts_final_strong.pth',
#                 os.path.join('..', '..', 'ml_training', 'modeling', 'cts_final_strong.pth'),
#             ]
#             for alt_path in alternative_paths:
#                 if os.path.exists(alt_path):
#                     model_path = alt_path
#                     print(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
#                     break
#             else:
#                 raise FileNotFoundError(f"æ‰¾ä¸åˆ°é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶: {model_path}")
        
#         # åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å‚æ•°ï¼‰
#         self.model = CTSDualTowerModel(
#             client_feats=self.scaler_c.n_features_in_,  # ä»scalerè·å–ç»´åº¦
#             image_feats=self.scaler_i.n_features_in_,
#             num_algos=len(self.enc_algo.classes_),
#             embed_dim=32
#         )
        
#         # åŠ è½½æ¨¡å‹æƒé‡
#         print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
#         checkpoint = torch.load(model_path, map_location='cpu')
        
#         if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
#             state_dict = checkpoint['model_state_dict']
#         else:
#             state_dict = checkpoint
        
#         self.model.load_state_dict(state_dict, strict=False)
#         self.model.eval()
#         print(f"âœ… æˆåŠŸåŠ è½½CFT-Netæ¨¡å‹")
    
#     def load_real_training_data(self):
#         """åŠ è½½çœŸå®çš„è®­ç»ƒæ•°æ®ï¼ˆä¸è®­ç»ƒä»£ç ä½¿ç”¨ç›¸åŒçš„æ•°æ®å¤„ç†é€»è¾‘ï¼‰"""
#         print("åŠ è½½çœŸå®çš„è®­ç»ƒæ•°æ®...")
        
#         data_path = os.path.join('..', 'modeling', 'cts_data.xlsx')
#         feature_path = os.path.join('..', 'modeling', 'image_features_database.csv')
        
#         # è¯»å–æ•°æ®ï¼ˆä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´ï¼‰
#         df_exp = pd.read_excel(data_path)
#         df_feat = pd.read_csv(feature_path)
        
#         # åˆ—åæ ‡å‡†åŒ–ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
#         rename_map = {
#             "image": "image_name", 
#             "method": "algo_name", 
#             "network_bw": "bandwidth_mbps", 
#             "network_delay": "network_rtt", 
#             "mem_limit": "mem_limit_mb"
#         }
#         df_exp = df_exp.rename(columns=rename_map)
        
#         if 'total_time' not in df_exp.columns:
#             possible_cols = [c for c in df_exp.columns if 'total_tim' in c]
#             if possible_cols: 
#                 df_exp = df_exp.rename(columns={possible_cols[0]: 'total_time'})
        
#         # è¿‡æ»¤æœ‰æ•ˆæ•°æ®ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
#         df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
#         df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
        
#         print(f"âœ… åŠ è½½æ•°æ®å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: {len(df)}")
#         return df
    
#     def prepare_features(self, df):
#         """å‡†å¤‡ç‰¹å¾æ•°æ®ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„scalerè¿›è¡Œtransformï¼Œè€Œä¸æ˜¯fitï¼‰"""
#         print("å‡†å¤‡ç‰¹å¾æ•°æ®...")
        
#         # ä½¿ç”¨è®­ç»ƒæ—¶çš„scalerè¿›è¡Œtransformï¼Œç¡®ä¿åˆ†å¸ƒä¸€è‡´
#         X_client = self.scaler_c.transform(df[self.col_client].values)  # æ³¨æ„ï¼šæ˜¯transformä¸æ˜¯fit_transformï¼
        
#         # å¤„ç†å¯èƒ½ç¼ºå¤±çš„é•œåƒç‰¹å¾åˆ—
#         available_image_cols = [c for c in self.col_image if c in df.columns]
#         if len(available_image_cols) != len(self.col_image):
#             print(f"è­¦å‘Š: é•œåƒç‰¹å¾åˆ—ä¸å®Œå…¨åŒ¹é…ï¼Œä½¿ç”¨å¯ç”¨åˆ—: {available_image_cols}")
#         X_image = self.scaler_i.transform(df[available_image_cols].values)
        
#         # ä½¿ç”¨è®­ç»ƒæ—¶çš„encoderè¿›è¡Œtransform
#         # å¤„ç†æœªè§è¿‡çš„ç®—æ³•åç§°
#         algo_names = df['algo_name'].values
#         known_algos = set(self.enc_algo.classes_)
#         unknown_algos = set(algo_names) - known_algos
        
#         if unknown_algos:
#             print(f"è­¦å‘Š: å‘ç°æœªè§è¿‡çš„ç®—æ³•: {unknown_algos}ï¼Œå°†æ˜ å°„ä¸º-1ï¼ˆå¯èƒ½åœ¨CFT-Netä¸­å‡ºé”™ï¼‰")
#             # å°†æœªçŸ¥ç®—æ³•æ›¿æ¢ä¸ºè®­ç»ƒæ—¶è§è¿‡çš„ç¬¬ä¸€ä¸ªç®—æ³•ï¼ˆä¸´æ—¶å¤„ç†ï¼‰
#             for unknown in unknown_algos:
#                 algo_names[algo_names == unknown] = self.enc_algo.classes_[0]
        
#         X_algo = self.enc_algo.transform(algo_names)
        
#         # ç›®æ ‡å€¼å¤„ç†ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼šlog1på˜æ¢ï¼‰
#         y_original = df['total_time'].values
#         y_log_transformed = np.log1p(y_original)
        
#         print(f"ç›®æ ‡å€¼ç»Ÿè®¡: å‡å€¼={y_original.mean():.2f}s, æ ‡å‡†å·®={y_original.std():.2f}s")
        
#         return X_client, X_image, X_algo, y_log_transformed, y_original
    
#     def train_all_models_on_same_data(self, df):
#         """åœ¨ç›¸åŒæ•°æ®ä¸Šè®­ç»ƒæ‰€æœ‰æ¨¡å‹è¿›è¡Œå…¬å¹³å¯¹æ¯”ï¼ˆä½¿ç”¨ä¸è®­ç»ƒä»£ç ç›¸åŒçš„æ•°æ®åˆ’åˆ†ï¼‰"""
#         print("=== åœ¨ç›¸åŒçœŸå®æ•°æ®ä¸Šè®­ç»ƒæ‰€æœ‰æ¨¡å‹ ===")
        
#         # å‡†å¤‡ç‰¹å¾ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶çš„scalerï¼‰
#         X_client, X_image, X_algo, y_log, y_orig = self.prepare_features(df)
        
#         # âœ… å…³é”®ä¿®å¤ï¼šä½¿ç”¨ä¸è®­ç»ƒä»£ç å®Œå…¨ç›¸åŒçš„æ•°æ®åˆ’åˆ†æ–¹å¼
#         N = len(df)
#         idx = np.random.permutation(N)  # ç›¸åŒçš„éšæœºç§å­ç¡®ä¿åˆ’åˆ†ä¸€è‡´
        
#         n_tr = int(N * 0.7)
#         n_val = int(N * 0.15)
#         # n_te = N - n_tr - n_val  # æµ‹è¯•é›†
        
#         # è®­ç»ƒé›†ï¼ˆç”¨äºè®­ç»ƒåŸºçº¿æ¨¡å‹ï¼‰
#         tr_idx = idx[:n_tr]
#         # éªŒè¯é›†ï¼ˆCFT-Netè®­ç»ƒæ—¶ä½¿ç”¨ï¼ŒåŸºçº¿æ¨¡å‹ä¸éœ€è¦ï¼‰
#         val_idx = idx[n_tr:n_tr+n_val]
#         # æµ‹è¯•é›†ï¼ˆç”¨äºå…¬å¹³è¯„ä¼°æ‰€æœ‰æ¨¡å‹ï¼‰
#         te_idx = idx[n_tr+n_val:]
        
#         print(f"æ•°æ®åˆ’åˆ†: è®­ç»ƒ {len(tr_idx)} | éªŒè¯ {len(val_idx)} | æµ‹è¯• {len(te_idx)}")
        
#         # è®­ç»ƒé›†ï¼ˆç”¨äºè®­ç»ƒåŸºçº¿æ¨¡å‹ï¼‰
#         X_train_combined = np.hstack([
#             X_client[tr_idx],
#             X_image[tr_idx],
#             X_algo[tr_idx].reshape(-1, 1)
#         ])
#         y_train_log = y_log[tr_idx]
        
#         # æµ‹è¯•é›†ï¼ˆç”¨äºè¯„ä¼°æ‰€æœ‰æ¨¡å‹ï¼ŒåŒ…æ‹¬CFT-Netï¼‰
#         X_test_combined = np.hstack([
#             X_client[te_idx],
#             X_image[te_idx],
#             X_algo[te_idx].reshape(-1, 1)
#         ])
#         X_test_client = X_client[te_idx]
#         X_test_image = X_image[te_idx]
#         X_test_algo = X_algo[te_idx]
#         y_test_orig = y_orig[te_idx]  # åŸå§‹å°ºåº¦çš„çœŸå®å€¼
        
#         # å¤„ç†æ— æ•ˆå€¼
#         X_train_combined = np.nan_to_num(X_train_combined, nan=0.0)
#         X_test_combined = np.nan_to_num(X_test_combined, nan=0.0)
#         y_train_log = np.nan_to_num(y_train_log, nan=np.median(y_train_log))
        
#         results = {}
        
#         # 1. çº¿æ€§å›å½’
#         print("è®­ç»ƒ Linear Regression...")
#         lr_model = LinearRegression()
#         lr_model.fit(X_train_combined, y_train_log)
#         lr_pred_log = lr_model.predict(X_test_combined)
#         lr_pred_log = np.clip(lr_pred_log, 0.1, np.log1p(1200.0))
#         lr_pred_orig = np.expm1(lr_pred_log)
#         results['Linear Regression'] = {
#             'predictions': lr_pred_orig,
#             'rmse': np.sqrt(mean_squared_error(y_test_orig, lr_pred_orig)),
#             'mae': mean_absolute_error(y_test_orig, lr_pred_orig),
#             'r2': r2_score(y_test_orig, lr_pred_orig)
#         }
        
#         # 2. éšæœºæ£®æ—
#         print("è®­ç»ƒ Random Forest...")
#         rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
#         rf_model.fit(X_train_combined, y_train_log)
#         rf_pred_log = rf_model.predict(X_test_combined)
#         rf_pred_log = np.clip(rf_pred_log, 0.1, np.log1p(1200.0))
#         rf_pred_orig = np.expm1(rf_pred_log)
#         results['Random Forest'] = {
#             'predictions': rf_pred_orig,
#             'rmse': np.sqrt(mean_squared_error(y_test_orig, rf_pred_orig)),
#             'mae': mean_absolute_error(y_test_orig, rf_pred_orig),
#             'r2': r2_score(y_test_orig, rf_pred_orig)
#         }
        
#         # 3. æ¢¯åº¦æå‡
#         print("è®­ç»ƒ Gradient Boosting...")
#         gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
#         gb_model.fit(X_train_combined, y_train_log)
#         gb_pred_log = gb_model.predict(X_test_combined)
#         gb_pred_log = np.clip(gb_pred_log, 0.1, np.log1p(1200.0))
#         gb_pred_orig = np.expm1(gb_pred_log)
#         results['Gradient Boosting'] = {
#             'predictions': gb_pred_orig,
#             'rmse': np.sqrt(mean_squared_error(y_test_orig, gb_pred_orig)),
#             'mae': mean_absolute_error(y_test_orig, gb_pred_orig),
#             'r2': r2_score(y_test_orig, gb_pred_orig)
#         }
        
#         # 4. CFT-Netï¼ˆä½¿ç”¨æµ‹è¯•é›†è¯„ä¼°ï¼Œä¸åŸºçº¿æ¨¡å‹å®Œå…¨ä¸€è‡´ï¼‰
#         print("è¯„ä¼° CFT-Net...")
#         cftnet_pred = self.predict_with_cftnet(X_test_client, X_test_image, X_test_algo)
#         results['CFT-Net'] = {
#             'predictions': cftnet_pred,
#             'rmse': np.sqrt(mean_squared_error(y_test_orig, cftnet_pred)),
#             'mae': mean_absolute_error(y_test_orig, cftnet_pred),
#             'r2': r2_score(y_test_orig, cftnet_pred)
#         }
        
#         return results, y_test_orig
    
#     def predict_with_cftnet(self, X_client, X_image, X_algo):
#         """ä½¿ç”¨CFT-Netè¿›è¡Œé¢„æµ‹"""
#         device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#         self.model = self.model.to(device)
        
#         cx = torch.FloatTensor(X_client).to(device)
#         ix = torch.FloatTensor(X_image).to(device)
#         ax = torch.LongTensor(X_algo).to(device)
        
#         with torch.no_grad():
#             preds = self.model(cx, ix, ax)
#             gamma = preds[:, 0]  # é¢„æµ‹å€¼
            
#         predictions = np.expm1(gamma.cpu().numpy())
#         predictions = np.nan_to_num(predictions, nan=np.median(predictions))
#         predictions = np.clip(predictions, 0.1, 1200.0)
        
#         return predictions
    
#     def generate_comparison_table(self, results):
#         """ç”Ÿæˆæ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨æ ¼"""
#         print("\n" + "=" * 80)
#         print("æ¨¡å‹é¢„æµ‹æ€§èƒ½å¯¹æ¯”ï¼ˆåŸºäºç›¸åŒæµ‹è¯•é›†ï¼‰")
#         print("=" * 80)
#         print(f"{'æ¨¡å‹':<25} {'RMSE (s)':<12} {'MAE (s)':<12} {'RÂ²':<12} {'ç›¸æ¯”æœ€ä½³åŸºçº¿':<15}")
#         print("-" * 80)
        
#         # æ‰¾åˆ°æœ€ä½³åŸºçº¿
#         baseline_models = {k: v for k, v in results.items() if 'CFT-Net' not in k}
#         best_baseline = min(baseline_models.items(), key=lambda x: x[1]['rmse'])
#         best_baseline_rmse = best_baseline[1]['rmse']
        
#         for name, result in results.items():
#             improvement = ""
#             if 'CFT-Net' in name:
#                 imp = (best_baseline_rmse - result['rmse']) / best_baseline_rmse * 100
#                 symbol = "â†“" if imp > 0 else "â†‘"
#                 improvement = f"{symbol} {abs(imp):.1f}%"
            
#             print(f"{name:<25} {result['rmse']:<12.4f} {result['mae']:<12.4f} "
#                   f"{result['r2']:<12.4f} {improvement:<15}")
        
#         print("=" * 80)
        
#         # ä¿å­˜CSV
#         comparison_data = []
#         for name, result in results.items():
#             comparison_data.append({
#                 'Model': name,
#                 'RMSE': result['rmse'],
#                 'MAE': result['mae'],
#                 'R2': result['r2']
#             })
#         pd.DataFrame(comparison_data).to_csv('model_comparison.csv', index=False)
#         print("âœ… ç»“æœå·²ä¿å­˜åˆ° model_comparison.csv")
    
#     def generate_prediction_scatter_plots(self, results, y_true):
#         """ç”Ÿæˆé¢„æµ‹å€¼vsçœŸå®å€¼æ•£ç‚¹å›¾"""
#         fig, axes = plt.subplots(2, 2, figsize=(15, 12))
#         fig.suptitle('æ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§å¯¹æ¯”', fontsize=16, fontweight='bold')
        
#         models = list(results.keys())
#         positions = [(0,0), (0,1), (1,0), (1,1)]
        
#         for i, model in enumerate(models[:4]):
#             row, col = positions[i]
#             ax = axes[row, col]
#             y_pred = results[model]['predictions']
            
#             ax.scatter(y_true, y_pred, alpha=0.5, s=20, edgecolors='none')
            
#             # å®Œç¾é¢„æµ‹çº¿
#             min_val = min(y_true.min(), y_pred.min())
#             max_val = max(y_true.max(), y_pred.max())
#             ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='å®Œç¾é¢„æµ‹')
            
#             rmse = results[model]['rmse']
#             r2 = results[model]['r2']
            
#             ax.set_xlabel('çœŸå®ä¼ è¾“æ—¶é—´ (ç§’)', fontsize=11)
#             ax.set_ylabel('é¢„æµ‹ä¼ è¾“æ—¶é—´ (ç§’)', fontsize=11)
#             ax.set_title(f'{model}\nRMSE={rmse:.3f}s, RÂ²={r2:.3f}', fontsize=12)
#             ax.legend()
#             ax.grid(True, alpha=0.3)
        
#         plt.tight_layout()
#         plt.savefig('prediction_accuracy.png', dpi=300, bbox_inches='tight')
#         print("âœ… æ•£ç‚¹å›¾å·²ä¿å­˜åˆ° prediction_accuracy.png")
#         plt.close()

#     def generate_performance_stats(self, results):
#         """ç”Ÿæˆæ€§èƒ½ç»Ÿè®¡æ‘˜è¦"""
#         cftnet_result = results['CFT-Net']
#         baseline_models = {k: v for k, v in results.items() if 'CFT-Net' not in k}
#         best_baseline = min(baseline_models.items(), key=lambda x: x[1]['rmse'])
#         best_baseline_result = best_baseline[1]
#         best_baseline_name = best_baseline[0]
        
#         rmse_improvement = (best_baseline_result['rmse'] - cftnet_result['rmse']) / best_baseline_result['rmse'] * 100
        
#         print(f"\n=== å…³é”®ç»Ÿè®¡ ===")
#         print(f"CFT-Net RMSE: {cftnet_result['rmse']:.4f}s")
#         print(f"æœ€ä½³åŸºçº¿ ({best_baseline_name}) RMSE: {best_baseline_result['rmse']:.4f}s")
#         print(f"RMSE æ”¹å–„: {rmse_improvement:.2f}%")
#         print(f"RÂ²: {cftnet_result['r2']:.4f}")
        
#         stats = {
#             'cftnet_rmse': float(cftnet_result['rmse']),
#             'best_baseline_rmse': float(best_baseline_result['rmse']),
#             'best_baseline_name': best_baseline_name,
#             'rmse_improvement_percent': float(rmse_improvement),
#             'cftnet_r2': float(cftnet_result['r2'])
#         }
        
#         with open('performance_stats.json', 'w') as f:
#             json.dump(stats, f, indent=2)
        
#         return stats


# def main():
#     """ä¸»å‡½æ•°"""
#     print("=== å…¬å¹³æ¨¡å‹å¯¹æ¯”è¯„ä¼°ï¼ˆä½¿ç”¨ç›¸åŒæ•°æ®åˆ’åˆ†å’Œé¢„å¤„ç†ï¼‰===")
    
#     evaluator = FairComparisonEvaluator()
    
#     # åŠ è½½é¢„å¤„ç†å¯¹è±¡å’Œæ¨¡å‹
#     evaluator.load_existing_model()
    
#     # åŠ è½½æ•°æ®
#     df = evaluator.load_real_training_data()
    
#     # è®­ç»ƒå’Œè¯„ä¼°
#     results, y_test = evaluator.train_all_models_on_same_data(df)
    
#     # ç”ŸæˆæŠ¥å‘Š
#     evaluator.generate_comparison_table(results)
#     evaluator.generate_prediction_scatter_plots(results, y_test)
#     stats = evaluator.generate_performance_stats(results)
    
#     print(f"\n=== å®éªŒå®Œæˆ ===")

# if __name__ == "__main__":
#     main()