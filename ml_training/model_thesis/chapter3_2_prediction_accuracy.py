import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor
import torch
import torch.nn as nn
import torch.nn.functional as F
import json
import warnings
import sys
import os
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
import matplotlib
import platform

# --- ğŸš€ æ ¸å¿ƒä¿®å¤ä»£ç å¼€å§‹ ---
system_name = platform.system()
if system_name == 'Windows':
    # Windows ä¼˜å…ˆç”¨å¾®è½¯é›…é»‘ï¼Œä¿åº•ç”¨é»‘ä½“
    font_list = ['Microsoft YaHei', 'SimHei', 'SimSun']
elif system_name == 'Darwin':
    # Mac OS ä¼˜å…ˆç”¨é»‘ä½“-ç®€
    font_list = ['Heiti TC', 'PingFang HK', 'Arial Unicode MS']
else:
    # Linux (Docker/Ubuntu) é€šå¸¸æ²¡æœ‰å¾®è½¯å­—ä½“ï¼Œä¼˜å…ˆç”¨ WenQuanYi æˆ– Droid Sans Fallback
    font_list = ['WenQuanYi Micro Hei', 'Droid Sans Fallback', 'SimHei']

# è¿™ä¸€è¡Œæ˜¯é­”æ³•ï¼šè‡ªåŠ¨å¯»æ‰¾ç³»ç»Ÿé‡Œå­˜åœ¨çš„ç¬¬ä¸€ä¸ªä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = font_list
matplotlib.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå· '-' æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
# --- ğŸš€ æ ¸å¿ƒä¿®å¤ä»£ç ç»“æŸ ---

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from ml_training.modeling.train import CTSDualTowerModel, TransformerTower, FeatureTokenizer
from sklearn.preprocessing import StandardScaler, LabelEncoder

class FairComparisonEvaluator:
    """å…¬å¹³å¯¹æ¯”è¯„ä¼°å™¨ - ä½¿ç”¨å®Œæ•´ç®—æ³•é›†è¿›è¡Œå¯¹æ¯”"""
    
    def __init__(self):
        self.model = None
        self.scaler_c = StandardScaler()
        self.scaler_i = StandardScaler()
        self.enc_algo = LabelEncoder()
        self.col_client = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
        self.col_image = ['total_size_mb', 'avg_layer_entropy', 'text_ratio', 'layer_count', 'zero_ratio']
        
    def load_existing_model(self):
        """åŠ è½½å·²è®­ç»ƒçš„CFT-Netæ¨¡å‹ï¼ˆä½¿ç”¨å®Œæ•´10ç§ç®—æ³•ï¼‰"""
        print("åŠ è½½ç°æœ‰çš„CFT-Netæ¨¡å‹ï¼ˆ10ç§ç®—æ³•ç‰ˆæœ¬ï¼‰...")
        
        # æ¨¡å‹è·¯å¾„
        model_path = os.path.join('..', 'modeling', 'cts_best_model_full_modified.pth')
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        
        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶çš„å®Œæ•´å‚æ•°ï¼‰
        self.model = CTSDualTowerModel(
            client_feats=len(self.col_client),
            image_feats=len(self.col_image),
            num_algos=10,  # ä½¿ç”¨å®Œæ•´çš„10ç§ç®—æ³•
            embed_dim=32
        )
        
        # åŠ è½½æ¨¡å‹æƒé‡
        state_dict = torch.load(model_path, map_location='cpu')
        self.model.load_state_dict(state_dict)
        self.model.eval()
        print(f"âœ… æˆåŠŸåŠ è½½CFT-Netæ¨¡å‹ï¼ˆ10ç§ç®—æ³•ï¼‰")
    
    def load_real_training_data(self):
        """åŠ è½½çœŸå®çš„è®­ç»ƒæ•°æ®"""
        print("åŠ è½½çœŸå®çš„cts_data.xlsxè®­ç»ƒæ•°æ®...")
        
        # æ•°æ®è·¯å¾„
        data_path = os.path.join('..', 'modeling', 'cts_data.xlsx')
        feature_path = os.path.join('..', 'modeling', 'image_features_database.csv')
        
        # è¯»å–æ•°æ®
        df_exp = pd.read_excel(data_path)
        df_feat = pd.read_csv(feature_path)
        
        # æ•°æ®é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        rename_map = {
            "image": "image_name", "method": "algo_name",
            "network_bw": "bandwidth_mbps", "network_delay": "network_rtt",
            "mem_limit": "mem_limit_mb"
        }
        df_exp = df_exp.rename(columns=rename_map)
        
        if 'total_time' not in df_exp.columns:
            possible_cols = [c for c in df_exp.columns if 'total_tim' in c]
            if possible_cols: 
                df_exp = df_exp.rename(columns={possible_cols[0]: 'total_time'})
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
        
        if 'mem_limit_mb' not in df_exp.columns: 
            df_exp['mem_limit_mb'] = 1024.0
        
        # åˆå¹¶ç‰¹å¾æ•°æ®
        df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
        print(f"âœ… åŠ è½½æ•°æ®å®Œæˆï¼Œæ ·æœ¬æ•°: {len(df)}")
        
        # æ˜¾ç¤ºç®—æ³•åˆ†å¸ƒ
        print("\nç®—æ³•åˆ†å¸ƒåˆ†æ:")
        algo_counts = df['algo_name'].value_counts()
        total_samples = len(df)
        for algo, count in algo_counts.items():
            percentage = (count / total_samples) * 100
            print(f"  {algo:15s}: {count:4d} æ ·æœ¬ ({percentage:5.1f}%)")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        print("\nå„ç®—æ³•æ€§èƒ½ç»Ÿè®¡:")
        algo_stats = df.groupby('algo_name')['total_time'].agg(['mean', 'std', 'count'])
        algo_stats = algo_stats.sort_values('mean')
        for algo in algo_stats.index:
            mean_time = algo_stats.loc[algo, 'mean']
            std_time = algo_stats.loc[algo, 'std']
            count = algo_stats.loc[algo, 'count']
            print(f"  {algo:15s}: å¹³å‡ {mean_time:6.2f}s Â± {std_time:5.2f}s (n={count})")
        
        return df
    
    def prepare_features(self, df):
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        print("å‡†å¤‡ç‰¹å¾æ•°æ®...")
        
        # ç‰¹å¾åˆ—
        col_client = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
        col_image = ['total_size_mb', 'avg_layer_entropy', 'text_ratio', 'layer_count', 'zero_ratio']
        
        # æ ‡å‡†åŒ–å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        X_client = self.scaler_c.fit_transform(df[col_client].values)
        X_client = self.scaler_c.fit_transform(df[col_client].values)
        X_image = self.scaler_i.fit_transform(df[col_image].values)
        X_algo = self.enc_algo.fit_transform(df['algo_name'].values)
        
        # ç›®æ ‡å€¼å¤„ç† - åº”ç”¨logå˜æ¢å¤„ç†é•¿å°¾åˆ†å¸ƒ
        y_original = df['total_time'].values
        y_log_transformed = np.log1p(y_original)  # log(1+x)å˜æ¢
        
        print(f"ç›®æ ‡å€¼åˆ†å¸ƒç»Ÿè®¡:")
        print(f"  åŸå§‹å€¼èŒƒå›´: {y_original.min():.2f} - {y_original.max():.2f} ç§’")
        print(f"  åŸå§‹å€¼å‡å€¼: {y_original.mean():.2f} Â± {y_original.std():.2f} ç§’")
        print(f"  å˜å¼‚ç³»æ•°: {y_original.std()/y_original.mean():.3f}")
        print(f"  Logå˜æ¢åèŒƒå›´: {y_log_transformed.min():.2f} - {y_log_transformed.max():.2f}")
        print(f"  Logå˜æ¢åå‡å€¼: {y_log_transformed.mean():.2f} Â± {y_log_transformed.std():.2f}")
        
        return X_client, X_image, X_algo, y_log_transformed, y_original
    
    def train_all_models_on_same_data(self, df):
        """åœ¨ç›¸åŒæ•°æ®ä¸Šè®­ç»ƒæ‰€æœ‰æ¨¡å‹è¿›è¡Œå…¬å¹³å¯¹æ¯”"""
        print("=== åœ¨ç›¸åŒçœŸå®æ•°æ®ä¸Šè®­ç»ƒæ‰€æœ‰æ¨¡å‹ ===")
        
        # å‡†å¤‡ç‰¹å¾
        X_client, X_image, X_algo, y_log, y_orig = self.prepare_features(df)
        
        # åˆ†å‰²è®­ç»ƒæµ‹è¯•é›†
        split_idx = int(len(df) * 0.8)
        X_train = (X_client[:split_idx], X_image[:split_idx], X_algo[:split_idx])
        X_test = (X_client[split_idx:], X_image[split_idx:], X_algo[split_idx:])
        y_train_orig = y_orig[:split_idx]
        y_test_orig = y_orig[split_idx:]
        y_train_log = y_log[:split_idx]
        y_test_log = y_log[split_idx:]
        
        # å‡†å¤‡åˆå¹¶ç‰¹å¾ç”¨äºä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹
        X_train_combined = np.hstack([
            X_train[0],  # å®¢æˆ·ç«¯ç‰¹å¾
            X_train[1],  # é•œåƒç‰¹å¾
            X_train[2].reshape(-1, 1)  # ç®—æ³•ç‰¹å¾
        ])
        X_test_combined = np.hstack([
            X_test[0],
            X_test[1], 
            X_test[2].reshape(-1, 1)
        ])
        
        # å¤„ç†æ•°æ®ä¸­çš„æ— æ•ˆå€¼
        X_train_combined = np.nan_to_num(X_train_combined, nan=0.0)
        X_test_combined = np.nan_to_num(X_test_combined, nan=0.0)
        y_train_log = np.nan_to_num(y_train_log, nan=np.median(y_train_log))
        y_test_log = np.nan_to_num(y_test_log, nan=np.median(y_test_log))
        
        results = {}
        
        # 1. è®­ç»ƒçº¿æ€§å›å½’ï¼ˆåœ¨logç©ºé—´è®­ç»ƒï¼‰
        print("è®­ç»ƒ Linear Regression (log-space)...")
        lr_model = LinearRegression()
        lr_model.fit(X_train_combined, y_train_log)
        lr_pred_log = lr_model.predict(X_test_combined)
        lr_pred_log = np.clip(lr_pred_log, 0.1, np.log1p(1200.0))  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        lr_pred_orig = np.expm1(lr_pred_log)  # è½¬æ¢å›åŸå§‹å°ºåº¦
        results['Linear Regression'] = {
            'model': lr_model,
            'predictions': lr_pred_orig,
            'rmse': np.sqrt(mean_squared_error(y_test_orig, lr_pred_orig)),
            'mae': mean_absolute_error(y_test_orig, lr_pred_orig),
            'r2': r2_score(y_test_orig, lr_pred_orig)
        }
        
        # 2. è®­ç»ƒéšæœºæ£®æ—ï¼ˆåœ¨logç©ºé—´è®­ç»ƒï¼‰
        print("è®­ç»ƒ Random Forest (log-space)...")
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        rf_model.fit(X_train_combined, y_train_log)
        rf_pred_log = rf_model.predict(X_test_combined)
        rf_pred_log = np.clip(rf_pred_log, 0.1, np.log1p(1200.0))
        rf_pred_orig = np.expm1(rf_pred_log)
        results['Random Forest'] = {
            'model': rf_model,
            'predictions': rf_pred_orig,
            'rmse': np.sqrt(mean_squared_error(y_test_orig, rf_pred_orig)),
            'mae': mean_absolute_error(y_test_orig, rf_pred_orig),
            'r2': r2_score(y_test_orig, rf_pred_orig)
        }
        
        # 3. è®­ç»ƒæ¢¯åº¦æå‡ï¼ˆåœ¨logç©ºé—´è®­ç»ƒï¼‰
        print("è®­ç»ƒ Gradient Boosting (log-space)...")
        gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        gb_model.fit(X_train_combined, y_train_log)
        gb_pred_log = gb_model.predict(X_test_combined)
        gb_pred_log = np.clip(gb_pred_log, 0.1, np.log1p(1200.0))
        gb_pred_orig = np.expm1(gb_pred_log)
        results['Gradient Boosting'] = {
            'model': gb_model,
            'predictions': gb_pred_orig,
            'rmse': np.sqrt(mean_squared_error(y_test_orig, gb_pred_orig)),
            'mae': mean_absolute_error(y_test_orig, gb_pred_orig),
            'r2': r2_score(y_test_orig, gb_pred_orig)
        }
        
        # 4. ä½¿ç”¨é¢„è®­ç»ƒçš„CFT-Netï¼ˆå®Œæ•´10ç§ç®—æ³•ï¼‰- æ³¨æ„ï¼šCFT-Netå·²ç»åœ¨logç©ºé—´è®­ç»ƒ
        print("ä½¿ç”¨é¢„è®­ç»ƒçš„ CFT-Netï¼ˆ10ç§ç®—æ³•ï¼‰...")
        cftnet_pred = self.predict_with_cftnet_full_algorithms(X_test[0], X_test[1], X_test[2])
        results['CFT-Net (10 algorithms)'] = {
            'predictions': cftnet_pred,
            'rmse': np.sqrt(mean_squared_error(y_test_orig, cftnet_pred)),
            'mae': mean_absolute_error(y_test_orig, cftnet_pred),
            'r2': r2_score(y_test_orig, cftnet_pred)
        }
        
        return results, y_test_orig
    
    def predict_with_cftnet_full_algorithms(self, X_client, X_image, X_algo):
        """ä½¿ç”¨CFT-Netè¿›è¡Œé¢„æµ‹ï¼ˆä½¿ç”¨å®Œæ•´10ç§ç®—æ³•ï¼‰"""
        # è½¬æ¢ä¸ºtorch tensors
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = self.model.to(device)
        
        cx = torch.FloatTensor(X_client).to(device)
        ix = torch.FloatTensor(X_image).to(device)
        ax = torch.LongTensor(X_algo).to(device)
        
        # é¢„æµ‹
        with torch.no_grad():
            preds = self.model(cx, ix, ax)
            gamma = preds[:, 0]  # åªéœ€è¦gammaä½œä¸ºé¢„æµ‹å€¼
            
        # è½¬æ¢å›åŸå§‹å°ºåº¦
        predictions = np.expm1(gamma.cpu().numpy())
        predictions = np.nan_to_num(predictions, nan=np.median(predictions))
        predictions = np.clip(predictions, 0.1, 1200.0)
        
        return predictions
    
    def generate_comparison_table(self, results):
        """ç”Ÿæˆæ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨æ ¼"""
        print("\nè¡¨3.1 æ¨¡å‹é¢„æµ‹æ€§èƒ½å¯¹æ¯”ï¼ˆåŸºäºçœŸå®æ•°æ®ï¼Œå®Œæ•´ç®—æ³•é›†ï¼‰")
        print("=" * 75)
        print(f"{'æ¨¡å‹':<25} {'RMSE':<12} {'MAE':<12} {'RÂ²':<12}")
        print("=" * 75)
        
        # æ‰¾åˆ°æœ€å¥½çš„åŸºçº¿æ¨¡å‹ç”¨äºæ¯”è¾ƒ
        baseline_models = {k: v for k, v in results.items() if 'CFT-Net' not in k}
        best_baseline = min(baseline_models.items(), key=lambda x: x[1]['rmse'])
        best_baseline_rmse = best_baseline[1]['rmse']
        best_baseline_name = best_baseline[0]
        
        for name, result in results.items():
            improvement = ""
            if 'CFT-Net' in name:
                improvement_direction = "æå‡" if result['rmse'] < best_baseline_rmse else "ä¸‹é™"
                improvement_percent = abs((best_baseline_rmse - result['rmse'])/best_baseline_rmse*100)
                improvement = f" (ç›¸æ¯”{best_baseline_name}{'æå‡' if result['rmse'] < best_baseline_rmse else 'ä¸‹é™'} {improvement_percent:.1f}%)"
            
            print(f"{name:<25} {result['rmse']:<12.4f} {result['mae']:<12.4f} {result['r2']:<12.4f}{improvement}")
        
        print("=" * 75)
        
        # ä¿å­˜ä¸ºCSV
        comparison_data = []
        for name, result in results.items():
            comparison_data.append({
                'Model': name,
                'RMSE': result['rmse'],
                'MAE': result['mae'],
                'R2': result['r2']
            })
        
        df_comparison = pd.DataFrame(comparison_data)
        df_comparison.to_csv('table_3_1_model_comparison.csv', index=False)
    
    def generate_prediction_scatter_plots(self, results, y_true):
        """ç”Ÿæˆé¢„æµ‹å€¼vsçœŸå®å€¼æ•£ç‚¹å›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('å›¾3.4 æ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§å¯¹æ¯”ï¼ˆå®Œæ•´ç®—æ³•é›†ï¼‰', fontsize=16, fontweight='bold')
        
        # ä½¿ç”¨å®é™…å­˜åœ¨çš„æ¨¡å‹
        available_models = [name for name in ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'CFT-Net (10 algorithms)'] if name in results]
        positions = [(0,0), (0,1), (1,0), (1,1)]
        
        for i, model in enumerate(available_models[:4]):  # æœ€å¤šæ˜¾ç¤º4ä¸ªæ¨¡å‹
            if i < len(positions):
                row, col = positions[i]
                ax = axes[row, col]
                y_pred = results[model]['predictions']
                
                # ç»˜åˆ¶æ•£ç‚¹å›¾
                ax.scatter(y_true, y_pred, alpha=0.6, s=20)
                
                # ç»˜åˆ¶å®Œç¾é¢„æµ‹çº¿
                min_val = min(min(y_true), min(y_pred))
                max_val = max(max(y_true), max(y_pred))
                ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)
                
                # è®¡ç®—æŒ‡æ ‡
                rmse = results[model]['rmse']
                r2 = results[model]['r2']
                
                ax.set_xlabel('çœŸå®ä¼ è¾“æ—¶é—´ (ç§’)')
                ax.set_ylabel('é¢„æµ‹ä¼ è¾“æ—¶é—´ (ç§’)')
                ax.set_title(f'{model}\nRMSE={rmse:.3f}, RÂ²={r2:.3f}')
                ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('figure_3_4_prediction_accuracy.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def generate_performance_stats(self, results):
        """ç”Ÿæˆæ€§èƒ½ç»Ÿè®¡æ‘˜è¦"""
        cftnet_result = results['CFT-Net (10 algorithms)']
        
        # æ‰¾åˆ°æœ€å¥½çš„åŸºçº¿æ¨¡å‹
        baseline_models = {k: v for k, v in results.items() if 'CFT-Net' not in k}
        best_baseline = min(baseline_models.items(), key=lambda x: x[1]['rmse'])
        best_baseline_result = best_baseline[1]
        best_baseline_name = best_baseline[0]
        
        rmse_improvement = (best_baseline_result['rmse'] - cftnet_result['rmse']) / best_baseline_result['rmse'] * 100
        r2_value = cftnet_result['r2'] * 100
        
        print(f"\n=== ç¬¬ä¸‰ç« å…³é”®ç»Ÿè®¡ ===")
        improvement_word = "æå‡" if rmse_improvement > 0 else "ä¸‹é™"
        print(f"CFT-Net(10ç®—æ³•)çš„RMSEä¸º {cftnet_result['rmse']:.3f}ï¼Œç›¸æ¯”{best_baseline_name}({best_baseline_result['rmse']:.3f}){improvement_word}äº† {abs(rmse_improvement):.1f}%ã€‚")
        print(f"RÂ²è¾¾åˆ° {r2_value:.1f}%ï¼Œè¯´æ˜æ¨¡å‹è§£é‡Šäº†{r2_value:.1f}%çš„æ€§èƒ½æ³¢åŠ¨ã€‚")
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats = {
            'cftnet_rmse': cftnet_result['rmse'],
            'best_baseline_rmse': best_baseline_result['rmse'],
            'best_baseline_name': best_baseline_name,
            'rmse_improvement_percent': rmse_improvement,
            'cftnet_r2_percent': r2_value
        }
        
        with open('chapter3_2_statistics.json', 'w') as f:
            json.dump(stats, f, indent=2)
        
        return stats

def main():
    """ä¸»å‡½æ•°"""
    print("=== ç¬¬ä¸‰ç« å®éªŒï¼šåŸºäºçœŸå®æ•°æ®çš„å…¬å¹³æ¨¡å‹å¯¹æ¯”ï¼ˆå®Œæ•´ç®—æ³•é›†ï¼‰===")
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = FairComparisonEvaluator()
    
    # åŠ è½½ç°æœ‰æ¨¡å‹
    evaluator.load_existing_model()
    
    # åŠ è½½çœŸå®è®­ç»ƒæ•°æ®
    df = evaluator.load_real_training_data()
    
    # åœ¨ç›¸åŒæ•°æ®ä¸Šè®­ç»ƒæ‰€æœ‰æ¨¡å‹è¿›è¡Œå…¬å¹³å¯¹æ¯”
    results, y_test = evaluator.train_all_models_on_same_data(df)
    
    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    evaluator.generate_comparison_table(results)
    
    # ç”Ÿæˆæ•£ç‚¹å›¾
    evaluator.generate_prediction_scatter_plots(results, y_test)
    
    # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
    stats = evaluator.generate_performance_stats(results)
    
    print(f"\n=== å®éªŒå®Œæˆ ===")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print("- table_3_1_model_comparison.csv: æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨")
    print("- figure_3_4_prediction_accuracy.png: é¢„æµ‹å‡†ç¡®æ€§å¯¹æ¯”å›¾")
    print("- chapter3_2_statistics.json: æ€§èƒ½æå‡ç»Ÿè®¡")

if __name__ == "__main__":
    main()