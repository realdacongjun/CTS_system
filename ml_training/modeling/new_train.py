import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from scipy.stats import spearmanr
import pickle
import random
import math
import platform
import matplotlib

# ==============================================================================
# 0. åŸºç¡€é…ç½®
# ==============================================================================
system_name = platform.system()
if system_name == 'Windows':
    font_list = ['Microsoft YaHei', 'SimHei']
elif system_name == 'Darwin':
    font_list = ['Heiti TC', 'PingFang HK']
else:
    font_list = ['WenQuanYi Micro Hei', 'Droid Sans Fallback']
    
matplotlib.rcParams['font.sans-serif'] = font_list
matplotlib.rcParams['axes.unicode_minus'] = False 

def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

set_seed(42)

# ==============================================================================
# 1. è¶…å‚æ•°é…ç½® (ç»ˆæå¼ºçº¦æŸç‰ˆ)
# ==============================================================================
CONFIG = {
    "lr": 0.0005,              
    "weight_decay": 1e-4,      
    "epochs": 200,             
    "patience": 15,            # æ¿€è¿›æ—©åœ
    "batch_size": 128,         
    "embed_dim": 32,           
    
    # å¼ºçº¦æŸå‚æ•°
    "reg_coeff": 1.0,          # ã€å¼ºã€‘æ‹‰æ»¡æƒ©ç½š
    "warmup_epochs": 3,        # ã€å¿«ã€‘å‡ ä¹ç«‹å³ä»‹å…¥
    
    "data_path": "cts_data.xlsx",
    "feature_path": "image_features_database.csv",
    "model_save_path": "cts_final_strong.pth",
}

# ==============================================================================
# 2. æŸå¤±å‡½æ•°ï¼šSymmetric Strong EUB
# ==============================================================================
def nig_nll_loss(y, gamma, v, alpha, beta):
    two_blambda = 2 * beta * (1 + v)
    nll = 0.5 * torch.log(np.pi / v) \
        - alpha * torch.log(two_blambda) \
        + (alpha + 0.5) * torch.log(v * (y - gamma)**2 + two_blambda) \
        + torch.lgamma(alpha) - torch.lgamma(alpha + 0.5)
    return nll.mean()

def strong_eub_reg_loss(y, gamma, v, alpha, beta):
    """
    ç»ˆæä¿åº•ç‰ˆï¼šå¼ºçº¦æŸ + å¯¹ç§°æƒ©ç½š
    ç›®æ ‡ï¼šå¼ºåˆ¶ Ratio = Error/Std æ¥è¿‘ 1
    """
    error = torch.abs(y - gamma)
    
    # è®¡ç®—æ ‡å‡†å·®
    var = beta / (v * (alpha - 1) + 1e-6)
    std = torch.sqrt(var + 1e-6)
    
    # æ¯”ç‡è®¡ç®— (å¸¦æˆªæ–­)
    raw_ratio = error / (std + 1e-6)
    ratio = torch.clamp(raw_ratio, max=5.0) # é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
    
    # å¯¹ç§°æƒ©ç½š (Symmetric Penalty)
    # Ratio > 1 (ç›²ç›®è‡ªä¿¡) -> (Ratio-1)^2 -> æƒ©ç½š
    # Ratio < 1 (è¿‡åº¦ä¿å®ˆ) -> (Ratio-1)^2 -> æƒ©ç½š
    # é€¼è¿«æ¨¡å‹å­¦ä¼š calibration
    penalty = (ratio - 1.0)**2 
    
    # Evidence æˆªæ–­
    evidence = torch.clamp(2 * v + alpha, max=20.0)
    
    # æœ€ç»ˆæ­£åˆ™
    reg = penalty * torch.log1p(evidence)
    
    return reg.mean()

def evidential_loss(pred, target, epoch):
    gamma, v, alpha, beta = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]
    target = target.view(-1)
    
    loss_nll = nig_nll_loss(target, gamma, v, alpha, beta)
    loss_reg = strong_eub_reg_loss(target, gamma, v, alpha, beta)
    
    # å¿«é€Ÿ Warmup
    if epoch < CONFIG["warmup_epochs"]:
        reg_weight = 0.0
    else:
        # 5è½®å†…æ‹‰æ»¡
        progress = min(1.0, (epoch - CONFIG["warmup_epochs"]) / 5)
        reg_weight = CONFIG["reg_coeff"] * progress
    
    total_loss = loss_nll + reg_weight * loss_reg
    return total_loss, loss_nll.item(), loss_reg.item()

# ==============================================================================
# 3. æ¨¡å‹å®šä¹‰ (Gated Fusion)
# ==============================================================================
class FeatureTokenizer(nn.Module):
    def __init__(self, num_features, embed_dim):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
        self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
        self.norm = nn.LayerNorm(embed_dim)
    def forward(self, x):
        return self.norm(x.unsqueeze(-1) * self.weights + self.biases)

class TransformerTower(nn.Module):
    def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
        super().__init__()
        self.tokenizer = FeatureTokenizer(num_features, embed_dim)
        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
            batch_first=True, dropout=0.1, activation="gelu"
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
    def forward(self, x):
        tokens = self.tokenizer(x)
        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)
        out = self.transformer(torch.cat((cls_tokens, tokens), dim=1))
        return out[:, 0, :]

class CTSDualTowerModel(nn.Module):
    def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
        super().__init__()
        self.client_tower = TransformerTower(client_feats, embed_dim)
        self.image_tower = TransformerTower(image_feats, embed_dim)
        self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
        self.gate_net = nn.Sequential(
            nn.Linear(embed_dim * 2, embed_dim),
            nn.Sigmoid()
        )
        self.hidden = nn.Sequential(
            nn.Linear(embed_dim * 3, 64),
            nn.LayerNorm(64),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.GELU()
        )
        self.head = nn.Linear(32, 4)

    def forward(self, cx, ix, ax):
        c_vec = self.client_tower(cx)
        i_vec = self.image_tower(ix)
        z = self.gate_net(torch.cat([c_vec, i_vec], dim=1))
        fused_vec = z * c_vec + (1 - z) * i_vec
        a_vec = self.algo_embed(ax)
        
        out = self.head(self.hidden(torch.cat([fused_vec, i_vec, a_vec], dim=1)))
        
        gamma = out[:, 0]
        v = F.softplus(out[:, 1]) + 0.1
        alpha = F.softplus(out[:, 2]) + 1.1
        beta = F.softplus(out[:, 3]) + 1e-6
        return torch.stack([gamma, v, alpha, beta], dim=1)

# ==============================================================================
# 4. æ•°æ®åŠ è½½
# ==============================================================================
class CTSDataset(Dataset):
    def __init__(self, cx, ix, ax, y):
        self.cx, self.ix, self.ax, self.y = torch.FloatTensor(cx), torch.FloatTensor(ix), torch.LongTensor(ax), torch.FloatTensor(y)
    def __len__(self): return len(self.y)
    def __getitem__(self, idx): return self.cx[idx], self.ix[idx], self.ax[idx], self.y[idx]

def load_data():
    print(f"ğŸ”„ è¯»å–æ•°æ®: {CONFIG['data_path']} ...")
    if not os.path.exists(CONFIG['data_path']):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {CONFIG['data_path']}")
        return None

    try:
        df_exp = pd.read_excel(CONFIG["data_path"])
        df_feat = pd.read_csv(CONFIG["feature_path"])
        
        rename_map = {"image": "image_name", "method": "algo_name", "network_bw": "bandwidth_mbps", "network_delay": "network_rtt", "mem_limit": "mem_limit_mb"}
        df_exp = df_exp.rename(columns=rename_map)
        if 'total_time' not in df_exp.columns: 
            cols = [c for c in df_exp.columns if 'total_tim' in c]
            if cols: df_exp = df_exp.rename(columns={cols[0]: 'total_time'})
            
        df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
        df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
        
        cols_c = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
        target_cols = ['total_size_mb', 'avg_layer_entropy', 'entropy_std', 'layer_count', 'size_std_mb', 'text_ratio', 'zero_ratio']
        cols_i = [c for c in target_cols if c in df.columns]
        
        Xc = StandardScaler().fit_transform(df[cols_c].values)
        Xi = StandardScaler().fit_transform(df[cols_i].values)
        enc = LabelEncoder()
        Xa = enc.fit_transform(df['algo_name'].values)
        y = np.log1p(df['total_time'].values)
        
        with open('preprocessing_objects.pkl', 'wb') as f:
            pickle.dump({'scaler_c': StandardScaler().fit(df[cols_c].values), 
                         'scaler_i': StandardScaler().fit(df[cols_i].values), 
                         'enc': enc}, f)
        
        return Xc, Xi, Xa, y, enc, len(cols_c), len(cols_i)
    
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å‡ºé”™: {e}")
        return None

# ==============================================================================
# 5. è®­ç»ƒä¸»å¾ªç¯
# ==============================================================================
if __name__ == "__main__":
    data = load_data()
    if data:
        Xc, Xi, Xa, y, enc_algo, c_dim, i_dim = data
        N = len(y)
        idx = np.random.permutation(N)
        n_tr, n_val = int(N * 0.7), int(N * 0.15)
        
        tr_d = CTSDataset(Xc[idx[:n_tr]], Xi[idx[:n_tr]], Xa[idx[:n_tr]], y[idx[:n_tr]])
        val_d = CTSDataset(Xc[idx[n_tr:n_tr+n_val]], Xi[idx[n_tr:n_tr+n_val]], Xa[idx[n_tr:n_tr+n_val]], y[idx[n_tr:n_tr+n_val]])
        
        tr_loader = DataLoader(tr_d, batch_size=CONFIG["batch_size"], shuffle=True)
        val_loader = DataLoader(val_d, batch_size=CONFIG["batch_size"])
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸš€ è®­ç»ƒå¼€å§‹ (ç­–ç•¥: Strong Symmetric EUB)")
        
        model = CTSDualTowerModel(c_dim, i_dim, len(enc_algo.classes_)).to(device)
        optimizer = optim.AdamW(model.parameters(), lr=CONFIG["lr"], weight_decay=CONFIG["weight_decay"])
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG["epochs"])
        
        best_corr = -1.0
        best_epoch = 0
        patience_counter = 0
        history = {'loss': [], 'corr': []}
        
        for epoch in range(CONFIG["epochs"]):
            model.train()
            t_loss = 0
            for cx, ix, ax, target in tr_loader:
                cx, ix, ax, target = cx.to(device), ix.to(device), ax.to(device), target.to(device)
                optimizer.zero_grad()
                loss, _, _ = evidential_loss(model(cx, ix, ax), target, epoch)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                t_loss += loss.item()
            
            scheduler.step()
            
            model.eval()
            uncs, errs = [], []
            with torch.no_grad():
                for cx, ix, ax, target in val_loader:
                    cx, ix, ax, target = cx.to(device), ix.to(device), ax.to(device), target.to(device)
                    preds = model(cx, ix, ax)
                    gamma, v, alpha, beta = preds[:,0], preds[:,1], preds[:,2], preds[:,3]
                    
                    unc = beta / (v * (alpha - 1))
                    err = torch.abs(torch.expm1(gamma) - torch.expm1(target))
                    uncs.extend(unc.cpu().numpy()); errs.extend(err.cpu().numpy())
            
            try: corr, _ = spearmanr(uncs, errs)
            except: corr = 0.0
            if np.isnan(corr): corr = 0.0
            
            history['loss'].append(t_loss/len(tr_loader))
            history['corr'].append(corr)
            
            print(f"Epoch {epoch+1:03d} | Loss: {history['loss'][-1]:.4f} | Val Corr: {corr:.4f}", end="")
            
            if corr > best_corr:
                best_corr = corr
                best_epoch = epoch
                patience_counter = 0
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'best_corr': best_corr,
                    'epoch': epoch,
                    'config': CONFIG
                }, CONFIG["model_save_path"])
                print(f" ğŸŒŸ New Best!")
            else:
                patience_counter += 1
                print(f" (Patience: {patience_counter}/{CONFIG['patience']})")
                
            if patience_counter >= CONFIG["patience"]:
                print(f"\nâ¹ï¸ è§¦å‘æ—©åœæœºåˆ¶ï¼")
                break
        
        print(f"\nâœ… è®­ç»ƒç»“æŸã€‚æœ€ä½³æ¨¡å‹: {CONFIG['model_save_path']} (Corr={best_corr:.4f})")
        
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(history['loss'], label='Strong EUB Loss')
        plt.title('è®­ç»ƒæŸå¤±')
        plt.legend()
        plt.subplot(1, 2, 2)
        plt.plot(history['corr'], color='#ff7f0e', label='Val Corr')
        plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Epoch {best_epoch+1}')
        plt.title('éªŒè¯é›†ç›¸å…³æ€§')
        plt.legend()
        plt.tight_layout()
        plt.savefig('training_result_strong.png')
# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import torch.optim as optim
# from torch.utils.data import Dataset, DataLoader
# import pandas as pd
# import numpy as np
# import os
# import matplotlib.pyplot as plt
# from sklearn.preprocessing import StandardScaler, LabelEncoder
# from scipy.stats import spearmanr
# import pickle
# import random
# import math

# # --- 1. å…¨å±€è®¾ç½® ---
# def set_seed(seed=42):
#     torch.manual_seed(seed)
#     torch.cuda.manual_seed_all(seed)
#     np.random.seed(seed)
#     random.seed(seed)
#     torch.backends.cudnn.deterministic = True

# set_seed(42)

# CONFIG = {
#     "kl_coeff": 1.0,           # KLæ•£åº¦æ­£åˆ™åŒ–ç³»æ•°ï¼Œé˜²æ­¢ä¸ç¡®å®šæ€§å‘æ•£
#     "annealing_epochs": 50,    # KLç³»æ•°é€€ç«å‘¨æœŸï¼Œå‰æœŸä¸“æ³¨äºå›å½’å‡†ç¡®åº¦
#     "lr": 0.0008,              # ç•¥å¾®é™ä½å­¦ä¹ ç‡ä»¥é…åˆGatedç»“æ„
#     "epochs": 200,             # è®­ç»ƒè½®æ¬¡
#     "data_path": "cts_data.xlsx",
#     "feature_path": "image_features_database.csv",
#     "batch_size": 128,         # æ˜¾å­˜å…è®¸çš„è¯ï¼Œå¤§Batchæœ‰åŠ©äºEDLæ”¶æ•›
#     "embed_dim": 32,           # Embeddingç»´åº¦
#     "model_save_path": "cts_best_model_gated.pth",
#     "weight_decay": 1e-4,      # L2æ­£åˆ™åŒ–
# }

# # --- 2. è¯æ®æ·±åº¦å­¦ä¹  (EDL) æ ¸å¿ƒæŸå¤±å‡½æ•° ---
# def nig_nll_loss(y, gamma, v, alpha, beta):
#     # è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤± (NLL) - æ‹Ÿåˆè§‚æµ‹æ•°æ®
#     two_blambda = 2 * beta * (1 + v)
#     nll = 0.5 * torch.log(np.pi / v) \
#         - alpha * torch.log(two_blambda) \
#         + (alpha + 0.5) * torch.log(v * (y - gamma)**2 + two_blambda) \
#         + torch.lgamma(alpha) - torch.lgamma(alpha + 0.5)
#     return nll.mean()

# def nig_reg_loss(y, gamma, v, alpha, beta):
#     # æ­£åˆ™åŒ–æŸå¤± - æƒ©ç½šé”™è¯¯çš„è‡ªä¿¡
#     error = torch.abs(y - gamma)
#     evidence = 2 * v + alpha
#     return (error * evidence).mean()

# def evidential_loss(pred, target, epoch):
#     gamma, v, alpha, beta = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]
#     target = target.view(-1)
    
#     loss_nll = nig_nll_loss(target, gamma, v, alpha, beta)
#     loss_reg = nig_reg_loss(target, gamma, v, alpha, beta)
    
#     # KLé€€ç«ç­–ç•¥ï¼šè®©æ¨¡å‹å…ˆå­¦å‡†(å›å½’)ï¼Œå†å­¦ç¨³(ä¸ç¡®å®šæ€§)
#     annealing_coef = min(1.0, epoch / CONFIG["annealing_epochs"])
    
#     total_loss = loss_nll + CONFIG["kl_coeff"] * annealing_coef * loss_reg
#     return total_loss, loss_nll.item(), loss_reg.item()

# # --- 3. æ¨¡å‹å®šä¹‰ (Gated Fusion Version) ---
# class FeatureTokenizer(nn.Module):
#     def __init__(self, num_features, embed_dim):
#         super().__init__()
#         self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
#         self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
#         # ä¼˜åŒ–ç‚¹1ï¼šåŠ å…¥LayerNormï¼Œç¨³å®šè¾“å…¥åˆ†å¸ƒ
#         self.norm = nn.LayerNorm(embed_dim)
#         nn.init.xavier_uniform_(self.weights)
#         nn.init.zeros_(self.biases)

#     def forward(self, x):
#         # ç±»ä¼¼FTTransformerçš„ç‰¹å¾TokenåŒ–
#         tokens = x.unsqueeze(-1) * self.weights + self.biases
#         return self.norm(tokens)

# class TransformerTower(nn.Module):
#     def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
#         super().__init__()
#         self.tokenizer = FeatureTokenizer(num_features, embed_dim)
#         self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
#         # ä¼˜åŒ–ç‚¹2ï¼šæ ‡å‡†çš„Transformer Encoder
#         encoder_layer = nn.TransformerEncoderLayer(
#             d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
#             batch_first=True, dropout=0.1, activation="gelu" # ä½¿ç”¨GELU
#         )
#         self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

#     def forward(self, x):
#         tokens = self.tokenizer(x)
#         cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)
#         tokens = torch.cat((cls_tokens, tokens), dim=1)
#         out = self.transformer(tokens)
#         return out[:, 0, :] # åªå– CLS Token ä½œä¸ºå¡”çš„è¾“å‡º

# class CTSDualTowerModel(nn.Module):
#     def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
#         super().__init__()
#         self.client_tower = TransformerTower(client_feats, embed_dim)
#         self.image_tower = TransformerTower(image_feats, embed_dim)
#         self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
#         # ä¼˜åŒ–ç‚¹3ï¼šé—¨æ§èåˆæœºåˆ¶ (Gated Fusion)
#         # å­¦ä¹ ä¸€ä¸ªæƒé‡ zï¼ŒåŠ¨æ€å†³å®šæ›´ä¿¡ä»» Client è¿˜æ˜¯ Image
#         self.gate_net = nn.Sequential(
#             nn.Linear(embed_dim * 2, embed_dim),
#             nn.Sigmoid()
#         )
        
#         # ä¼˜åŒ–ç‚¹4ï¼šå¢å¼ºçš„å›å½’å¤´ (GELU + Dropout)
#         self.hidden = nn.Sequential(
#             nn.Linear(embed_dim * 3, 64),
#             nn.LayerNorm(64),
#             nn.GELU(),
#             nn.Dropout(0.2),
#             nn.Linear(64, 32),
#             nn.GELU()
#         )
#         self.head = nn.Linear(32, 4) # è¾“å‡º4ä¸ªEDLå‚æ•°

#     def forward(self, cx, ix, ax):
#         c_vec = self.client_tower(cx) # Client ç‰¹å¾
#         i_vec = self.image_tower(ix)  # Image ç‰¹å¾
        
#         # --- é—¨æ§èåˆæ ¸å¿ƒé€»è¾‘ ---
#         # z æ˜¯ä¸€ä¸ª (Batch, Dim) çš„æƒé‡å‘é‡ï¼Œ0~1ä¹‹é—´
#         # å¦‚æœ z æ¥è¿‘ 1ï¼Œè¯´æ˜å½“å‰æ›´åŠ å…³æ³¨ç½‘ç»œç¯å¢ƒï¼›åä¹‹å…³æ³¨é•œåƒæœ¬èº«
#         z = self.gate_net(torch.cat([c_vec, i_vec], dim=1))
#         fused_vec = z * c_vec + (1 - z) * i_vec
        
#         a_vec = self.algo_embed(ax)
#         # å°†èåˆç‰¹å¾ã€åŸå§‹é•œåƒç‰¹å¾ã€ç®—æ³•ç‰¹å¾æ‹¼æ¥
#         combined = torch.cat([fused_vec, i_vec, a_vec], dim=1)
        
#         hidden = self.hidden(combined)
#         out = self.head(hidden)
        
#         # æ¿€æ´»å‡½æ•°ç¡®ä¿å‚æ•°æ»¡è¶³åˆ†å¸ƒè¦æ±‚
#         gamma = out[:, 0]
#         v = F.softplus(out[:, 1]) + 0.1
#         alpha = F.softplus(out[:, 2]) + 1.1 # ä¿è¯ alpha > 1
#         beta = F.softplus(out[:, 3]) + 1e-6
        
#         return torch.stack([gamma, v, alpha, beta], dim=1)

# # --- 4. æ•°æ®å¤„ç† (ä¿æŒä¸å˜) ---
# class CTSDataset(Dataset):
#     def __init__(self, client_x, image_x, algo_x, y):
#         self.cx = torch.FloatTensor(client_x)
#         self.ix = torch.FloatTensor(image_x)
#         self.ax = torch.LongTensor(algo_x)
#         self.y = torch.FloatTensor(y)
#     def __len__(self): return len(self.y)
#     def __getitem__(self, idx): return self.cx[idx], self.ix[idx], self.ax[idx], self.y[idx]

# def load_and_process_data():
#     print(f"ğŸ”„ è¯»å–æ•°æ®...")
#     # æ¨¡æ‹Ÿè¯»å–é€»è¾‘ï¼Œè¯·ç¡®ä¿è·¯å¾„æ­£ç¡®
#     try:
#         df_exp = pd.read_excel(CONFIG["data_path"])
#         df_feat = pd.read_csv(CONFIG["feature_path"])
#     except:
#         print("âŒ æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ CONFIG ä¸­çš„è·¯å¾„")
#         return None, None, None, None, None

#     # åˆ—åæ˜ å°„ (æ ¹æ®ä½ æä¾›çš„æˆªå›¾è°ƒæ•´)
#     rename_map = {
#         "image": "image_name", "method": "algo_name",
#         "network_bw": "bandwidth_mbps", "network_delay": "network_rtt",
#         "mem_limit": "mem_limit_mb"
#     }
#     df_exp = df_exp.rename(columns=rename_map)
#     if 'total_time' not in df_exp.columns:
#         possible = [c for c in df_exp.columns if 'total_tim' in c]
#         if possible: df_exp = df_exp.rename(columns={possible[0]: 'total_time'})
    
#     # è¿‡æ»¤æ— æ•ˆæ•°æ®
#     df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
#     df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
    
#     col_client = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
#     col_image = ['total_size_mb', 'avg_layer_entropy', 'text_ratio', 'layer_count', 'zero_ratio']
    
#     # é¢„å¤„ç†
#     scaler_c = StandardScaler(); X_client = scaler_c.fit_transform(df[col_client].values)
#     scaler_i = StandardScaler(); X_image = scaler_i.fit_transform(df[col_image].values)
#     enc_algo = LabelEncoder(); X_algo = enc_algo.fit_transform(df['algo_name'].values)
#     y_target = np.log1p(df['total_time'].values) # Logå˜æ¢å¹³æ»‘é•¿å°¾åˆ†å¸ƒ
    
#     return X_client, X_image, X_algo, y_target, enc_algo

# # --- 5. è®­ç»ƒä¸»å¾ªç¯ ---
# if __name__ == "__main__":
#     Xc, Xi, Xa, y, enc_algo = load_and_process_data()
    
#     if Xc is not None:
#         # åˆ’åˆ†æ•°æ®é›†
#         N = len(y)
#         indices = np.random.permutation(N)
#         n_train, n_val = int(N * 0.7), int(N * 0.15)
#         train_idx, val_idx, test_idx = indices[:n_train], indices[n_train:n_train+n_val], indices[n_train+n_val:]
        
#         train_loader = DataLoader(CTSDataset(Xc[train_idx], Xi[train_idx], Xa[train_idx], y[train_idx]), 
#                                   batch_size=CONFIG["batch_size"], shuffle=True)
#         val_loader = DataLoader(CTSDataset(Xc[val_idx], Xi[val_idx], Xa[val_idx], y[val_idx]), 
#                                 batch_size=CONFIG["batch_size"])
        
#         device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#         print(f"ğŸš€ è®¾å¤‡: {device} | è®­ç»ƒé›†: {len(train_idx)} | éªŒè¯é›†: {len(val_idx)}")
        
#         model = CTSDualTowerModel(
#             client_feats=Xc.shape[1], 
#             image_feats=Xi.shape[1], 
#             num_algos=len(enc_algo.classes_)
#         ).to(device)
        
#         # ä¼˜åŒ–ç‚¹5ï¼šä½¿ç”¨ CosineAnnealing å­¦ä¹ ç‡è°ƒåº¦
#         optimizer = optim.AdamW(model.parameters(), lr=CONFIG["lr"], weight_decay=CONFIG["weight_decay"])
#         scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG["epochs"], eta_min=1e-5)
        
#         best_corr = -1.0
#         history = {'epoch': [], 'loss': [], 'val_corr': []}
        
#         for epoch in range(CONFIG["epochs"]):
#             model.train()
#             train_loss = 0
#             for cx, ix, ax, target in train_loader:
#                 cx, ix, ax, target = cx.to(device), ix.to(device), ax.to(device), target.to(device)
#                 optimizer.zero_grad()
#                 preds = model(cx, ix, ax)
#                 loss, _, _ = evidential_loss(preds, target, epoch)
#                 loss.backward()
#                 torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # æ¢¯åº¦è£å‰ªé˜²æ­¢çˆ†ç‚¸
#                 optimizer.step()
#                 train_loss += loss.item()
            
#             scheduler.step()
            
#             # éªŒè¯ï¼šè®¡ç®— Spearman Correlation (ä¸ç¡®å®šæ€§ vs è¯¯å·®)
#             model.eval()
#             all_unc, all_err = [], []
#             with torch.no_grad():
#                 for cx, ix, ax, target in val_loader:
#                     cx, ix, ax, target = cx.to(device), ix.to(device), ax.to(device), target.to(device)
#                     preds = model(cx, ix, ax)
                    
#                     gamma, v, alpha, beta = preds[:, 0], preds[:, 1], preds[:, 2], preds[:, 3]
#                     pred_time = torch.expm1(gamma) # è¿˜åŸ Log
#                     true_time = torch.expm1(target)
                    
#                     # æ ¸å¿ƒå…¬å¼ï¼šä¸ç¡®å®šæ€§ = beta / (v * (alpha - 1))
#                     uncertainty = beta / (v * (alpha - 1))
#                     error = torch.abs(pred_time - true_time)
                    
#                     all_unc.extend(uncertainty.cpu().numpy())
#                     all_err.extend(error.cpu().numpy())
            
#             # åªæœ‰å½“æ•°æ®é‡è¶³å¤Ÿä¸”æ— NaNæ—¶è®¡ç®—Corr
#             try:
#                 corr, _ = spearmanr(all_unc, all_err)
#             except:
#                 corr = 0.0
                
#             history['epoch'].append(epoch)
#             history['loss'].append(train_loss / len(train_loader))
#             history['val_corr'].append(corr)
            
#             # ä¿å­˜æœ€ä½³æ¨¡å‹ (ä»¥ Correlation ä¸ºå‡†)
#             if corr > best_corr and epoch > 10:
#                 best_corr = corr
#                 torch.save(model.state_dict(), CONFIG["model_save_path"])
#                 print(f"Epoch {epoch+1:03d} | Loss: {train_loss/len(train_loader):.4f} | Val Corr: {corr:.4f} (New Best!)")
#             elif (epoch+1) % 10 == 0:
#                 print(f"Epoch {epoch+1:03d} | Loss: {train_loss/len(train_loader):.4f} | Val Corr: {corr:.4f}")
        
#         print(f"\nâœ… è®­ç»ƒå®Œæˆã€‚æœ€ä½³ä¸ç¡®å®šæ€§ç›¸å…³ç³»æ•°: {best_corr:.4f}")
        
#         # ç»˜åˆ¶ç®€å•çš„è®­ç»ƒæ›²çº¿
#         plt.figure(figsize=(10, 4))
#         plt.subplot(1, 2, 1)
#         plt.plot(history['epoch'], history['loss'], label='Train Loss')
#         plt.title('Loss Curve')
#         plt.subplot(1, 2, 2)
#         plt.plot(history['epoch'], history['val_corr'], color='orange', label='Val Correlation')
#         plt.title('Uncertainty-Error Correlation')
#         plt.savefig('training_result.png')
#         print("ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜ä¸º training_result.png")







# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import torch.optim as optim
# from torch.utils.data import Dataset, DataLoader
# import pandas as pd
# import numpy as np
# import os
# import matplotlib.pyplot as plt
# from sklearn.preprocessing import StandardScaler, LabelEncoder
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import r2_score, mean_squared_error
# from scipy.stats import spearmanr  # [ä¿®æ”¹] ç”¨Spearmanæ›´ç¨³å¥


# # [æ–°å¢] å›ºå®šéšæœºç§å­
# def set_seed(seed=42):
#     torch.manual_seed(seed)
#     torch.cuda.manual_seed_all(seed)
#     np.random.seed(seed)
#     import random
#     random.seed(seed)
#     torch.backends.cudnn.deterministic = True


# set_seed(42)


# CONFIG = {
#     "kl_coeff": 1.5,
#     "annealing_epochs": 150,
#     "lr": 0.001,
#     "epochs": 300,
#     "data_path": "cts_data.xlsx",         
#     "feature_path": "image_features_database.csv",
#     "batch_size": 64,
#     "embed_dim": 32,
#     "model_save_path": "cts_best_model_fixed_v3.pth",
#     "weight_decay": 1e-4,  # [æ–°å¢] AdamWçš„weight decay
# }


# # è·¯å¾„æ£€æŸ¥
# if not os.path.exists(CONFIG["data_path"]):
#     if os.path.exists(f"../{CONFIG['data_path']}"):
#         CONFIG["data_path"] = f"../{CONFIG['data_path']}"
#         CONFIG["feature_path"] = f"../{CONFIG['feature_path']}"
#         print(f"ğŸ“‚ è‡ªåŠ¨åˆ‡æ¢æ•°æ®è·¯å¾„åˆ°ä¸Šä¸€çº§: {CONFIG['data_path']}")

# # ==============================================================================
# # ğŸŒŸ ä¿®å¤åçš„è¯æ®æ·±åº¦å­¦ä¹ æŸå¤±å‡½æ•°
# # ==============================================================================

# def nig_nll_loss(y, gamma, v, alpha, beta):
#     """è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±"""
#     two_blambda = 2 * beta * (1 + v)
#     nll = 0.5 * torch.log(np.pi / v) \
#         - alpha * torch.log(two_blambda) \
#         + (alpha + 0.5) * torch.log(v * (y - gamma)**2 + two_blambda) \
#         + torch.lgamma(alpha) - torch.lgamma(alpha + 0.5)
#     return nll.mean()

# def nig_reg_loss(y, gamma, v, alpha, beta):
#     """æ­£åˆ™åŒ–æŸå¤±ï¼šæƒ©ç½šé”™è¯¯ä¸”è‡ªä¿¡"""
#     error = torch.abs(y - gamma)
#     evidence = 2 * v + alpha
#     return (error * evidence).mean()

# def evidential_loss(pred, target, epoch, lambda_coef=CONFIG["kl_coeff"]):
#     """æ€»æŸå¤± = NLL + æ­£åˆ™åŒ–"""
#     gamma, v, alpha, beta = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]
#     target = target.view(-1)
    
#     loss_nll = nig_nll_loss(target, gamma, v, alpha, beta)
#     loss_reg = nig_reg_loss(target, gamma, v, alpha, beta)
    
#     # [ä¿®å¤] å¹³æ–¹é€€ç«
#     if epoch < CONFIG["annealing_epochs"]:
#         annealing_coef = (epoch / CONFIG["annealing_epochs"]) ** 2
#     else:
#         annealing_coef = 1.0
    
#     total_loss = loss_nll + lambda_coef * annealing_coef * loss_reg
    
#     return total_loss, loss_nll.item(), loss_reg.item(), annealing_coef

# # ==============================================================================
# # 2. æ¨¡å‹å®šä¹‰ ([å…³é”®ä¿®å¤] æ•°å€¼çº¦æŸ)
# # ==============================================================================

# class FeatureTokenizer(nn.Module):
#     def __init__(self, num_features, embed_dim):
#         super().__init__()
#         self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
#         self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
#         nn.init.xavier_uniform_(self.weights)
#         nn.init.zeros_(self.biases)

#     def forward(self, x):
#         return x.unsqueeze(-1) * self.weights + self.biases

# class TransformerTower(nn.Module):
#     def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
#         super().__init__()
#         self.tokenizer = FeatureTokenizer(num_features, embed_dim)
#         self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
#         encoder_layer = nn.TransformerEncoderLayer(
#             d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
#             batch_first=True, dropout=0.1
#         )
#         self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

#     def forward(self, x):
#         tokens = self.tokenizer(x)
#         batch_size = x.shape[0]
#         cls_tokens = self.cls_token.expand(batch_size, -1, -1)
#         tokens = torch.cat((cls_tokens, tokens), dim=1)
#         out = self.transformer(tokens)
#         return out[:, 0, :]

# class CTSDualTowerModel(nn.Module):
#     def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
#         super().__init__()
#         self.client_tower = TransformerTower(client_feats, embed_dim)
#         self.image_tower = TransformerTower(image_feats, embed_dim)
#         self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
#         fusion_input_dim = embed_dim * 3 
#         self.hidden = nn.Sequential(
#             nn.Linear(fusion_input_dim, 64),
#             nn.LayerNorm(64),
#             nn.ReLU(),
#             nn.Dropout(0.2)
#         )
#         self.head = nn.Linear(64, 4) 

#     def forward(self, cx, ix, ax):
#         c_vec = self.client_tower(cx)
#         i_vec = self.image_tower(ix)
#         a_vec = self.algo_embed(ax)
#         combined = torch.cat([c_vec, i_vec, a_vec], dim=1)
#         hidden = self.hidden(combined)
#         out = self.head(hidden)
        
#         # [å…³é”®ä¿®å¤] æ›´å¼ºçš„æ•°å€¼çº¦æŸ
#         gamma = out[:, 0]
#         v = F.softplus(out[:, 1]) + 0.1        # [ä¿®å¤] æœ€å°0.1
#         alpha = F.softplus(out[:, 2]) + 1.1    # [ä¿®å¤] æœ€å°1.1ï¼Œ(alpha-1)>=0.1
#         beta = F.softplus(out[:, 3]) + 1e-6
        
#         return torch.stack([gamma, v, alpha, beta], dim=1)

# # ==============================================================================
# # 3. æ•°æ®åŠ è½½
# # ==============================================================================

# def load_data():
#     print(f"ğŸ”„ 1. æ­£åœ¨è¯»å–æ•°æ®: {CONFIG['data_path']} ...")
#     try:
#         df_exp = pd.read_excel(CONFIG["data_path"])
#     except ImportError:
#         print("âŒ è¯»å–å¤±è´¥ï¼è¯·è¿è¡Œ 'pip install openpyxl'")
#         exit(1)

#     rename_map = {
#         "image": "image_name", "method": "algo_name",
#         "network_bw": "bandwidth_mbps", "network_delay": "network_rtt",
#         "mem_limit": "mem_limit_mb"
#     }
#     df_exp = df_exp.rename(columns=rename_map)
    
#     if 'total_time' not in df_exp.columns:
#         possible_cols = [c for c in df_exp.columns if 'total_tim' in c]
#         if possible_cols: df_exp = df_exp.rename(columns={possible_cols[0]: 'total_time'})

#     df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
    
#     if 'mem_limit_mb' not in df_exp.columns: 
#         df_exp['mem_limit_mb'] = 1024.0
    
#     print(f"ğŸ”„ 2. è¯»å–é•œåƒç‰¹å¾: {CONFIG['feature_path']} ...")
#     df_feat = pd.read_csv(CONFIG["feature_path"])
    
#     df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
#     print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œæ ·æœ¬æ•°: {len(df)}")
#     return df

# class CTSDataset(Dataset):
#     def __init__(self, client_x, image_x, algo_x, y):
#         self.cx = torch.FloatTensor(client_x)
#         self.ix = torch.FloatTensor(image_x)
#         self.ax = torch.LongTensor(algo_x)
#         self.y = torch.FloatTensor(y)
#     def __len__(self): return len(self.y)
#     def __getitem__(self, idx): return self.cx[idx], self.ix[idx], self.ax[idx], self.y[idx]

# # ==============================================================================
# # 4. ä¸»è®­ç»ƒæµç¨‹ ([å…³é”®ä¿®å¤] ä¸‰åˆ†æ•°æ®é›† + åŸå§‹ç©ºé—´ç›¸å…³æ€§)
# # ==============================================================================

# if __name__ == "__main__":
#     # --- Step 1: å‡†å¤‡æ•°æ® ---
#     df = load_data()
    
#     col_client = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
#     col_image = ['total_size_mb', 'avg_layer_entropy', 'text_ratio', 'layer_count', 'zero_ratio']
    
#     scaler_c = StandardScaler()
#     X_client = scaler_c.fit_transform(df[col_client].values)
    
#     scaler_i = StandardScaler()
#     X_image = scaler_i.fit_transform(df[col_image].values)
    
#     enc_algo = LabelEncoder()
#     X_algo = enc_algo.fit_transform(df['algo_name'].values)
    
#     y_target = np.log1p(df['total_time'].values)

#     # [å…³é”®ä¿®å¤] ä¸‰åˆ†æ•°æ®é›†ï¼š70% train / 15% val / 15% test
#     Xc_temp, Xc_test, Xi_temp, Xi_test, Xa_temp, Xa_test, y_temp, y_test = train_test_split(
#         X_client, X_image, X_algo, y_target, test_size=0.3, random_state=42
#     )
#     Xc_train, Xc_val, Xi_train, Xi_val, Xa_train, Xa_val, y_train, y_val = train_test_split(
#         Xc_temp, Xi_temp, Xa_temp, y_temp, test_size=0.5, random_state=42  # 0.5 * 0.3 = 0.15
#     )
    
#     print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
#     print(f"   è®­ç»ƒé›†: {len(y_train)} æ ·æœ¬ (70%)")
#     print(f"   éªŒè¯é›†: {len(y_val)} æ ·æœ¬ (15%)")
#     print(f"   æµ‹è¯•é›†: {len(y_test)} æ ·æœ¬ (15%)")
    
#     train_loader = DataLoader(CTSDataset(Xc_train, Xi_train, Xa_train, y_train), 
#                               batch_size=CONFIG["batch_size"], shuffle=True)
#     val_loader = DataLoader(CTSDataset(Xc_val, Xi_val, Xa_val, y_val), 
#                             batch_size=CONFIG["batch_size"])
#     test_loader = DataLoader(CTSDataset(Xc_test, Xi_test, Xa_test, y_test), 
#                              batch_size=CONFIG["batch_size"])
    
#     # --- Step 2: æ¨¡å‹åˆå§‹åŒ– ---
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     print(f"\nğŸ–¥ï¸ è®­ç»ƒè®¾å¤‡: {device}")
    
#     model = CTSDualTowerModel(
#         client_feats=len(col_client),
#         image_feats=len(col_image),
#         num_algos=len(enc_algo.classes_)
#     ).to(device)
    
#     # [ä¿®æ”¹] AdamW + weight decay
#     optimizer = optim.AdamW(model.parameters(), lr=CONFIG["lr"], weight_decay=CONFIG["weight_decay"])
    
#     # --- Step 3: è®­ç»ƒ ---
#     print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
#     print(f"é…ç½®: epochs={CONFIG['epochs']}, kl_coeff={CONFIG['kl_coeff']}")
    
#     best_val_loss = float('inf')
#     best_epoch = 0
#     patience = 30  # [æ–°å¢] æ—©åœè€å¿ƒ
#     patience_counter = 0
    
#     history = {'epoch': [], 'train_total': [], 'train_nll': [], 'train_reg': [], 
#                'val_nll': [], 'val_corr': []}  # [ä¿®æ”¹] val_corr
    
#     for epoch in range(CONFIG["epochs"]):
#         model.train()
#         train_total = train_nll = train_reg = 0
        
#         for cx, ix, ax, y in train_loader:
#             cx, ix, ax, y = cx.to(device), ix.to(device), ax.to(device), y.to(device)
#             optimizer.zero_grad()
            
#             preds = model(cx, ix, ax)
#             loss, nll, reg, anneal = evidential_loss(preds, y, epoch)
            
#             loss.backward()
#             optimizer.step()
            
#             train_total += loss.item()
#             train_nll += nll
#             train_reg += reg
        
#         # [å…³é”®ä¿®å¤] åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ï¼ˆä¸æ˜¯æµ‹è¯•é›†ï¼‰
#         model.eval()
#         val_nll = 0
#         all_uncertainties = []
#         all_errors = []  # [ä¿®æ”¹] åŸå§‹ç©ºé—´è¯¯å·®
        
#         with torch.no_grad():
#             for cx, ix, ax, y in val_loader:
#                 cx, ix, ax, y = cx.to(device), ix.to(device), ax.to(device), y.to(device)
#                 preds = model(cx, ix, ax)
#                 gamma, v, alpha, beta = preds[:, 0], preds[:, 1], preds[:, 2], preds[:, 3]
                
#                 val_nll += nig_nll_loss(y, gamma, v, alpha, beta).item()
                
#                 # [å…³é”®ä¿®å¤] åœ¨åŸå§‹æ—¶é—´ç©ºé—´è®¡ç®—è¯¯å·®
#                 pred_time = np.expm1(gamma.cpu().numpy())  # ç§’
#                 true_time = np.expm1(y.cpu().numpy())      # ç§’
#                 error = np.abs(pred_time - true_time)      # ç§’
                
#                 uncertainty = (beta / (v * (alpha - 1))).cpu().numpy()
#                 all_uncertainties.extend(uncertainty)
#                 all_errors.extend(error)
        
#         # [ä¿®æ”¹] Spearmanç›¸å…³æ€§
#         try:
#             corr, _ = spearmanr(all_uncertainties, all_errors)
#         except:
#             corr = 0
        
#         avg_train_total = train_total / len(train_loader)
#         avg_train_nll = train_nll / len(train_loader)
#         avg_train_reg = train_reg / len(train_loader)
#         avg_val_nll = val_nll / len(val_loader)
        
#         history['epoch'].append(epoch)
#         history['train_total'].append(avg_train_total)
#         history['train_nll'].append(avg_train_nll)
#         history['train_reg'].append(avg_train_reg)
#         history['val_nll'].append(avg_val_nll)
#         history['val_corr'].append(corr)
        
#         if (epoch + 1) % 20 == 0:
#             print(f"Epoch {epoch+1:03d} | "
#                   f"Train: {avg_train_total:.3f} | "
#                   f"Val NLL: {avg_val_nll:.3f} | "
#                   f"Val Corr: {corr:+.3f}")
        
#         # [æ–°å¢] æ—©åœï¼šç”¨éªŒè¯é›†é€‰æ‹©æœ€ä½³æ¨¡å‹
#         if avg_val_nll < best_val_loss:
#             best_val_loss = avg_val_nll
#             best_epoch = epoch
#             patience_counter = 0
#             torch.save({
#                 'epoch': epoch,
#                 'model_state_dict': model.state_dict(),
#                 'optimizer_state_dict': optimizer.state_dict(),
#                 'best_val_loss': best_val_loss,
#                 'config': CONFIG,
#                 'scaler_c': scaler_c,
#                 'scaler_i': scaler_i,
#                 'enc_algo': enc_algo,
#                 'col_client': col_client,
#                 'col_image': col_image,
#             }, CONFIG["model_save_path"])
#         else:
#             patience_counter += 1
#             if patience_counter >= patience:
#                 print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼è¿ç»­{patience}è½®æ— æ”¹å–„")
#                 break

#     print(f"\nğŸ’¾ è®­ç»ƒç»“æŸï¼æœ€ä½³Val NLL: {best_val_loss:.4f} (Epoch {best_epoch})")
    
#     # --- Step 4: æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°ï¼ˆåªè·‘ä¸€æ¬¡ï¼‰---
#     print("\nğŸ”® æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°:")
#     checkpoint = torch.load(CONFIG["model_save_path"], weights_only=False)
#     model.load_state_dict(checkpoint['model_state_dict'])
#     model.eval()
    
#     test_nll = 0
#     all_test_unc = []
#     all_test_err = []
#     all_preds = []
#     all_targets = []
    
#     with torch.no_grad():
#         for cx, ix, ax, y in test_loader:
#             cx, ix, ax, y = cx.to(device), ix.to(device), ax.to(device), y.to(device)
#             preds = model(cx, ix, ax)
#             gamma, v, alpha, beta = preds[:, 0], preds[:, 1], preds[:, 2], preds[:, 3]
            
#             test_nll += nig_nll_loss(y, gamma, v, alpha, beta).item()
            
#             # åŸå§‹ç©ºé—´
#             pred_time = np.expm1(gamma.cpu().numpy())
#             true_time = np.expm1(y.cpu().numpy())
#             error = np.abs(pred_time - true_time)
            
#             uncertainty = (beta / (v * (alpha - 1))).cpu().numpy()
#             all_test_unc.extend(uncertainty)
#             all_test_err.extend(error)
#             all_preds.extend(pred_time)
#             all_targets.extend(true_time)
    
#     # æµ‹è¯•é›†æŒ‡æ ‡
#     final_corr, _ = spearmanr(all_test_unc, all_test_err)
#     rmse = np.sqrt(np.mean((np.array(all_targets) - np.array(all_preds))**2))
    
#     print(f"\n{'='*60}")
#     print(f"ğŸ“Š æµ‹è¯•é›†æœ€ç»ˆæŒ‡æ ‡:")
#     print(f"   Test NLL: {test_nll/len(test_loader):.4f}")
#     print(f"   RMSE: {rmse:.4f} (ç§’)")
#     print(f"   Uncertainty-Error Corr: {final_corr:+.3f}")
#     print(f"   ä¸ç¡®å®šæ€§èŒƒå›´: [{np.min(all_test_unc):.3f}, {np.max(all_test_unc):.3f}]")
#     print(f"{'='*60}")
    
#     # --- Step 5: ä¿å­˜scalerå’Œç‰¹å¾ä¿¡æ¯ï¼ˆç”¨äºåç»­ç”»å›¾ï¼‰---
#     print(f"\nğŸ“¦ ä¿å­˜é¢„å¤„ç†ä¿¡æ¯...")
#     import pickle
#     with open('preprocessing_info.pkl', 'wb') as f:
#         pickle.dump({
#             'scaler_c': scaler_c,
#             'scaler_i': scaler_i,
#             'enc_algo': enc_algo,
#             'col_client': col_client,
#             'col_image': col_image,
#         }, f)
    
#     # --- Step 6: ç»˜å›¾ ---
#     fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
#     axes[0,0].plot(history['epoch'], history['train_total'], label='Train')
#     axes[0,0].plot(history['epoch'], history['val_nll'], label='Val NLL')
#     axes[0,0].set_title('Loss Curves')
#     axes[0,0].legend()
#     axes[0,0].grid(True, alpha=0.3)
    
#     axes[0,1].plot(history['epoch'], history['train_nll'], label='NLL')
#     axes[0,1].plot(history['epoch'], history['train_reg'], label='Reg')
#     axes[0,1].set_title('NLL vs Regularization')
#     axes[0,1].legend()
#     axes[0,1].grid(True, alpha=0.3)
    
#     axes[1,0].plot(history['epoch'], history['val_corr'], 'g-', linewidth=2)
#     axes[1,0].axhline(y=0, color='r', linestyle='--')
#     axes[1,0].set_title('Validation: Uncertainty-Error Correlation')
#     axes[1,0].set_ylabel('Spearman Correlation')
#     axes[1,0].grid(True, alpha=0.3)
    
#     axes[1,1].scatter(all_test_unc, all_test_err, alpha=0.5, s=10)
#     axes[1,1].set_xlabel('Uncertainty')
#     axes[1,1].set_ylabel('Absolute Error (seconds)')
#     axes[1,1].set_title(f'Test: Uncertainty vs Error (Corr={final_corr:.3f})')
#     axes[1,1].grid(True, alpha=0.3)
    
#     plt.tight_layout()
#     plt.savefig('training_diagnostics_v3.png', dpi=150)
#     print("\nğŸ“Š è®­ç»ƒè¯Šæ–­å›¾å·²ä¿å­˜")



# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# import torch.optim as optim
# from torch.utils.data import Dataset, DataLoader
# import pandas as pd
# import numpy as np
# import os
# import matplotlib.pyplot as plt
# from sklearn.preprocessing import StandardScaler, LabelEncoder
# from scipy.stats import spearmanr
# import pickle


# # å›ºå®šéšæœºç§å­
# def set_seed(seed=42):
#     torch.manual_seed(seed)
#     torch.cuda.manual_seed_all(seed)
#     np.random.seed(seed)
#     import random
#     random.seed(seed)
#     torch.backends.cudnn.deterministic = True


# set_seed(42)


# CONFIG = {
#     "kl_coeff": 1.5,
#     "annealing_epochs": 150,
#     "lr": 0.001,
#     "epochs": 300,
#     "data_path": "cts_data.xlsx",
#     "feature_path": "image_features_database.csv",
#     "batch_size": 64,
#     "embed_dim": 32,
#     "model_save_path": "cts_best_model_final.pth",
#     "weight_decay": 1e-4,
# }


# # è·¯å¾„æ£€æŸ¥
# if not os.path.exists(CONFIG["data_path"]):
#     if os.path.exists(f"../{CONFIG['data_path']}"):
#         CONFIG["data_path"] = f"../{CONFIG['data_path']}"
#         CONFIG["feature_path"] = f"../{CONFIG['feature_path']}"

# # ==============================================================================
# # æŸå¤±å‡½æ•°
# # ==============================================================================

# def nig_nll_loss(y, gamma, v, alpha, beta):
#     two_blambda = 2 * beta * (1 + v)
#     nll = 0.5 * torch.log(np.pi / v) \
#         - alpha * torch.log(two_blambda) \
#         + (alpha + 0.5) * torch.log(v * (y - gamma)**2 + two_blambda) \
#         + torch.lgamma(alpha) - torch.lgamma(alpha + 0.5)
#     return nll.mean()


# def nig_reg_loss(y, gamma, v, alpha, beta):
#     error = torch.abs(y - gamma)
#     evidence = 2 * v + alpha
#     return (error * evidence).mean()


# def evidential_loss(pred, target, epoch, lambda_coef=CONFIG["kl_coeff"]):
#     gamma, v, alpha, beta = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]
#     target = target.view(-1)
    
#     loss_nll = nig_nll_loss(target, gamma, v, alpha, beta)
#     loss_reg = nig_reg_loss(target, gamma, v, alpha, beta)
    
#     if epoch < CONFIG["annealing_epochs"]:
#         annealing_coef = (epoch / CONFIG["annealing_epochs"]) ** 2
#     else:
#         annealing_coef = 1.0
    
#     total_loss = loss_nll + lambda_coef * annealing_coef * loss_reg
#     return total_loss, loss_nll.item(), loss_reg.item(), annealing_coef

# # ==============================================================================
# # æ¨¡å‹å®šä¹‰ï¼ˆæ•°å€¼çº¦æŸä¿®å¤ï¼‰
# # ==============================================================================

# class FeatureTokenizer(nn.Module):
#     def __init__(self, num_features, embed_dim):
#         super().__init__()
#         self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
#         self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
#         nn.init.xavier_uniform_(self.weights)
#         nn.init.zeros_(self.biases)

#     def forward(self, x):
#         return x.unsqueeze(-1) * self.weights + self.biases


# class TransformerTower(nn.Module):
#     def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
#         super().__init__()
#         self.tokenizer = FeatureTokenizer(num_features, embed_dim)
#         self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
#         encoder_layer = nn.TransformerEncoderLayer(
#             d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
#             batch_first=True, dropout=0.1
#         )
#         self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

#     def forward(self, x):
#         tokens = self.tokenizer(x)
#         batch_size = x.shape[0]
#         cls_tokens = self.cls_token.expand(batch_size, -1, -1)
#         tokens = torch.cat((cls_tokens, tokens), dim=1)
#         out = self.transformer(tokens)
#         return out[:, 0, :]


# class CTSDualTowerModel(nn.Module):
#     def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
#         super().__init__()
#         self.client_tower = TransformerTower(client_feats, embed_dim)
#         self.image_tower = TransformerTower(image_feats, embed_dim)
#         self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
#         fusion_input_dim = embed_dim * 3
#         self.hidden = nn.Sequential(
#             nn.Linear(fusion_input_dim, 64),
#             nn.LayerNorm(64),
#             nn.ReLU(),
#             nn.Dropout(0.2)
#         )
#         self.head = nn.Linear(64, 4)

#     def forward(self, cx, ix, ax):
#         c_vec = self.client_tower(cx)
#         i_vec = self.image_tower(ix)
#         a_vec = self.algo_embed(ax)
#         combined = torch.cat([c_vec, i_vec, a_vec], dim=1)
#         hidden = self.hidden(combined)
#         out = self.head(hidden)
        
#         # æ•°å€¼çº¦æŸ
#         gamma = out[:, 0]
#         v = F.softplus(out[:, 1]) + 0.1
#         alpha = F.softplus(out[:, 2]) + 1.1
#         beta = F.softplus(out[:, 3]) + 1e-6
        
#         return torch.stack([gamma, v, alpha, beta], dim=1)


# class CTSDataset(Dataset):
#     def __init__(self, client_x, image_x, algo_x, y):
#         self.cx = torch.FloatTensor(client_x)
#         self.ix = torch.FloatTensor(image_x)
#         self.ax = torch.LongTensor(algo_x)
#         self.y = torch.FloatTensor(y)
#     def __len__(self): return len(self.y)
#     def __getitem__(self, idx): return self.cx[idx], self.ix[idx], self.ax[idx], self.y[idx]


# # ==============================================================================
# # ä¸»æµç¨‹
# # ==============================================================================

# if __name__ == "__main__":
#     # åŠ è½½æ•°æ®
#     print(f"ğŸ”„ 1. æ­£åœ¨è¯»å–æ•°æ®: {CONFIG['data_path']} ...")
#     df_exp = pd.read_excel(CONFIG["data_path"])
#     df_feat = pd.read_csv(CONFIG["feature_path"])
    
#     rename_map = {
#         "image": "image_name", "method": "algo_name",
#         "network_bw": "bandwidth_mbps", "network_delay": "network_rtt",
#         "mem_limit": "mem_limit_mb"
#     }
#     df_exp = df_exp.rename(columns=rename_map)
#     if 'total_time' not in df_exp.columns:
#         possible_cols = [c for c in df_exp.columns if 'total_tim' in c]
#         if possible_cols: df_exp = df_exp.rename(columns={possible_cols[0]: 'total_time'})
#     df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
#     if 'mem_limit_mb' not in df_exp.columns:
#         df_exp['mem_limit_mb'] = 1024.0
    
#     df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
#     print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œæ ·æœ¬æ•°: {len(df)}")
    
#     # ç‰¹å¾
#     col_client = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
#     col_image = ['total_size_mb', 'avg_layer_entropy', 'text_ratio', 'layer_count', 'zero_ratio']
    
#     scaler_c = StandardScaler()
#     X_client = scaler_c.fit_transform(df[col_client].values)
#     scaler_i = StandardScaler()
#     X_image = scaler_i.fit_transform(df[col_image].values)
#     enc_algo = LabelEncoder()
#     X_algo = enc_algo.fit_transform(df['algo_name'].values)
#     y_target = np.log1p(df['total_time'].values)
    
#     # [å…³é”®ä¿®å¤] ç²¾ç¡®70/15/15åˆ’åˆ†
#     n_total = len(y_target)
#     indices = np.random.permutation(n_total)
    
#     n_train = int(n_total * 0.70)
#     n_val = int(n_total * 0.15)
#     # n_test = n_total - n_train - n_val  # å‰©ä½™ç»™æµ‹è¯•
    
#     train_idx = indices[:n_train]
#     val_idx = indices[n_train:n_train+n_val]
#     test_idx = indices[n_train+n_val:]
    
#     Xc_train, Xi_train, Xa_train, y_train = X_client[train_idx], X_image[train_idx], X_algo[train_idx], y_target[train_idx]
#     Xc_val, Xi_val, Xa_val, y_val = X_client[val_idx], X_image[val_idx], X_algo[val_idx], y_target[val_idx]
#     Xc_test, Xi_test, Xa_test, y_test = X_client[test_idx], X_image[test_idx], X_algo[test_idx], y_target[test_idx]
    
#     print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
#     print(f"   è®­ç»ƒé›†: {len(y_train)} æ ·æœ¬ ({len(y_train)/n_total*100:.1f}%)")
#     print(f"   éªŒè¯é›†: {len(y_val)} æ ·æœ¬ ({len(y_val)/n_total*100:.1f}%)")
#     print(f"   æµ‹è¯•é›†: {len(y_test)} æ ·æœ¬ ({len(y_test)/n_total*100:.1f}%)")
    
#     train_loader = DataLoader(CTSDataset(Xc_train, Xi_train, Xa_train, y_train), batch_size=CONFIG["batch_size"], shuffle=True)
#     val_loader = DataLoader(CTSDataset(Xc_val, Xi_val, Xa_val, y_val), batch_size=CONFIG["batch_size"])
#     test_loader = DataLoader(CTSDataset(Xc_test, Xi_test, Xa_test, y_test), batch_size=CONFIG["batch_size"])
    
#     # æ¨¡å‹
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     print(f"\nğŸ–¥ï¸ è®­ç»ƒè®¾å¤‡: {device}")
    
#     model = CTSDualTowerModel(
#         client_feats=len(col_client),
#         image_feats=len(col_image),
#         num_algos=len(enc_algo.classes_)
#     ).to(device)
    
#     optimizer = optim.AdamW(model.parameters(), lr=CONFIG["lr"], weight_decay=CONFIG["weight_decay"])
    
#     # è®­ç»ƒ
#     print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
#     best_val_loss = float('inf')
#     best_epoch = 0
#     patience = 30
#     patience_counter = 0
    
#     history = {'epoch': [], 'train_total': [], 'val_nll': [], 'val_corr': []}
    
#     for epoch in range(CONFIG["epochs"]):
#         model.train()
#         train_total = 0
        
#         for cx, ix, ax, y in train_loader:
#             cx, ix, ax, y = cx.to(device), ix.to(device), ax.to(device), y.to(device)
#             optimizer.zero_grad()
#             preds = model(cx, ix, ax)
#             loss, nll, reg, anneal = evidential_loss(preds, y, epoch)
#             loss.backward()
#             optimizer.step()
#             train_total += loss.item()
        
#         # éªŒè¯
#         model.eval()
#         val_nll = 0
#         all_unc, all_err = [], []
        
#         with torch.no_grad():
#             for cx, ix, ax, y in val_loader:
#                 cx, ix, ax, y = cx.to(device), ix.to(device), ax.to(device), y.to(device)
#                 preds = model(cx, ix, ax)
#                 gamma, v, alpha, beta = preds[:, 0], preds[:, 1], preds[:, 2], preds[:, 3]
                
#                 val_nll += nig_nll_loss(y, gamma, v, alpha, beta).item()
                
#                 # åŸå§‹ç©ºé—´
#                 pred_time = np.expm1(gamma.cpu().numpy())
#                 true_time = np.expm1(y.cpu().numpy())
#                 error = np.abs(pred_time - true_time)
#                 uncertainty = (beta / (v * (alpha - 1))).cpu().numpy()
                
#                 all_unc.extend(uncertainty)
#                 all_err.extend(error)
        
#         try:
#             corr, _ = spearmanr(all_unc, all_err)
#         except:
#             corr = 0
        
#         avg_train = train_total / len(train_loader)
#         avg_val = val_nll / len(val_loader)
        
#         history['epoch'].append(epoch)
#         history['train_total'].append(avg_train)
#         history['val_nll'].append(avg_val)
#         history['val_corr'].append(corr)
        
#         if (epoch + 1) % 20 == 0:
#             print(f"Epoch {epoch+1:03d} | Train: {avg_train:.3f} | Val NLL: {avg_val:.3f} | Corr: {corr:+.3f}")
        
#         # æ—©åœ
#         if avg_val < best_val_loss:
#             best_val_loss = avg_val
#             best_epoch = epoch
#             patience_counter = 0
#             torch.save({
#                 'epoch': epoch,
#                 'model_state_dict': model.state_dict(),
#                 'best_val_loss': best_val_loss,
#                 'scaler_c': scaler_c,
#                 'scaler_i': scaler_i,
#                 'enc_algo': enc_algo,
#                 'col_client': col_client,
#                 'col_image': col_image,
#             }, CONFIG["model_save_path"])
#         else:
#             patience_counter += 1
#             if patience_counter >= patience:
#                 print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼")
#                 break
    
#     print(f"\nğŸ’¾ æœ€ä½³Val NLL: {best_val_loss:.4f} (Epoch {best_epoch})")
    
#     # æµ‹è¯•
#     print("\nğŸ”® æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°:")
#     checkpoint = torch.load(CONFIG["model_save_path"], weights_only=False)
#     model.load_state_dict(checkpoint['model_state_dict'])
#     model.eval()
    
#     test_nll = 0
#     all_test_unc, all_test_err = [], []
    
#     with torch.no_grad():
#         for cx, ix, ax, y in test_loader:
#             cx, ix, ax, y = cx.to(device), ix.to(device), ax.to(device), y.to(device)
#             preds = model(cx, ix, ax)
#             gamma, v, alpha, beta = preds[:, 0], preds[:, 1], preds[:, 2], preds[:, 3]
            
#             test_nll += nig_nll_loss(y, gamma, v, alpha, beta).item()
            
#             pred_time = np.expm1(gamma.cpu().numpy())
#             true_time = np.expm1(y.cpu().numpy())
#             error = np.abs(pred_time - true_time)
#             uncertainty = (beta / (v * (alpha - 1))).cpu().numpy()
            
#             all_test_unc.extend(uncertainty)
#             all_test_err.extend(error)
    
#     final_corr, _ = spearmanr(all_test_unc, all_test_err)
#     rmse = np.sqrt(np.mean(np.array(all_test_err)**2))
    
#     print(f"\n{'='*60}")
#     print(f"ğŸ“Š æµ‹è¯•é›†æœ€ç»ˆæŒ‡æ ‡:")
#     print(f"   Test NLL: {test_nll/len(test_loader):.4f}")
#     print(f"   RMSE: {rmse:.4f} (ç§’)")
#     print(f"   Uncertainty-Error Corr: {final_corr:+.3f}")
#     print(f"   ä¸ç¡®å®šæ€§èŒƒå›´: [{np.min(all_test_unc):.3f}, {np.max(all_test_unc):.3f}]")
#     print(f"{'='*60}")
    
#     # ç»˜å›¾
#     fig, axes = plt.subplots(2, 2, figsize=(12, 8))
#     axes[0,0].plot(history['epoch'], history['train_total'], label='Train')
#     axes[0,0].plot(history['epoch'], history['val_nll'], label='Val')
#     axes[0,0].set_title('Loss Curves')
#     axes[0,0].legend()
#     axes[0,0].grid(True, alpha=0.3)
    
#     axes[1,0].plot(history['epoch'], history['val_corr'], 'g-', linewidth=2)
#     axes[1,0].axhline(y=0, color='r', linestyle='--')
#     axes[1,0].set_title('Validation Correlation')
#     axes[1,0].set_ylabel('Spearman')
#     axes[1,0].grid(True, alpha=0.3)
    
#     axes[1,1].scatter(all_test_unc, all_test_err, alpha=0.5, s=10)
#     axes[1,1].set_xlabel('Uncertainty')
#     axes[1,1].set_ylabel('Error (seconds)')
#     axes[1,1].set_title(f'Test: Corr={final_corr:.3f}')
#     axes[1,1].grid(True, alpha=0.3)
    
#     plt.tight_layout()
#     plt.savefig('final_results.png', dpi=150)
#     print("\nğŸ“Š ç»“æœå›¾å·²ä¿å­˜")