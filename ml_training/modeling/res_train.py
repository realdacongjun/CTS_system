import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from scipy.stats import spearmanr
import pickle
import random
import math
import platform
import matplotlib

# ==============================================================================
# 0. åŸºç¡€é…ç½®
# ==============================================================================
system_name = platform.system()
if system_name == 'Windows':
    font_list = ['Microsoft YaHei', 'SimHei']
elif system_name == 'Darwin':
    font_list = ['Heiti TC', 'PingFang HK']
else:
    font_list = ['WenQuanYi Micro Hei', 'Droid Sans Fallback']
    
matplotlib.rcParams['font.sans-serif'] = font_list
matplotlib.rcParams['axes.unicode_minus'] = False 

def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

set_seed(42)

# ==============================================================================
# 1. è¶…å‚æ•°é…ç½® (ç¨³å®šç‰ˆ)
# ==============================================================================
CONFIG = {
    "lr": 0.0005,              
    "weight_decay": 1e-4,      
    "epochs": 200,             
    "patience": 15,           
    "batch_size": 128,         
    "embed_dim": 32,           
    
    # æ­£åˆ™åŒ–å‚æ•°ï¼ˆå»ºè®®è®­ç»ƒæ—¶è§‚å¯Ÿloss_nllå’Œloss_regçš„é‡çº§ï¼Œé€‚å½“è°ƒæ•´ï¼‰
    "reg_coeff": 1.0,          
    "warmup_epochs": 3,        
    
    "data_path": "cts_data.xlsx",
    "feature_path": "image_features_database.csv",
    "model_save_path": "cts_final_strong.pth",
}

# ==============================================================================
# 2. æŸå¤±å‡½æ•°ï¼šSymmetric Strong EUBï¼ˆä¿æŒä¸å˜ï¼‰
# ==============================================================================
def nig_nll_loss(y, gamma, v, alpha, beta):
    two_blambda = 2 * beta * (1 + v)
    nll = 0.5 * torch.log(np.pi / v) \
        - alpha * torch.log(two_blambda) \
        + (alpha + 0.5) * torch.log(v * (y - gamma)**2 + two_blambda) \
        + torch.lgamma(alpha) - torch.lgamma(alpha + 0.5)
    return nll.mean()

def strong_eub_reg_loss(y, gamma, v, alpha, beta):
    """
    å¯¹ç§°ä¿çœŸåº¦æ­£åˆ™é¡¹ï¼šå¼ºåˆ¶è¯¯å·®/æ ‡å‡†å·®è¶‹è¿‘1ï¼ŒåŒæ—¶æƒ©ç½šè¿‡åº¦è‡ªä¿¡å’Œè¿‡åº¦ä¿å®ˆ
    """
    error = torch.abs(y - gamma)
    
    # è®¡ç®—æ ‡å‡†å·®ï¼ˆç§»é™¤ +1e-6 åˆ†æ¯ä¿æŠ¤ï¼Œå› ä¸º alpha>1 å·²ç¡®ä¿ï¼‰
    var = beta / (v * (alpha - 1))
    std = torch.sqrt(var + 1e-6)
    
    raw_ratio = error / (std + 1e-6)
    ratio = torch.clamp(raw_ratio, max=5.0)
    
    penalty = (ratio - 1.0) ** 2
    
    # è¯æ®æˆªæ–­
    evidence = torch.clamp(2 * v + alpha, max=20.0)
    reg = penalty * torch.log1p(evidence)
    
    return reg.mean()

def evidential_loss(pred, target, epoch):
    gamma, v, alpha, beta = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]
    target = target.view(-1)
    
    loss_nll = nig_nll_loss(target, gamma, v, alpha, beta)
    loss_reg = strong_eub_reg_loss(target, gamma, v, alpha, beta)
    
    if epoch < CONFIG["warmup_epochs"]:
        reg_weight = 0.0
    else:
        progress = min(1.0, (epoch - CONFIG["warmup_epochs"]) / 5)
        reg_weight = CONFIG["reg_coeff"] * progress
    
    total_loss = loss_nll + reg_weight * loss_reg
    return total_loss, loss_nll.item(), loss_reg.item()

# ==============================================================================
# 3. æ¨¡å‹å®šä¹‰ï¼ˆç§»é™¤é—¨æ§ï¼Œæ”¹ä¸ºç›´æ¥æ‹¼æ¥ï¼‰
# ==============================================================================
class FeatureTokenizer(nn.Module):
    def __init__(self, num_features, embed_dim):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(num_features, embed_dim))
        self.biases = nn.Parameter(torch.randn(num_features, embed_dim))
        self.norm = nn.LayerNorm(embed_dim)
    def forward(self, x):
        return self.norm(x.unsqueeze(-1) * self.weights + self.biases)

class TransformerTower(nn.Module):
    def __init__(self, num_features, embed_dim, nhead=4, num_layers=2):
        super().__init__()
        self.tokenizer = FeatureTokenizer(num_features, embed_dim)
        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, nhead=nhead, dim_feedforward=embed_dim*4,
            batch_first=True, dropout=0.1, activation="gelu"
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
    def forward(self, x):
        tokens = self.tokenizer(x)
        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)
        out = self.transformer(torch.cat((cls_tokens, tokens), dim=1))
        return out[:, 0, :]

class CTSDualTowerModel(nn.Module):
    """
    åŒå¡”Transformeræ¨¡å‹ï¼ˆæ— é—¨æ§ï¼Œç›´æ¥æ‹¼æ¥ï¼‰
    - å®¢æˆ·ç«¯ç‰¹å¾å¡” + é•œåƒç‰¹å¾å¡” â†’ ç‰¹å¾å‘é‡æ‹¼æ¥
    - ç®—æ³•åµŒå…¥
    - æ‹¼æ¥åé€å…¥MLPé¢„æµ‹NIGåˆ†å¸ƒå‚æ•°
    """
    def __init__(self, client_feats, image_feats, num_algos, embed_dim=32):
        super().__init__()
        self.client_tower = TransformerTower(client_feats, embed_dim)
        self.image_tower = TransformerTower(image_feats, embed_dim)
        self.algo_embed = nn.Embedding(num_algos, embed_dim)
        
        # éšè—å±‚ï¼ˆè¾“å…¥ç»´åº¦ï¼šclient_vec + image_vec + algo_vec = embed_dim*3ï¼‰
        self.hidden = nn.Sequential(
            nn.Linear(embed_dim * 3, 64),
            nn.LayerNorm(64),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.GELU()
        )
        self.head = nn.Linear(32, 4)

    def forward(self, cx, ix, ax):
        # æå–ç‰¹å¾å‘é‡
        c_vec = self.client_tower(cx)   # [batch, embed_dim]
        i_vec = self.image_tower(ix)    # [batch, embed_dim]
        a_vec = self.algo_embed(ax)     # [batch, embed_dim]
        
        # ç›´æ¥æ‹¼æ¥å®¢æˆ·ç«¯å’Œé•œåƒç‰¹å¾ï¼ˆå–æ¶ˆé—¨æ§ï¼‰
        fused_vec = torch.cat([c_vec, i_vec], dim=1)  # [batch, embed_dim*2]
        
        # ä¸ç®—æ³•å‘é‡æ‹¼æ¥
        combined = torch.cat([fused_vec, a_vec], dim=1)  # [batch, embed_dim*3]
        
        out = self.head(self.hidden(combined))
        
        # çº¦æŸNIGå‚æ•°
        gamma = out[:, 0]
        v = F.softplus(out[:, 1]) + 0.1
        alpha = F.softplus(out[:, 2]) + 1.1   # ç¡®ä¿ alpha > 1
        beta = F.softplus(out[:, 3]) + 1e-6
        
        return torch.stack([gamma, v, alpha, beta], dim=1)

# ==============================================================================
# 4. æ•°æ®åŠ è½½ï¼ˆä¿®å¤scalerä¿å­˜é”™è¯¯ï¼Œå¢åŠ æµ‹è¯•é›†åˆ’åˆ†ï¼‰
# ==============================================================================
class CTSDataset(Dataset):
    def __init__(self, cx, ix, ax, y):
        self.cx = torch.FloatTensor(cx)
        self.ix = torch.FloatTensor(ix)
        self.ax = torch.LongTensor(ax)
        self.y = torch.FloatTensor(y)
    def __len__(self): 
        return len(self.y)
    def __getitem__(self, idx): 
        return self.cx[idx], self.ix[idx], self.ax[idx], self.y[idx]

def load_data():
    print(f"ğŸ”„ è¯»å–æ•°æ®: {CONFIG['data_path']} ...")
    if not os.path.exists(CONFIG['data_path']):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {CONFIG['data_path']}")
        return None

    try:
        df_exp = pd.read_excel(CONFIG["data_path"])
        df_feat = pd.read_csv(CONFIG["feature_path"])
        
        # åˆ—åæ ‡å‡†åŒ–
        rename_map = {
            "image": "image_name", 
            "method": "algo_name", 
            "network_bw": "bandwidth_mbps", 
            "network_delay": "network_rtt", 
            "mem_limit": "mem_limit_mb"
        }
        df_exp = df_exp.rename(columns=rename_map)
        
        # å…¼å®¹total_timeåˆ—å
        if 'total_time' not in df_exp.columns: 
            cols = [c for c in df_exp.columns if 'total_tim' in c]
            if cols: 
                df_exp = df_exp.rename(columns={cols[0]: 'total_time'})
            
        df_exp = df_exp[(df_exp['status'] == 'SUCCESS') & (df_exp['total_time'] > 0)]
        df = pd.merge(df_exp, df_feat, on="image_name", how="inner")
        
        # å®¢æˆ·ç«¯ç‰¹å¾
        cols_c = ['bandwidth_mbps', 'cpu_limit', 'network_rtt', 'mem_limit_mb']
        # é•œåƒç‰¹å¾ï¼ˆä»…ä¿ç•™å­˜åœ¨çš„åˆ—ï¼‰
        target_cols = ['total_size_mb', 'avg_layer_entropy', 'entropy_std', 
                       'layer_count', 'size_std_mb', 'text_ratio', 'zero_ratio']
        cols_i = [c for c in target_cols if c in df.columns]
        
        # âœ… ä¿®å¤1ï¼šæ­£ç¡®ä¿å­˜å·²æ‹Ÿåˆçš„ scalerï¼Œè€Œä¸æ˜¯é‡æ–°fit
        scaler_c = StandardScaler().fit(df[cols_c].values)
        Xc = scaler_c.transform(df[cols_c].values)
        
        scaler_i = StandardScaler().fit(df[cols_i].values)
        Xi = scaler_i.transform(df[cols_i].values)
        
        enc = LabelEncoder()
        Xa = enc.fit_transform(df['algo_name'].values)
        y = np.log1p(df['total_time'].values)
        
        # ä¿å­˜é¢„å¤„ç†å¯¹è±¡
        with open('preprocessing_objects.pkl', 'wb') as f:
            pickle.dump({
                'scaler_c': scaler_c, 
                'scaler_i': scaler_i, 
                'enc': enc
            }, f)
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæ€»æ ·æœ¬æ•°: {len(y)}")
        return Xc, Xi, Xa, y, enc, len(cols_c), len(cols_i)
    
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

# ==============================================================================
# 5. è®­ç»ƒä¸»å¾ªç¯ï¼ˆå¢åŠ ç‹¬ç«‹æµ‹è¯•é›†ï¼‰
# ==============================================================================
if __name__ == "__main__":
    data = load_data()
    if data:
        Xc, Xi, Xa, y, enc_algo, c_dim, i_dim = data
        N = len(y)
        idx = np.random.permutation(N)
        
        # âœ… ä¿®å¤2ï¼šåˆ’åˆ†è®­ç»ƒ(70%)ã€éªŒè¯(15%)ã€æµ‹è¯•(15%)
        n_tr = int(N * 0.7)
        n_val = int(N * 0.15)
        n_te = N - n_tr - n_val
        
        tr_idx = idx[:n_tr]
        val_idx = idx[n_tr:n_tr+n_val]
        te_idx = idx[n_tr+n_val:]
        
        print(f"ğŸ“Š æ•°æ®é›†åˆ’åˆ†: è®­ç»ƒ {len(tr_idx)} æ¡, éªŒè¯ {len(val_idx)} æ¡, æµ‹è¯• {len(te_idx)} æ¡")
        
        # åˆ›å»ºæ•°æ®é›†
        tr_d = CTSDataset(Xc[tr_idx], Xi[tr_idx], Xa[tr_idx], y[tr_idx])
        val_d = CTSDataset(Xc[val_idx], Xi[val_idx], Xa[val_idx], y[val_idx])
        te_d = CTSDataset(Xc[te_idx], Xi[te_idx], Xa[te_idx], y[te_idx])
        
        tr_loader = DataLoader(tr_d, batch_size=CONFIG["batch_size"], shuffle=True)
        val_loader = DataLoader(val_d, batch_size=CONFIG["batch_size"])
        te_loader = DataLoader(te_d, batch_size=CONFIG["batch_size"])  # ä»…ç”¨äºæœ€ç»ˆè¯„ä¼°
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")
        
        model = CTSDualTowerModel(c_dim, i_dim, len(enc_algo.classes_)).to(device)
        print(f"ğŸ“¦ æ¨¡å‹ç»“æ„:\n{model}")
        
        optimizer = optim.AdamW(model.parameters(), 
                               lr=CONFIG["lr"], 
                               weight_decay=CONFIG["weight_decay"])
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG["epochs"])
        
        best_corr = -1.0
        best_epoch = 0
        patience_counter = 0
        history = {'loss': [], 'corr': [], 'test_corr': []}
        
        for epoch in range(CONFIG["epochs"]):
            # ---------- è®­ç»ƒ ----------
            model.train()
            t_loss = 0
            for cx, ix, ax, target in tr_loader:
                cx, ix, ax, target = cx.to(device), ix.to(device), ax.to(device), target.to(device)
                optimizer.zero_grad()
                loss, _, _ = evidential_loss(model(cx, ix, ax), target, epoch)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                t_loss += loss.item()
            
            scheduler.step()
            
            # ---------- éªŒè¯ ----------
            model.eval()
            uncs, errs = [], []
            with torch.no_grad():
                for cx, ix, ax, target in val_loader:
                    cx, ix, ax, target = cx.to(device), ix.to(device), ax.to(device), target.to(device)
                    preds = model(cx, ix, ax)
                    gamma, v, alpha, beta = preds[:,0], preds[:,1], preds[:,2], preds[:,3]
                    
                    # ä¸ç¡®å®šæ€§åº¦é‡ï¼ˆæ–¹å·®ï¼‰
                    unc = beta / (v * (alpha - 1))
                    # ç»å¯¹è¯¯å·®ï¼ˆåŸå§‹å°ºåº¦ï¼‰
                    err = torch.abs(torch.expm1(gamma) - torch.expm1(target))
                    uncs.extend(unc.cpu().numpy())
                    errs.extend(err.cpu().numpy())
            
            try:
                corr, _ = spearmanr(uncs, errs)
                corr = corr if not np.isnan(corr) else 0.0
            except:
                corr = 0.0
            
            history['loss'].append(t_loss/len(tr_loader))
            history['corr'].append(corr)
            
            # ---------- æ—©åœä¸æ¨¡å‹ä¿å­˜ ----------
            print(f"Epoch {epoch+1:03d} | Loss: {history['loss'][-1]:.4f} | Val Corr: {corr:.4f}", end="")
            
            if corr > best_corr:
                best_corr = corr
                best_epoch = epoch
                patience_counter = 0
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_corr': best_corr,
                    'epoch': epoch,
                    'config': CONFIG
                }, CONFIG["model_save_path"])
                print(f" ğŸŒŸ æ–°æœ€ä½³æ¨¡å‹ (Corr={best_corr:.4f})")
            else:
                patience_counter += 1
                print(f" (è€å¿ƒ: {patience_counter}/{CONFIG['patience']})")
                
            if patience_counter >= CONFIG["patience"]:
                print(f"\nâ¹ï¸ è§¦å‘æ—©åœï¼Œåœæ­¢è®­ç»ƒã€‚")
                break
        
        # ---------- æœ€ç»ˆæµ‹è¯•ï¼ˆåŠ è½½æœ€ä½³æ¨¡å‹ï¼‰----------
        print("\nğŸ” åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•é›†è¯„ä¼°...")
        checkpoint = torch.load(CONFIG["model_save_path"])
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        test_uncs, test_errs = [], []
        with torch.no_grad():
            for cx, ix, ax, target in te_loader:
                cx, ix, ax, target = cx.to(device), ix.to(device), ax.to(device), target.to(device)
                preds = model(cx, ix, ax)
                gamma, v, alpha, beta = preds[:,0], preds[:,1], preds[:,2], preds[:,3]
                
                unc = beta / (v * (alpha - 1))
                err = torch.abs(torch.expm1(gamma) - torch.expm1(target))
                test_uncs.extend(unc.cpu().numpy())
                test_errs.extend(err.cpu().numpy())
        
        try:
            test_corr, _ = spearmanr(test_uncs, test_errs)
            test_corr = test_corr if not np.isnan(test_corr) else 0.0
        except:
            test_corr = 0.0
        
        print(f"âœ… æµ‹è¯•é›† Spearman ç›¸å…³ç³»æ•°: {test_corr:.4f}")
        
        # ---------- è®­ç»ƒæ›²çº¿å¯è§†åŒ– ----------
        plt.figure(figsize=(15, 5))
        
        plt.subplot(1, 3, 1)
        plt.plot(history['loss'], label='Training Loss')
        plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.subplot(1, 3, 2)
        plt.plot(history['corr'], color='#ff7f0e', label='Validation Corr')
        plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Epoch {best_epoch+1}')
        plt.title('éªŒè¯é›† Spearman ç›¸å…³æ€§')
        plt.xlabel('Epoch')
        plt.ylabel('Spearman Ï')
        plt.legend()
        
        plt.subplot(1, 3, 3)
        plt.scatter(test_uncs, test_errs, alpha=0.5, s=10)
        plt.xlabel('é¢„æµ‹ä¸ç¡®å®šæ€§ (æ–¹å·®)')
        plt.ylabel('ç»å¯¹é¢„æµ‹è¯¯å·® (ç§’)')
        plt.title(f'æµ‹è¯•é›†: ä¸ç¡®å®šæ€§ vs è¯¯å·® (Ï={test_corr:.3f})')
        plt.xscale('log')
        plt.yscale('log')
        
        plt.tight_layout()
        plt.savefig('training_result_strong.png', dpi=150)
        plt.show()
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹: {CONFIG['model_save_path']}")
        print(f"   æœ€ä½³éªŒè¯ Corr: {best_corr:.4f} (Epoch {best_epoch+1})")
        print(f"   æµ‹è¯•é›† Corr: {test_corr:.4f}")