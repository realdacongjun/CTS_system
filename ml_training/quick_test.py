"""
å¢å¼ºç‰ˆå¿«é€ŸéªŒè¯è„šæœ¬ (Data Quality Ready)
åŠŸèƒ½ï¼šæ‰§è¡Œå°å‹å®éªŒçŸ©é˜µï¼Œå¹¶éªŒè¯æ”¶é›†åˆ°çš„å®æµ‹æ•°æ®è´¨é‡æ˜¯å¦æ»¡è¶³åŒå¡”æ¨¡å‹è®­ç»ƒè¦æ±‚
"""

import os
import sys
import time
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from ml_training.config import get_client_capabilities, get_image_profiles, get_compression_config
from ml_training.exp_orchestrator import ExperimentOrchestrator

def run_quick_test():
    print("ğŸš€ å¼€å§‹è¿è¡Œå¢å¼ºç‰ˆéªŒè¯å®éªŒ...")
    
    # 1. åˆå§‹åŒ–è®¾ç½®
    data_dir = "/tmp/quick_test_data"
    Path(data_dir).mkdir(parents=True, exist_ok=True)
    
    # å»ºè®®ï¼šå¦‚æœæ˜¯æœ¬åœ°æµ‹è¯•è®¾ä¸º Falseï¼Œå¦‚æœåœ¨äº‘ç«¯æµ‹è¯•è®¾ä¸º True
    IS_CLOUD = False 
    
    orchestrator = ExperimentOrchestrator(
        registry_url="localhost:5000",
        data_dir=data_dir,
        container_image="cts_client:latest",
        cloud_mode=IS_CLOUD
    )
    
    # 2. é€‰å–å®éªŒå­é›† (1x2x2)
    all_client_profiles = get_client_capabilities()['profiles']
    selected_profiles = [p for p in all_client_profiles if p['name'] == 'C1'][:1]
    
    all_target_images = get_image_profiles()
    # é€‰å–ä¸€ä¸ªè¶…å°é•œåƒå’Œä¸€ä¸ªä¸­å‹é•œåƒï¼Œè§‚å¯Ÿæ•°æ®å·®å¼‚
    selected_images = [i for i in all_target_images if i['name'] in ['hello-world', 'alpine']][:2]
    
    selected_methods = ['gzip-1', 'zstd-1']
    
    all_results = []
    
    # 3. æ‰§è¡Œå®éªŒå¾ªç¯ - éœ€è¦å¯åŠ¨å®¹å™¨å¹¶è¿è¡Œå®éªŒ
    for profile in selected_profiles:
        print(f"\n[Profile: {profile['name']}] è®¾å®šå¸¦å®½ç›®æ ‡: {profile.get('bw_rate', profile.get('bandwidth_mbps', 'N/A'))} Mbps")
        
        # å¯åŠ¨å®¹å™¨
        container = orchestrator._setup_emulated_container(profile)
        
        try:
            for image in selected_images:
                for method in selected_methods:
                    print(f"æ­£åœ¨æµ‹è¯•: Image={image['name']} | Method={method}...")
                    
                    try:
                        # è°ƒç”¨ä¿®æ”¹åçš„ orchestrator (åº”åŒ…å«å®æ—¶ç›‘æ§é€»è¾‘)
                        record = orchestrator.run_profiled_experiment(
                            container,
                            f"{orchestrator.registry_url}/{image['name']}",
                            method,
                            profile
                        )
                        
                        # è¡¥å……é•œåƒç‰©ç†ç‰¹å¾ (ä¸ºäº†ç»™åŒå¡”æ¨¡å‹æä¾›å³å¡”è¾“å…¥)
                        record['static_image_size_mb'] = image.get('size_mb', 0)
                        record['static_layer_count'] = image.get('layer_count', 0)
                        
                        all_results.append(record)
                        
                        # å®æ—¶åé¦ˆå®æµ‹è´¨é‡
                        if record['status'] == 'SUCCESS':
                            actual_bw = record.get('actual_bandwidth', 0)
                            bw_std = record.get('bandwidth_std', 0)
                            
                            print(f" âœ… æˆåŠŸ | å®æµ‹å¸¦å®½: {actual_bw:.2f} Mbps (æ³¢åŠ¨: {bw_std:.2f})")
                            if record.get('is_noisy_data'):
                                print(f" âš ï¸  è­¦å‘Š: æ­¤æ¡æ•°æ®æ³¢åŠ¨è¿‡å¤§ï¼Œå°†è¢«æ¨¡å‹æ ‡è®°ä¸ºå™ªå£°")
                        else:
                            print(f" âŒ å¤±è´¥ | åŸå› : {record.get('error')}")

                    except Exception as e:
                        print(f" ğŸ’¥ è„šæœ¬å´©æºƒ: {e}")
                        import traceback
                        traceback.print_exc()
        finally:
            # æ¸…ç†å®¹å™¨
            try:
                container.stop()
                container.remove()
            except:
                pass

    # 4. æ±‡æ€»ä¸æ¨¡å‹å‡†å¤‡åº¦åˆ†æ
    print("\n" + "="*30)
    print("ğŸ“Š å®éªŒç»“æœåˆ†æ")
    print("="*30)
    
    successes = [r for r in all_results if r['status'] == 'SUCCESS']
    noisy = [r for r in successes if r.get('is_noisy_data', False)]
    
    print(f"1. æ€»æ ·æœ¬æ•°: {len(all_results)}")
    print(f"2. æœ‰æ•ˆæ ·æœ¬ (ç”¨äºè®­ç»ƒ): {len(successes) - len(noisy)}")
    print(f"3. å™ªå£°æ ·æœ¬ (äº‘ç«¯å¹²æ‰°): {len(noisy)}")
    
    # æ‰“å°ä¸€æ¡æ ·æœ¬é¢„è§ˆï¼Œæ£€æŸ¥å­—æ®µæ˜¯å¦å®Œæ•´
    if successes:
        print("\n[ä¸€æ¡å¯ç”¨äºè®­ç»ƒçš„æ ·æœ¬é¢„è§ˆ]:")
        sample = successes[0]
        # æŒ‘é€‰æ¨¡å‹å…³å¿ƒçš„å­—æ®µ
        training_features = {
            "X_Client": [sample.get('actual_bandwidth'), sample.get('avg_cpu_usage')],
            "X_Image": [sample.get('static_image_size_mb'), sample.get('static_layer_count')],
            "Y_Label": sample.get('decompression_time', 0)
        }
        print(json.dumps(training_features, indent=4))

    # 5. ä¿å­˜
    output_file = os.path.join(data_dir, "model_training_ready_data.json")
    with open(output_file, 'w') as f:
        json.dump(all_results, f, indent=2)
    
    print(f"\næ•°æ®å·²ä¿å­˜è‡³: {output_file}")

if __name__ == "__main__":
    run_quick_test()